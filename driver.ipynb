{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import *\n",
    "from keras.layers import *\n",
    "from keras.applications import *\n",
    "from keras.preprocessing.image import *\n",
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "import numpy as np\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import applications\n",
    "def vgg16Model(image_size = (224, 224), if_draw_model = False):\n",
    "    width = image_size[0]\n",
    "    height = image_size[1]\n",
    "    \n",
    "    base_model = applications.VGG16(input_tensor=Input((height, width, 3)), weights='imagenet', include_top=False)\n",
    "\n",
    "    for layers in base_model.layers:\n",
    "        layers.trainable = True\n",
    "        \n",
    "    for i, layer in enumerate(base_model.layers):\n",
    "        print(i, layer.name)\n",
    "        \n",
    "   # for layer in base_model.layers[25:]:\n",
    "   #     layer.trainable = True\n",
    "\n",
    "    x = GlobalAveragePooling2D()(base_model.output)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = Dense(10, activation='sigmoid')(x)\n",
    "    model = Model(base_model.input, x)\n",
    "    \n",
    "    if if_draw_model:\n",
    "        SVG(model_to_dot(model).create(prog='dot', format='svg'))\n",
    "    \n",
    "    model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications.resnet50 import ResNet50\n",
    "from keras.applications.resnet50 import preprocess_input, decode_predictions\n",
    "import numpy as np\n",
    "\n",
    "def restNet_model(image_size = (224, 224), if_draw_model = False):\n",
    "\n",
    "    width = image_size[0]\n",
    "    height = image_size[1]\n",
    "    \n",
    "    base_model = ResNet50(input_tensor=Input((height, width, 3)), weights='imagenet', include_top=False)\n",
    "\n",
    "    for layers in base_model.layers:\n",
    "        layers.trainable = True\n",
    "        \n",
    "    for i, layer in enumerate(base_model.layers):\n",
    "        print(i, layer.name)\n",
    "        \n",
    "   # for layer in base_model.layers[25:]:\n",
    "   #     layer.trainable = True\n",
    "\n",
    "    x = GlobalAveragePooling2D()(base_model.output)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = Dense(10, activation='sigmoid')(x)\n",
    "    model = Model(base_model.input, x)\n",
    "    \n",
    "    if if_draw_model:\n",
    "        SVG(model_to_dot(model).create(prog='dot', format='svg'))\n",
    "    \n",
    "    model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.applications.inception_v3 import preprocess_input, decode_predictions\n",
    "import numpy as np\n",
    "\n",
    "def inceptionV3_model(image_size = (224, 224), if_draw_model = False):\n",
    "\n",
    "    width = image_size[0]\n",
    "    height = image_size[1]\n",
    "    \n",
    "    base_model = InceptionV3(input_tensor=Input((height, width, 3)), weights='imagenet', include_top=False)\n",
    "\n",
    "    for layers in base_model.layers:\n",
    "        layers.trainable = True\n",
    "        \n",
    "    for i, layer in enumerate(base_model.layers):\n",
    "        print(i, layer.name)\n",
    "        \n",
    "   # for layer in base_model.layers[25:]:\n",
    "   #     layer.trainable = True\n",
    "\n",
    "    x = GlobalAveragePooling2D()(base_model.output)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = Dense(10, activation='sigmoid')(x)\n",
    "    model = Model(base_model.input, x)\n",
    "    \n",
    "    if if_draw_model:\n",
    "        SVG(model_to_dot(model).create(prog='dot', format='svg'))\n",
    "    \n",
    "    model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#简单模型\n",
    "def simple_model(time_len=1):\n",
    "    ch, row, col = 3, 66, 200  # camera format\n",
    "    model = Sequential()\n",
    "    model.add(Lambda(lambda x: x/127.5 - 1.,\n",
    "  #  model.add(Lambda(lambda x: x,\n",
    "            input_shape=( row, col, ch),\n",
    "            output_shape=( row, col,ch)))\n",
    "    model.add(Convolution2D(3, 3, 3, subsample=(2, 2), border_mode=\"same\"))\n",
    "    model.add(ELU())\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    model.add(Dropout(.5))\n",
    "    model.add(ELU())\n",
    "    model.add(Dense(10))\n",
    "#  model.add(Lambda(nor_output_1))\n",
    "    sgd = optimizers.SGD(lr=0.00003, momentum=0.9, nesterov=True)\n",
    "    model.compile(loss='mean_squared_error', optimizer=sgd)\n",
    "\n",
    "      \n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "from sklearn.utils import shuffle\n",
    "np.random.seed(2017)\n",
    "\n",
    "def prepare_val():\n",
    "    dirname = 'imgs/val'\n",
    "    dirname_src = 'imgs/train/'\n",
    "    if os.path.exists(dirname):\n",
    "        return\n",
    "    os.mkdir(dirname)\n",
    "    sub_dirs = ['c0', 'c1', 'c2', 'c3', 'c4', 'c5', 'c6', 'c7', 'c8', 'c9']\n",
    "    for sub_dir in sub_dirs:\n",
    "        address_des = dirname + '/' + sub_dir\n",
    "        os.mkdir(address_des)\n",
    "        \n",
    "        address_src = dirname_src + '/' + sub_dir\n",
    "        train_filenames = os.listdir(address_src)\n",
    "        train_filenames = shuffle(train_filenames)\n",
    "        for file_src in train_filenames[0: int(len(train_filenames) / 10)]:\n",
    "            add_con_list = file_src.split('/')\n",
    "            add_old = dirname_src + sub_dir + '/' + add_con_list[-1]\n",
    "            add_new = dirname + '/' + sub_dir + '/' + add_con_list[-1]\n",
    "         #   print(add_old)\n",
    "         #   print(add_new)\n",
    "            shutil.move(add_old, add_new)  \n",
    "        \n",
    "prepare_val()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import pandas as pd\n",
    "import cv2\n",
    "from sklearn.utils import shuffle\n",
    "np.random.seed(2017)\n",
    "\n",
    "def get_driver_list():\n",
    "    driver_id_list = []\n",
    "    df = pd.read_csv(\"driver_imgs_list.csv\")\n",
    "    for i in range(df.shape[0]):\n",
    "        driver_id = df.loc[i][\"subject\"]\n",
    "        is_saved_id = False\n",
    "        for saved_id in driver_id_list:\n",
    "            if saved_id == driver_id:\n",
    "                is_saved_id = True\n",
    "                break\n",
    "        \n",
    "        if is_saved_id == False:\n",
    "            driver_id_list.append(driver_id)\n",
    "    return driver_id_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def prepare_data():\n",
    "    dirbase = 'imgs/train2/'\n",
    "    if os.path.exists(dirbase):\n",
    "        return\n",
    "    os.mkdir(dirbase)\n",
    "        \n",
    "    driver_id_list = get_driver_list()\n",
    "    \n",
    "    df = pd.read_csv(\"driver_imgs_list.csv\")  \n",
    "    sub_dirs = ['c0', 'c1', 'c2', 'c3', 'c4', 'c5', 'c6', 'c7', 'c8', 'c9']\n",
    "    for driver_id in driver_id_list:\n",
    "        os.mkdir(dirbase + driver_id)\n",
    "        for sub_dir in sub_dirs:\n",
    "            os.mkdir(dirbase + driver_id + '/' + sub_dir)\n",
    "\n",
    "    for i in range(df.shape[0]):\n",
    "        driver_id = df.loc[i][\"subject\"]\n",
    "        class_name = df.loc[i][\"classname\"]\n",
    "        img = df.loc[i][\"img\"]\n",
    "        add_old = 'imgs/train/' + class_name+'/' + img\n",
    "        add_new = dirbase + driver_id + '/' + class_name + '/' + img\n",
    "        if os.path.exists(add_old):\n",
    "            shutil.move(add_old, add_new)\n",
    "        \n",
    "prepare_data()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size=(224, 224)\n",
    "batch_size =64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#训练\n",
    "from keras.callbacks import *\n",
    "from keras.models import *\n",
    "#from keras.applications.vgg19 import preprocess_input\n",
    "from keras.applications.resnet50 import preprocess_input, decode_predictions\n",
    "#from keras.applications.inception_v3 import preprocess_input, decode_predictions\n",
    "\n",
    "import copy\n",
    "def get_file_num(driver_id):\n",
    "    train_base_add = 'imgs/train2/'\n",
    "    add_driver = train_base_add + driver_id\n",
    "    sub_dirs = ['c0', 'c1', 'c2', 'c3', 'c4', 'c5', 'c6', 'c7', 'c8', 'c9']\n",
    "    num = 0\n",
    "    for sub_dir in sub_dirs:\n",
    "        add_driver_class = add_driver + '/' + sub_dir\n",
    "        train_filenames = os.listdir(add_driver_class)\n",
    "        num += len(train_filenames)\n",
    "    return num\n",
    "\n",
    "def train_model(Model):\n",
    "    model = Model()\n",
    "    \n",
    "    train_datagen = ImageDataGenerator(\n",
    " #   shear_range=0.2,\n",
    " #   zoom_range=0.2,\n",
    "    preprocessing_function=preprocess_input,\n",
    " #   horizontal_flip=True\n",
    "    )\n",
    "    driver_id_list = get_driver_list()\n",
    "    train_base_add = 'imgs/train2/'\n",
    "    \n",
    "    \n",
    "    patience = 5\n",
    "    loss_list = []\n",
    "    \n",
    "    best_model = 0\n",
    "    save_loss_callback = LambdaCallback(on_epoch_end=lambda epoch, logs:loss_list.append(logs['val_loss']))\n",
    "                            \n",
    "    for epoch in range(15):\n",
    "        print('step---------------------- {%d}'%(epoch))\n",
    "        for driver_id in driver_id_list:\n",
    "            nb_train_samples = get_file_num(driver_id)\n",
    "            \n",
    "            train_generator = train_datagen.flow_from_directory(\n",
    "                train_base_add + driver_id,\n",
    "                target_size=(image_size[0], image_size[1]),\n",
    "                batch_size=batch_size,\n",
    "                class_mode='categorical')\n",
    "    \n",
    "            val_generator = train_datagen.flow_from_directory(\n",
    "                'imgs/val',\n",
    "                target_size=(image_size[0], image_size[1]),\n",
    "                batch_size=batch_size,\n",
    "                class_mode='categorical')\n",
    "        \n",
    "            model.fit_generator(\n",
    "                train_generator,\n",
    "                steps_per_epoch=nb_train_samples // batch_size,\n",
    "                epochs=1,\n",
    "                workers=6,\n",
    "                callbacks=[save_loss_callback],\n",
    "                validation_data = val_generator)\n",
    "            \n",
    "            last_loss = loss_list[-1]\n",
    "            if_best_loss = True\n",
    "            for loss in loss_list:\n",
    "                if loss < last_loss:\n",
    "                    if_best_loss = False\n",
    "            if if_best_loss == True:\n",
    "            #    best_model =copy.deepcopy(model) \n",
    "                if epoch >= 6:\n",
    "                    print('last model loss ------------------------------------------%f'%(last_loss))\n",
    "                    model.save('model.h5')\n",
    "    \n",
    "    \n",
    "    model = load_model('model.h5')\n",
    "    \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import *\n",
    "from keras.models import *\n",
    "#from keras.applications.vgg19 import preprocess_input\n",
    "from keras.applications.resnet50 import preprocess_input, decode_predictions\n",
    "#from keras.applications.inception_v3 import preprocess_input, decode_predictions\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from skimage.io import imread, imsave\n",
    "from scipy.misc import imresize\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.utils import np_utils\n",
    "\n",
    "def get_file_num(driver_id):\n",
    "    train_base_add = 'imgs/train2/'\n",
    "    add_driver = train_base_add + driver_id\n",
    "    sub_dirs = ['c0', 'c1', 'c2', 'c3', 'c4', 'c5', 'c6', 'c7', 'c8', 'c9']\n",
    "    num = 0\n",
    "    for sub_dir in sub_dirs:\n",
    "        add_driver_class = add_driver + '/' + sub_dir\n",
    "        train_filenames = os.listdir(add_driver_class)\n",
    "        num += len(train_filenames)\n",
    "    return num\n",
    "\n",
    "def load_image(path):\n",
    "    img = imread(path)\n",
    "    img = imresize(img, (image_size[1], image_size[0]))\n",
    "    return img\n",
    "\n",
    "def load_driver_imgs(driver_id, pre_add = 'imgs/train2/'):\n",
    "    base_add = pre_add + driver_id\n",
    "    sub_dirs = ['c0', 'c1', 'c2', 'c3', 'c4', 'c5', 'c6', 'c7', 'c8', 'c9']\n",
    "    \n",
    "    img_list = []\n",
    "    label_list = []\n",
    "    for i, sub_dir in enumerate(sub_dirs) :\n",
    "        img_class_add = base_add + '/' + sub_dir\n",
    "        img_names = os.listdir(img_class_add)\n",
    "        for img_name in img_names:\n",
    "            \n",
    "            img = load_image(img_class_add + '/' + img_name)\n",
    "            img_list.append(img)\n",
    "         #   label_val = [0,0,0,0,0,0,0,0,0,0]\n",
    "         #   label_val[i] = 1\n",
    "            label_list.append(sub_dir)\n",
    "            \n",
    "    encoder = LabelEncoder()\n",
    "    encoder.fit(label_list)\n",
    "    encoded_Y = encoder.transform(label_list)\n",
    "# convert integers to dummy variables (i.e. one hot encoded)\n",
    "    label_list = np_utils.to_categorical(encoded_Y)\n",
    "    \n",
    "    img_list = np.array(img_list)\n",
    "    label_list = np.array(label_list)\n",
    "    return img_list, label_list\n",
    "\n",
    "def train_model_2(Model):\n",
    "    model = Model()\n",
    "    \n",
    "    train_datagen = ImageDataGenerator(\n",
    " #   shear_range=0.2,\n",
    " #   zoom_range=0.2,\n",
    "    preprocessing_function=preprocess_input,\n",
    " #   horizontal_flip=True\n",
    "    )\n",
    "    driver_id_list = get_driver_list()\n",
    "    train_base_add = 'imgs/train2/'\n",
    "    \n",
    "    \n",
    "    patience = 5\n",
    "    loss_list = []\n",
    "    \n",
    "    best_model = model\n",
    "    save_loss_callback = LambdaCallback(on_epoch_end=lambda epoch, logs:loss_list.append(logs['val_loss']))\n",
    "    \n",
    "    val_datagen = ImageDataGenerator(\n",
    " #   shear_range=0.2,\n",
    " #   zoom_range=0.2,\n",
    "    preprocessing_function=preprocess_input,\n",
    " #   horizontal_flip=True\n",
    "    )\n",
    "    x_val, y_val = load_driver_imgs('val', 'imgs/')\n",
    "    val_datagen.fit(x_val)\n",
    "    \n",
    "    \n",
    "    for epoch in range(13):\n",
    "        print('step---------------------- {%d}'%(epoch))\n",
    "        for driver_id in driver_id_list:\n",
    "            nb_train_samples = get_file_num(driver_id)\n",
    "            \n",
    "            x_train, y_train = load_driver_imgs(driver_id)\n",
    "        \n",
    "            train_datagen.fit(x_train)\n",
    "            \n",
    "            if epoch >= 5:\n",
    "                model.fit_generator(\n",
    "                    train_datagen.flow(x_train, y_train, batch_size=batch_size),\n",
    "                    shuffle=True,\n",
    "                    steps_per_epoch=nb_train_samples // batch_size,\n",
    "                    epochs=1,\n",
    "                    workers=6,\n",
    "                    callbacks=[save_loss_callback],\n",
    "                    validation_data = val_datagen.flow(x_val, y_val, batch_size=batch_size)               \n",
    "                )\n",
    "                last_loss = loss_list[-1]\n",
    "                if_best_loss = True\n",
    "                for loss in loss_list:\n",
    "                    if loss < last_loss:\n",
    "                        if_best_loss = False\n",
    "                if if_best_loss == True:\n",
    "                \n",
    "                    best_model = model\n",
    "                    print('last model loss ------------------------------------------%f'%(last_loss))\n",
    "                    model.save('model.h5')\n",
    "            else:\n",
    "                model.fit_generator(\n",
    "                train_datagen.flow(x_train, y_train, batch_size=batch_size),\n",
    "                shuffle=True,\n",
    "                steps_per_epoch=nb_train_samples // batch_size,\n",
    "                epochs=1,\n",
    "                workers=6,\n",
    "                validation_data = val_datagen.flow(x_val, y_val, batch_size=batch_size))\n",
    "    \n",
    "    model = load_model('model.h5')\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import cv2\n",
    "def test_model(model, file_name):\n",
    "    df = pd.read_csv(\"sample_submission.csv\")\n",
    "    \n",
    "    test_address = 'imgs/test'\n",
    "    test_filenames = os.listdir(test_address)\n",
    " #   test_filenames = test_filenames[:10]\n",
    "    X = np.zeros((len(test_filenames), image_size[0], image_size[1], 3), dtype=np.uint8)\n",
    "\n",
    "    for i, test_file in enumerate(test_filenames) :\n",
    "        X[i] = cv2.resize(cv2.imread(test_address + '/' + test_file), image_size)\n",
    "    \n",
    "    y_pred = model.predict(X, batch_size=batch_size, verbose=0)\n",
    "  #  print(y_pred)\n",
    "    \n",
    "    for i, fname in enumerate(test_filenames):\n",
    "      #  print(fname)\n",
    "        df.set_value(i, 'img', fname)\n",
    "        sub_dirs = ['c0', 'c1', 'c2', 'c3', 'c4', 'c5', 'c6', 'c7', 'c8', 'c9']\n",
    "        for ii, sb in enumerate(sub_dirs):\n",
    "            df.set_value(i, sb, y_pred[i][ii])\n",
    "\n",
    "\n",
    "    df.to_csv(file_name, index=None)\n",
    "    df.head(10)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import cv2\n",
    "#from keras.applications.vgg19 import preprocess_input\n",
    "#from keras.applications.resnet50 import preprocess_input, decode_predictions\n",
    "from keras.applications.inception_v3 import preprocess_input, decode_predictions\n",
    "\n",
    "def test_model_2(model, file_name):\n",
    "    df = pd.read_csv(\"sample_submission.csv\")\n",
    "    \n",
    "    test_address = 'imgs/test'\n",
    "\n",
    "    \n",
    "    test_datagen = ImageDataGenerator(\n",
    " #   shear_range=0.2,\n",
    " #   zoom_range=0.2,\n",
    "    preprocessing_function=preprocess_input,\n",
    " #   horizontal_flip=True\n",
    "    )\n",
    "    test_generator = test_datagen.flow_from_directory(\n",
    "        test_address,\n",
    "        target_size=(image_size[0], image_size[1]),\n",
    "        shuffle = \"false\",\n",
    "        class_mode='categorical',\n",
    "        batch_size=1)\n",
    "\n",
    "    filenames = test_generator.filenames\n",
    "    nb_samples = len(filenames)\n",
    "   \n",
    "    y_pred = model.predict_generator(test_generator, steps = nb_samples)\n",
    "  #  print(y_pred)\n",
    "    \n",
    "    for i, fname in enumerate(filenames):\n",
    "      #  print(fname)\n",
    "        df.set_value(i, 'img', fname)\n",
    "        sub_dirs = ['c0', 'c1', 'c2', 'c3', 'c4', 'c5', 'c6', 'c7', 'c8', 'c9']\n",
    "        for ii, sb in enumerate(sub_dirs):\n",
    "            df.set_value(i, sb, y_pred[i][ii])\n",
    "\n",
    "\n",
    "    df.to_csv(file_name, index=None)\n",
    "    df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 input_3\n",
      "1 conv1\n",
      "2 bn_conv1\n",
      "3 activation_99\n",
      "4 max_pooling2d_3\n",
      "5 res2a_branch2a\n",
      "6 bn2a_branch2a\n",
      "7 activation_100\n",
      "8 res2a_branch2b\n",
      "9 bn2a_branch2b\n",
      "10 activation_101\n",
      "11 res2a_branch2c\n",
      "12 res2a_branch1\n",
      "13 bn2a_branch2c\n",
      "14 bn2a_branch1\n",
      "15 add_33\n",
      "16 activation_102\n",
      "17 res2b_branch2a\n",
      "18 bn2b_branch2a\n",
      "19 activation_103\n",
      "20 res2b_branch2b\n",
      "21 bn2b_branch2b\n",
      "22 activation_104\n",
      "23 res2b_branch2c\n",
      "24 bn2b_branch2c\n",
      "25 add_34\n",
      "26 activation_105\n",
      "27 res2c_branch2a\n",
      "28 bn2c_branch2a\n",
      "29 activation_106\n",
      "30 res2c_branch2b\n",
      "31 bn2c_branch2b\n",
      "32 activation_107\n",
      "33 res2c_branch2c\n",
      "34 bn2c_branch2c\n",
      "35 add_35\n",
      "36 activation_108\n",
      "37 res3a_branch2a\n",
      "38 bn3a_branch2a\n",
      "39 activation_109\n",
      "40 res3a_branch2b\n",
      "41 bn3a_branch2b\n",
      "42 activation_110\n",
      "43 res3a_branch2c\n",
      "44 res3a_branch1\n",
      "45 bn3a_branch2c\n",
      "46 bn3a_branch1\n",
      "47 add_36\n",
      "48 activation_111\n",
      "49 res3b_branch2a\n",
      "50 bn3b_branch2a\n",
      "51 activation_112\n",
      "52 res3b_branch2b\n",
      "53 bn3b_branch2b\n",
      "54 activation_113\n",
      "55 res3b_branch2c\n",
      "56 bn3b_branch2c\n",
      "57 add_37\n",
      "58 activation_114\n",
      "59 res3c_branch2a\n",
      "60 bn3c_branch2a\n",
      "61 activation_115\n",
      "62 res3c_branch2b\n",
      "63 bn3c_branch2b\n",
      "64 activation_116\n",
      "65 res3c_branch2c\n",
      "66 bn3c_branch2c\n",
      "67 add_38\n",
      "68 activation_117\n",
      "69 res3d_branch2a\n",
      "70 bn3d_branch2a\n",
      "71 activation_118\n",
      "72 res3d_branch2b\n",
      "73 bn3d_branch2b\n",
      "74 activation_119\n",
      "75 res3d_branch2c\n",
      "76 bn3d_branch2c\n",
      "77 add_39\n",
      "78 activation_120\n",
      "79 res4a_branch2a\n",
      "80 bn4a_branch2a\n",
      "81 activation_121\n",
      "82 res4a_branch2b\n",
      "83 bn4a_branch2b\n",
      "84 activation_122\n",
      "85 res4a_branch2c\n",
      "86 res4a_branch1\n",
      "87 bn4a_branch2c\n",
      "88 bn4a_branch1\n",
      "89 add_40\n",
      "90 activation_123\n",
      "91 res4b_branch2a\n",
      "92 bn4b_branch2a\n",
      "93 activation_124\n",
      "94 res4b_branch2b\n",
      "95 bn4b_branch2b\n",
      "96 activation_125\n",
      "97 res4b_branch2c\n",
      "98 bn4b_branch2c\n",
      "99 add_41\n",
      "100 activation_126\n",
      "101 res4c_branch2a\n",
      "102 bn4c_branch2a\n",
      "103 activation_127\n",
      "104 res4c_branch2b\n",
      "105 bn4c_branch2b\n",
      "106 activation_128\n",
      "107 res4c_branch2c\n",
      "108 bn4c_branch2c\n",
      "109 add_42\n",
      "110 activation_129\n",
      "111 res4d_branch2a\n",
      "112 bn4d_branch2a\n",
      "113 activation_130\n",
      "114 res4d_branch2b\n",
      "115 bn4d_branch2b\n",
      "116 activation_131\n",
      "117 res4d_branch2c\n",
      "118 bn4d_branch2c\n",
      "119 add_43\n",
      "120 activation_132\n",
      "121 res4e_branch2a\n",
      "122 bn4e_branch2a\n",
      "123 activation_133\n",
      "124 res4e_branch2b\n",
      "125 bn4e_branch2b\n",
      "126 activation_134\n",
      "127 res4e_branch2c\n",
      "128 bn4e_branch2c\n",
      "129 add_44\n",
      "130 activation_135\n",
      "131 res4f_branch2a\n",
      "132 bn4f_branch2a\n",
      "133 activation_136\n",
      "134 res4f_branch2b\n",
      "135 bn4f_branch2b\n",
      "136 activation_137\n",
      "137 res4f_branch2c\n",
      "138 bn4f_branch2c\n",
      "139 add_45\n",
      "140 activation_138\n",
      "141 res5a_branch2a\n",
      "142 bn5a_branch2a\n",
      "143 activation_139\n",
      "144 res5a_branch2b\n",
      "145 bn5a_branch2b\n",
      "146 activation_140\n",
      "147 res5a_branch2c\n",
      "148 res5a_branch1\n",
      "149 bn5a_branch2c\n",
      "150 bn5a_branch1\n",
      "151 add_46\n",
      "152 activation_141\n",
      "153 res5b_branch2a\n",
      "154 bn5b_branch2a\n",
      "155 activation_142\n",
      "156 res5b_branch2b\n",
      "157 bn5b_branch2b\n",
      "158 activation_143\n",
      "159 res5b_branch2c\n",
      "160 bn5b_branch2c\n",
      "161 add_47\n",
      "162 activation_144\n",
      "163 res5c_branch2a\n",
      "164 bn5c_branch2a\n",
      "165 activation_145\n",
      "166 res5c_branch2b\n",
      "167 bn5c_branch2b\n",
      "168 activation_146\n",
      "169 res5c_branch2c\n",
      "170 bn5c_branch2c\n",
      "171 add_48\n",
      "172 activation_147\n",
      "173 avg_pool\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda/lib/python3.5/site-packages/ipykernel_launcher.py:25: DeprecationWarning: `imresize` is deprecated!\n",
      "`imresize` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``skimage.transform.resize`` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step---------------------- {0}\n",
      "Epoch 1/1\n",
      "10/10 [==============================] - 13s 1s/step - loss: 0.6712 - acc: 0.8441 - val_loss: 3.7846 - val_acc: 0.2620\n",
      "Epoch 1/1\n",
      "11/11 [==============================] - 8s 732ms/step - loss: 0.2804 - acc: 0.9199 - val_loss: 8.7061 - val_acc: 0.2758\n",
      "Epoch 1/1\n",
      "12/12 [==============================] - 8s 689ms/step - loss: 0.1844 - acc: 0.9568 - val_loss: 12.2395 - val_acc: 0.1547\n",
      "Epoch 1/1\n",
      "12/12 [==============================] - 8s 695ms/step - loss: 0.5523 - acc: 0.8920 - val_loss: 13.4705 - val_acc: 0.1542\n",
      "Epoch 1/1\n",
      "14/14 [==============================] - 9s 656ms/step - loss: 2.8053 - acc: 0.4489 - val_loss: 1.1921e-07 - val_acc: 0.1109\n",
      "Epoch 1/1\n",
      "17/17 [==============================] - 10s 589ms/step - loss: 1.1687 - acc: 0.6324 - val_loss: 13.0634 - val_acc: 0.1033\n",
      "Epoch 1/1\n",
      "17/17 [==============================] - 10s 590ms/step - loss: 1.7060 - acc: 0.5549 - val_loss: 13.2177 - val_acc: 0.1010\n",
      "Epoch 1/1\n",
      "17/17 [==============================] - 10s 580ms/step - loss: 0.7089 - acc: 0.8010 - val_loss: 14.4825 - val_acc: 0.1015\n",
      "Epoch 1/1\n",
      "16/16 [==============================] - 10s 609ms/step - loss: 0.6717 - acc: 0.8182 - val_loss: 11.2092 - val_acc: 0.1726\n",
      "Epoch 1/1\n",
      "11/11 [==============================] - 8s 738ms/step - loss: 0.7783 - acc: 0.8156 - val_loss: 14.3816 - val_acc: 0.1055\n",
      "Epoch 1/1\n",
      "9/9 [==============================] - 7s 803ms/step - loss: 0.5586 - acc: 0.8535 - val_loss: 13.3904 - val_acc: 0.1278\n",
      "Epoch 1/1\n",
      "8/8 [==============================] - 7s 875ms/step - loss: 0.3821 - acc: 0.9035 - val_loss: 13.2991 - val_acc: 0.1207\n",
      "Epoch 1/1\n",
      "8/8 [==============================] - 7s 901ms/step - loss: 2.3037 - acc: 0.3887 - val_loss: 13.2014 - val_acc: 0.1046\n",
      "Epoch 1/1\n",
      "10/10 [==============================] - 8s 786ms/step - loss: 1.6615 - acc: 0.4281 - val_loss: 1.1921e-07 - val_acc: 0.1109\n",
      "Epoch 1/1\n",
      "11/11 [==============================] - 8s 733ms/step - loss: 2.0430 - acc: 0.5549 - val_loss: 11.7476 - val_acc: 0.1010\n",
      "Epoch 1/1\n",
      "14/14 [==============================] - 9s 653ms/step - loss: 0.7467 - acc: 0.7946 - val_loss: 11.4540 - val_acc: 0.0966\n",
      "Epoch 1/1\n",
      "11/11 [==============================] - 8s 723ms/step - loss: 0.8903 - acc: 0.7514 - val_loss: 14.3579 - val_acc: 0.0925\n",
      "Epoch 1/1\n",
      "13/13 [==============================] - 9s 680ms/step - loss: 0.7041 - acc: 0.7752 - val_loss: 5.5937 - val_acc: 0.1399\n",
      "Epoch 1/1\n",
      "10/10 [==============================] - 8s 762ms/step - loss: 1.5257 - acc: 0.5300 - val_loss: 11.9382 - val_acc: 0.1162\n",
      "Epoch 1/1\n",
      "11/11 [==============================] - 8s 724ms/step - loss: 0.6630 - acc: 0.7960 - val_loss: 9.0855 - val_acc: 0.1726\n",
      "Epoch 1/1\n",
      "11/11 [==============================] - 8s 744ms/step - loss: 0.8828 - acc: 0.7699 - val_loss: 7.8845 - val_acc: 0.1833\n",
      "Epoch 1/1\n",
      "11/11 [==============================] - 8s 746ms/step - loss: 0.6493 - acc: 0.7855 - val_loss: 12.3896 - val_acc: 0.0975\n",
      "Epoch 1/1\n",
      "14/14 [==============================] - 9s 645ms/step - loss: 0.7195 - acc: 0.7991 - val_loss: 12.8857 - val_acc: 0.1292\n",
      "Epoch 1/1\n",
      "4/4 [==============================] - 6s 1s/step - loss: 0.7772 - acc: 0.7037 - val_loss: 13.4128 - val_acc: 0.1055\n",
      "Epoch 1/1\n",
      "11/11 [==============================] - 8s 731ms/step - loss: 1.1663 - acc: 0.6832 - val_loss: 10.7532 - val_acc: 0.1681\n",
      "Epoch 1/1\n",
      "11/11 [==============================] - 8s 735ms/step - loss: 0.5191 - acc: 0.8379 - val_loss: 12.8869 - val_acc: 0.1064\n",
      "step---------------------- {1}\n",
      "Epoch 1/1\n",
      "10/10 [==============================] - 8s 766ms/step - loss: 0.6802 - acc: 0.8143 - val_loss: 14.4537 - val_acc: 0.1033\n",
      "Epoch 1/1\n",
      "11/11 [==============================] - 8s 737ms/step - loss: 0.8907 - acc: 0.7414 - val_loss: 14.4897 - val_acc: 0.1010\n",
      "Epoch 1/1\n",
      "12/12 [==============================] - 8s 689ms/step - loss: 0.2781 - acc: 0.9202 - val_loss: 14.4897 - val_acc: 0.1010\n",
      "Epoch 1/1\n",
      "12/12 [==============================] - 8s 697ms/step - loss: 0.7891 - acc: 0.7729 - val_loss: 14.4897 - val_acc: 0.1010\n",
      "Epoch 1/1\n",
      "14/14 [==============================] - 9s 654ms/step - loss: 0.3965 - acc: 0.8949 - val_loss: 11.8709 - val_acc: 0.1596\n",
      "Epoch 1/1\n",
      "17/17 [==============================] - 10s 590ms/step - loss: 0.4792 - acc: 0.8590 - val_loss: 9.6664 - val_acc: 0.2409\n",
      "Epoch 1/1\n",
      "17/17 [==============================] - 10s 591ms/step - loss: 0.2325 - acc: 0.9330 - val_loss: 8.3487 - val_acc: 0.3277\n",
      "Epoch 1/1\n",
      "17/17 [==============================] - 10s 597ms/step - loss: 0.1986 - acc: 0.9403 - val_loss: 14.4237 - val_acc: 0.1046\n",
      "Epoch 1/1\n",
      "16/16 [==============================] - 10s 611ms/step - loss: 0.3687 - acc: 0.8875 - val_loss: 9.5660 - val_acc: 0.2588\n",
      "Epoch 1/1\n",
      "11/11 [==============================] - 8s 739ms/step - loss: 0.2733 - acc: 0.9324 - val_loss: 7.5316 - val_acc: 0.2503\n",
      "Epoch 1/1\n",
      "9/9 [==============================] - 7s 815ms/step - loss: 0.2940 - acc: 0.9230 - val_loss: 6.8288 - val_acc: 0.2709\n",
      "Epoch 1/1\n",
      "8/8 [==============================] - 7s 904ms/step - loss: 0.6142 - acc: 0.7852 - val_loss: 6.5567 - val_acc: 0.3205\n",
      "Epoch 1/1\n",
      "8/8 [==============================] - 7s 881ms/step - loss: 0.3743 - acc: 0.8766 - val_loss: 9.8345 - val_acc: 0.2539\n",
      "Epoch 1/1\n",
      "10/10 [==============================] - 8s 766ms/step - loss: 0.2216 - acc: 0.9580 - val_loss: 9.8139 - val_acc: 0.2785\n",
      "Epoch 1/1\n",
      "11/11 [==============================] - 8s 735ms/step - loss: 0.4045 - acc: 0.8949 - val_loss: 13.1640 - val_acc: 0.1234\n",
      "Epoch 1/1\n",
      "14/14 [==============================] - 9s 657ms/step - loss: 0.8353 - acc: 0.7656 - val_loss: 13.7282 - val_acc: 0.1274\n",
      "Epoch 1/1\n",
      "11/11 [==============================] - 8s 721ms/step - loss: 1.7653 - acc: 0.5029 - val_loss: 9.8213 - val_acc: 0.1127\n",
      "Epoch 1/1\n",
      "13/13 [==============================] - 9s 682ms/step - loss: 0.8012 - acc: 0.7825 - val_loss: 14.4254 - val_acc: 0.1046\n",
      "Epoch 1/1\n",
      "10/10 [==============================] - 8s 756ms/step - loss: 0.3742 - acc: 0.9102 - val_loss: 13.3344 - val_acc: 0.1448\n",
      "Epoch 1/1\n",
      "11/11 [==============================] - 8s 726ms/step - loss: 0.4970 - acc: 0.8597 - val_loss: 13.1736 - val_acc: 0.1283\n",
      "Epoch 1/1\n",
      "11/11 [==============================] - 8s 730ms/step - loss: 1.7250 - acc: 0.5383 - val_loss: 14.3572 - val_acc: 0.0863\n",
      "Epoch 1/1\n",
      "11/11 [==============================] - 8s 735ms/step - loss: 0.4620 - acc: 0.8562 - val_loss: 14.4347 - val_acc: 0.0899\n",
      "Epoch 1/1\n",
      "14/14 [==============================] - 9s 645ms/step - loss: 0.7893 - acc: 0.7372 - val_loss: 11.8486 - val_acc: 0.1328\n",
      "Epoch 1/1\n",
      "4/4 [==============================] - 6s 1s/step - loss: 0.9746 - acc: 0.6482 - val_loss: 11.8189 - val_acc: 0.1363\n",
      "Epoch 1/1\n",
      "11/11 [==============================] - 8s 746ms/step - loss: 0.3936 - acc: 0.8892 - val_loss: 6.0256 - val_acc: 0.2928\n",
      "Epoch 1/1\n",
      "11/11 [==============================] - 8s 735ms/step - loss: 0.4192 - acc: 0.8806 - val_loss: 4.9780 - val_acc: 0.2570\n",
      "step---------------------- {2}\n",
      "Epoch 1/1\n",
      "10/10 [==============================] - 8s 763ms/step - loss: 0.2751 - acc: 0.9182 - val_loss: 7.5218 - val_acc: 0.2123\n",
      "Epoch 1/1\n",
      "11/11 [==============================] - 8s 736ms/step - loss: 0.5971 - acc: 0.8141 - val_loss: 9.8892 - val_acc: 0.2409\n",
      "Epoch 1/1\n",
      "12/12 [==============================] - 8s 693ms/step - loss: 1.5548 - acc: 0.6123 - val_loss: 9.8984 - val_acc: 0.1824\n",
      "Epoch 1/1\n",
      "12/12 [==============================] - 8s 696ms/step - loss: 0.5575 - acc: 0.8239 - val_loss: 10.1182 - val_acc: 0.1663\n",
      "Epoch 1/1\n",
      "14/14 [==============================] - 9s 655ms/step - loss: 0.3951 - acc: 0.9009 - val_loss: 7.3934 - val_acc: 0.3169\n",
      "Epoch 1/1\n",
      "17/17 [==============================] - 10s 590ms/step - loss: 0.4982 - acc: 0.8741 - val_loss: 9.6773 - val_acc: 0.2257\n",
      "Epoch 1/1\n",
      "17/17 [==============================] - 10s 591ms/step - loss: 0.8125 - acc: 0.7700 - val_loss: 6.2744 - val_acc: 0.3178\n",
      "Epoch 1/1\n",
      "17/17 [==============================] - 10s 587ms/step - loss: 0.2521 - acc: 0.9217 - val_loss: 7.2336 - val_acc: 0.3634\n",
      "Epoch 1/1\n",
      "16/16 [==============================] - 10s 610ms/step - loss: 0.8333 - acc: 0.7855 - val_loss: 5.8363 - val_acc: 0.3053\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 8s 741ms/step - loss: 0.2181 - acc: 0.9345 - val_loss: 4.6163 - val_acc: 0.4747\n",
      "Epoch 1/1\n",
      "9/9 [==============================] - 8s 841ms/step - loss: 0.3820 - acc: 0.9132 - val_loss: 5.2609 - val_acc: 0.3397\n",
      "Epoch 1/1\n",
      "8/8 [==============================] - 7s 901ms/step - loss: 0.1858 - acc: 0.9492 - val_loss: 7.1044 - val_acc: 0.3076\n",
      "Epoch 1/1\n",
      "8/8 [==============================] - 7s 879ms/step - loss: 0.2193 - acc: 0.9460 - val_loss: 7.4140 - val_acc: 0.3478\n",
      "Epoch 1/1\n",
      "10/10 [==============================] - 8s 758ms/step - loss: 0.2449 - acc: 0.9391 - val_loss: 7.5698 - val_acc: 0.3335\n",
      "Epoch 1/1\n",
      "11/11 [==============================] - 8s 738ms/step - loss: 0.7045 - acc: 0.7434 - val_loss: 10.9682 - val_acc: 0.1851\n",
      "Epoch 1/1\n",
      "14/14 [==============================] - 9s 640ms/step - loss: 0.1381 - acc: 0.9630 - val_loss: 5.4502 - val_acc: 0.3947\n",
      "Epoch 1/1\n",
      "11/11 [==============================] - 8s 724ms/step - loss: 1.3588 - acc: 0.6084 - val_loss: 3.3128 - val_acc: 0.5378\n",
      "Epoch 1/1\n",
      "13/13 [==============================] - 9s 682ms/step - loss: 0.4272 - acc: 0.8774 - val_loss: 3.3673 - val_acc: 0.5159\n",
      "Epoch 1/1\n",
      "10/10 [==============================] - 8s 764ms/step - loss: 0.2001 - acc: 0.9653 - val_loss: 2.2247 - val_acc: 0.5923\n",
      "Epoch 1/1\n",
      "11/11 [==============================] - 8s 745ms/step - loss: 1.0013 - acc: 0.7287 - val_loss: 4.5987 - val_acc: 0.3715\n",
      "Epoch 1/1\n",
      "11/11 [==============================] - 8s 733ms/step - loss: 1.0758 - acc: 0.6923 - val_loss: 3.8392 - val_acc: 0.4215\n",
      "Epoch 1/1\n",
      "11/11 [==============================] - 8s 732ms/step - loss: 1.0851 - acc: 0.6786 - val_loss: 2.2026 - val_acc: 0.4671\n",
      "Epoch 1/1\n",
      "14/14 [==============================] - 9s 642ms/step - loss: 0.9655 - acc: 0.6963 - val_loss: 3.6887 - val_acc: 0.3420\n",
      "Epoch 1/1\n",
      "4/4 [==============================] - 6s 1s/step - loss: 1.5028 - acc: 0.4892 - val_loss: 3.1905 - val_acc: 0.4108\n",
      "Epoch 1/1\n",
      "11/11 [==============================] - 8s 725ms/step - loss: 0.4451 - acc: 0.8570 - val_loss: 4.3060 - val_acc: 0.3402\n",
      "Epoch 1/1\n",
      "11/11 [==============================] - 8s 726ms/step - loss: 0.3482 - acc: 0.8904 - val_loss: 1.5049 - val_acc: 0.5606\n",
      "step---------------------- {3}\n",
      "Epoch 1/1\n",
      "10/10 [==============================] - 8s 756ms/step - loss: 0.9356 - acc: 0.7124 - val_loss: 3.0547 - val_acc: 0.2861\n",
      "Epoch 1/1\n",
      "11/11 [==============================] - 8s 738ms/step - loss: 0.4567 - acc: 0.8682 - val_loss: 3.9169 - val_acc: 0.3076\n",
      "Epoch 1/1\n",
      "12/12 [==============================] - 8s 691ms/step - loss: 0.2410 - acc: 0.9398 - val_loss: 6.3631 - val_acc: 0.2356\n",
      "Epoch 1/1\n",
      "12/12 [==============================] - 8s 695ms/step - loss: 0.3747 - acc: 0.8781 - val_loss: 4.0818 - val_acc: 0.3746\n",
      "Epoch 1/1\n",
      "14/14 [==============================] - 9s 656ms/step - loss: 0.3550 - acc: 0.8983 - val_loss: 1.8227 - val_acc: 0.6147\n",
      "Epoch 1/1\n",
      "17/17 [==============================] - 10s 590ms/step - loss: 0.3622 - acc: 0.9003 - val_loss: 4.0444 - val_acc: 0.4211\n",
      "Epoch 1/1\n",
      "17/17 [==============================] - 10s 590ms/step - loss: 0.1860 - acc: 0.9521 - val_loss: 5.0789 - val_acc: 0.4166\n",
      "Epoch 1/1\n",
      "17/17 [==============================] - 10s 587ms/step - loss: 0.1260 - acc: 0.9624 - val_loss: 8.8552 - val_acc: 0.2526\n",
      "Epoch 1/1\n",
      "16/16 [==============================] - 10s 609ms/step - loss: 0.5722 - acc: 0.8404 - val_loss: 5.7861 - val_acc: 0.3348\n",
      "Epoch 1/1\n",
      "11/11 [==============================] - 8s 740ms/step - loss: 0.1060 - acc: 0.9768 - val_loss: 2.3318 - val_acc: 0.5892\n",
      "Epoch 1/1\n",
      "9/9 [==============================] - 7s 816ms/step - loss: 0.1551 - acc: 0.9318 - val_loss: 1.4551 - val_acc: 0.6477\n",
      "Epoch 1/1\n",
      "8/8 [==============================] - 7s 876ms/step - loss: 0.0925 - acc: 0.9808 - val_loss: 1.3295 - val_acc: 0.6679\n",
      "Epoch 1/1\n",
      "8/8 [==============================] - 7s 882ms/step - loss: 0.5945 - acc: 0.8048 - val_loss: 1.8666 - val_acc: 0.5910\n",
      "Epoch 1/1\n",
      "10/10 [==============================] - 8s 767ms/step - loss: 0.1614 - acc: 0.9663 - val_loss: 2.7149 - val_acc: 0.4993\n",
      "Epoch 1/1\n",
      "11/11 [==============================] - 8s 737ms/step - loss: 0.2330 - acc: 0.9295 - val_loss: 2.1882 - val_acc: 0.5302\n",
      "Epoch 1/1\n",
      "14/14 [==============================] - 9s 640ms/step - loss: 0.0797 - acc: 0.9787 - val_loss: 2.5494 - val_acc: 0.5275\n",
      "Epoch 1/1\n",
      "11/11 [==============================] - 8s 748ms/step - loss: 0.4910 - acc: 0.8622 - val_loss: 1.5259 - val_acc: 0.6723\n",
      "Epoch 1/1\n",
      "13/13 [==============================] - 9s 681ms/step - loss: 0.2128 - acc: 0.9435 - val_loss: 1.3643 - val_acc: 0.7103\n",
      "Epoch 1/1\n",
      "10/10 [==============================] - 8s 786ms/step - loss: 0.0960 - acc: 0.9844 - val_loss: 1.0169 - val_acc: 0.7354\n",
      "Epoch 1/1\n",
      "11/11 [==============================] - 8s 719ms/step - loss: 0.2292 - acc: 0.9297 - val_loss: 0.9728 - val_acc: 0.7461\n",
      "Epoch 1/1\n",
      "11/11 [==============================] - 8s 731ms/step - loss: 0.2270 - acc: 0.9406 - val_loss: 1.5240 - val_acc: 0.6764\n",
      "Epoch 1/1\n",
      "11/11 [==============================] - 8s 731ms/step - loss: 0.2074 - acc: 0.9430 - val_loss: 0.9725 - val_acc: 0.7278\n",
      "Epoch 1/1\n",
      "14/14 [==============================] - 9s 645ms/step - loss: 0.2052 - acc: 0.9402 - val_loss: 0.8259 - val_acc: 0.7662\n",
      "Epoch 1/1\n",
      "4/4 [==============================] - 6s 1s/step - loss: 0.5015 - acc: 0.8071 - val_loss: 0.9328 - val_acc: 0.7492\n",
      "Epoch 1/1\n",
      "11/11 [==============================] - 8s 724ms/step - loss: 0.1916 - acc: 0.9557 - val_loss: 1.1461 - val_acc: 0.7291\n",
      "Epoch 1/1\n",
      "11/11 [==============================] - 8s 727ms/step - loss: 0.0960 - acc: 0.9746 - val_loss: 1.3418 - val_acc: 0.6790\n",
      "step---------------------- {4}\n",
      "Epoch 1/1\n",
      "10/10 [==============================] - 8s 764ms/step - loss: 0.1274 - acc: 0.9575 - val_loss: 1.1622 - val_acc: 0.7072\n",
      "Epoch 1/1\n",
      "11/11 [==============================] - 8s 737ms/step - loss: 0.2548 - acc: 0.9183 - val_loss: 0.8734 - val_acc: 0.7170\n",
      "Epoch 1/1\n",
      "12/12 [==============================] - 9s 711ms/step - loss: 0.1352 - acc: 0.9674 - val_loss: 1.6785 - val_acc: 0.6424\n",
      "Epoch 1/1\n",
      "12/12 [==============================] - 8s 689ms/step - loss: 0.1660 - acc: 0.9450 - val_loss: 2.7699 - val_acc: 0.5136\n",
      "Epoch 1/1\n",
      "14/14 [==============================] - 9s 654ms/step - loss: 0.0850 - acc: 0.9709 - val_loss: 4.7429 - val_acc: 0.3013\n",
      "Epoch 1/1\n",
      "17/17 [==============================] - 10s 591ms/step - loss: 0.1666 - acc: 0.9533 - val_loss: 1.6032 - val_acc: 0.5986\n",
      "Epoch 1/1\n",
      "17/17 [==============================] - 10s 591ms/step - loss: 0.0657 - acc: 0.9827 - val_loss: 0.8705 - val_acc: 0.7684\n",
      "Epoch 1/1\n",
      "17/17 [==============================] - 10s 588ms/step - loss: 0.0785 - acc: 0.9788 - val_loss: 1.2536 - val_acc: 0.7219\n",
      "Epoch 1/1\n",
      "16/16 [==============================] - 10s 610ms/step - loss: 0.5101 - acc: 0.8543 - val_loss: 1.7514 - val_acc: 0.6437\n",
      "Epoch 1/1\n",
      "11/11 [==============================] - 8s 738ms/step - loss: 0.1257 - acc: 0.9626 - val_loss: 0.9102 - val_acc: 0.7881\n",
      "Epoch 1/1\n",
      "9/9 [==============================] - 7s 816ms/step - loss: 0.0708 - acc: 0.9843 - val_loss: 1.2210 - val_acc: 0.7050\n",
      "Epoch 1/1\n",
      "8/8 [==============================] - 7s 884ms/step - loss: 0.6470 - acc: 0.7806 - val_loss: 4.6621 - val_acc: 0.2803\n",
      "Epoch 1/1\n",
      "8/8 [==============================] - 7s 884ms/step - loss: 0.1843 - acc: 0.9547 - val_loss: 10.0753 - val_acc: 0.1694\n",
      "Epoch 1/1\n",
      "10/10 [==============================] - 8s 764ms/step - loss: 0.6417 - acc: 0.8006 - val_loss: 8.0248 - val_acc: 0.3053\n",
      "Epoch 1/1\n",
      "11/11 [==============================] - 8s 739ms/step - loss: 0.2261 - acc: 0.9396 - val_loss: 8.9687 - val_acc: 0.3013\n",
      "Epoch 1/1\n",
      "14/14 [==============================] - 9s 640ms/step - loss: 0.0762 - acc: 0.9810 - val_loss: 9.0422 - val_acc: 0.2687\n",
      "Epoch 1/1\n",
      "11/11 [==============================] - 8s 745ms/step - loss: 0.2083 - acc: 0.9332 - val_loss: 6.6956 - val_acc: 0.3643\n",
      "Epoch 1/1\n",
      "13/13 [==============================] - 9s 681ms/step - loss: 0.1801 - acc: 0.9519 - val_loss: 5.0824 - val_acc: 0.4792\n",
      "Epoch 1/1\n",
      "10/10 [==============================] - 8s 763ms/step - loss: 0.5620 - acc: 0.8094 - val_loss: 3.5043 - val_acc: 0.5002\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 8s 747ms/step - loss: 0.7654 - acc: 0.7727 - val_loss: 9.7484 - val_acc: 0.1404\n",
      "Epoch 1/1\n",
      "11/11 [==============================] - 8s 730ms/step - loss: 0.2146 - acc: 0.9456 - val_loss: 10.0870 - val_acc: 0.1730\n",
      "Epoch 1/1\n",
      "11/11 [==============================] - 8s 732ms/step - loss: 0.2001 - acc: 0.9345 - val_loss: 5.1849 - val_acc: 0.4189\n",
      "Epoch 1/1\n",
      "14/14 [==============================] - 9s 643ms/step - loss: 0.1595 - acc: 0.9522 - val_loss: 3.1306 - val_acc: 0.5306\n",
      "Epoch 1/1\n",
      "4/4 [==============================] - 6s 1s/step - loss: 0.2668 - acc: 0.9199 - val_loss: 2.2319 - val_acc: 0.5874\n",
      "Epoch 1/1\n",
      "11/11 [==============================] - 8s 733ms/step - loss: 0.1688 - acc: 0.9528 - val_loss: 0.9890 - val_acc: 0.7076\n",
      "Epoch 1/1\n",
      "11/11 [==============================] - 8s 733ms/step - loss: 0.0856 - acc: 0.9759 - val_loss: 0.8879 - val_acc: 0.7215\n",
      "step---------------------- {5}\n",
      "Epoch 1/1\n",
      "10/10 [==============================] - 8s 766ms/step - loss: 0.8882 - acc: 0.7281 - val_loss: 3.2238 - val_acc: 0.4555\n",
      "last model loss ------------------------------------------3.223843\n",
      "Epoch 1/1\n",
      "11/11 [==============================] - 8s 739ms/step - loss: 0.4219 - acc: 0.8733 - val_loss: 11.0833 - val_acc: 0.1636\n",
      "Epoch 1/1\n",
      "12/12 [==============================] - 8s 689ms/step - loss: 0.1607 - acc: 0.9568 - val_loss: 3.8918 - val_acc: 0.4524\n",
      "Epoch 1/1\n",
      "12/12 [==============================] - 8s 691ms/step - loss: 0.2114 - acc: 0.9266 - val_loss: 2.5551 - val_acc: 0.5373\n",
      "last model loss ------------------------------------------2.555144\n",
      "Epoch 1/1\n",
      "14/14 [==============================] - 9s 654ms/step - loss: 0.1156 - acc: 0.9731 - val_loss: 4.1200 - val_acc: 0.4144\n",
      "Epoch 1/1\n",
      "17/17 [==============================] - 10s 597ms/step - loss: 0.5665 - acc: 0.8382 - val_loss: 9.0941 - val_acc: 0.2047\n",
      "Epoch 1/1\n",
      "17/17 [==============================] - 10s 590ms/step - loss: 0.1143 - acc: 0.9751 - val_loss: 5.2115 - val_acc: 0.3625\n",
      "Epoch 1/1\n",
      "17/17 [==============================] - 10s 586ms/step - loss: 0.0725 - acc: 0.9843 - val_loss: 2.1756 - val_acc: 0.6044\n",
      "last model loss ------------------------------------------2.175571\n",
      "Epoch 1/1\n",
      "16/16 [==============================] - 10s 609ms/step - loss: 0.1008 - acc: 0.9700 - val_loss: 1.3979 - val_acc: 0.6898\n",
      "last model loss ------------------------------------------1.397933\n",
      "Epoch 1/1\n",
      "11/11 [==============================] - 8s 744ms/step - loss: 0.0531 - acc: 0.9844 - val_loss: 1.2582 - val_acc: 0.7349\n",
      "last model loss ------------------------------------------1.258201\n",
      "Epoch 1/1\n",
      "9/9 [==============================] - 7s 815ms/step - loss: 0.2184 - acc: 0.9389 - val_loss: 1.9395 - val_acc: 0.6348\n",
      "Epoch 1/1\n",
      "8/8 [==============================] - 7s 885ms/step - loss: 0.0866 - acc: 0.9747 - val_loss: 1.0909 - val_acc: 0.7474\n",
      "last model loss ------------------------------------------1.090886\n",
      "Epoch 1/1\n",
      "8/8 [==============================] - 7s 881ms/step - loss: 0.0343 - acc: 0.9941 - val_loss: 1.5109 - val_acc: 0.6983\n",
      "Epoch 1/1\n",
      "10/10 [==============================] - 8s 784ms/step - loss: 0.0570 - acc: 0.9828 - val_loss: 2.2034 - val_acc: 0.6089\n",
      "Epoch 1/1\n",
      "11/11 [==============================] - 8s 736ms/step - loss: 0.1397 - acc: 0.9644 - val_loss: 3.0949 - val_acc: 0.5221\n",
      "Epoch 1/1\n",
      "14/14 [==============================] - 9s 637ms/step - loss: 0.0530 - acc: 0.9831 - val_loss: 4.4930 - val_acc: 0.4296\n",
      "Epoch 1/1\n",
      "11/11 [==============================] - 8s 720ms/step - loss: 0.2024 - acc: 0.9528 - val_loss: 4.6963 - val_acc: 0.3692\n",
      "Epoch 1/1\n",
      "13/13 [==============================] - 9s 682ms/step - loss: 0.1117 - acc: 0.9760 - val_loss: 2.9563 - val_acc: 0.4841\n",
      "Epoch 1/1\n",
      "10/10 [==============================] - 8s 762ms/step - loss: 0.4132 - acc: 0.8691 - val_loss: 6.5494 - val_acc: 0.3008\n",
      "Epoch 1/1\n",
      "11/11 [==============================] - 8s 721ms/step - loss: 0.3194 - acc: 0.9114 - val_loss: 2.3153 - val_acc: 0.6437\n",
      "Epoch 1/1\n",
      "11/11 [==============================] - 8s 732ms/step - loss: 0.1843 - acc: 0.9428 - val_loss: 5.1245 - val_acc: 0.4207\n",
      "Epoch 1/1\n",
      "11/11 [==============================] - 8s 735ms/step - loss: 0.4433 - acc: 0.8703 - val_loss: 3.9971 - val_acc: 0.4819\n",
      "Epoch 1/1\n",
      "14/14 [==============================] - 9s 643ms/step - loss: 0.7299 - acc: 0.7590 - val_loss: 4.9627 - val_acc: 0.3853\n",
      "Epoch 1/1\n",
      "4/4 [==============================] - 6s 1s/step - loss: 0.5142 - acc: 0.8228 - val_loss: 7.0429 - val_acc: 0.3312\n",
      "Epoch 1/1\n",
      "11/11 [==============================] - 8s 732ms/step - loss: 1.0518 - acc: 0.6902 - val_loss: 2.3160 - val_acc: 0.4743\n",
      "Epoch 1/1\n",
      "11/11 [==============================] - 8s 734ms/step - loss: 0.2022 - acc: 0.9444 - val_loss: 2.7102 - val_acc: 0.4515\n",
      "step---------------------- {6}\n",
      "Epoch 1/1\n",
      "10/10 [==============================] - 8s 763ms/step - loss: 0.4153 - acc: 0.8994 - val_loss: 1.5191 - val_acc: 0.5655\n",
      "Epoch 1/1\n",
      "11/11 [==============================] - 8s 734ms/step - loss: 0.3627 - acc: 0.9038 - val_loss: 2.4565 - val_acc: 0.6142\n",
      "Epoch 1/1\n",
      "12/12 [==============================] - 8s 685ms/step - loss: 0.1095 - acc: 0.9764 - val_loss: 1.5839 - val_acc: 0.7121\n",
      "Epoch 1/1\n",
      "12/12 [==============================] - 8s 695ms/step - loss: 0.1596 - acc: 0.9418 - val_loss: 1.0004 - val_acc: 0.7564\n",
      "last model loss ------------------------------------------1.000373\n",
      "Epoch 1/1\n",
      "14/14 [==============================] - 9s 655ms/step - loss: 0.0994 - acc: 0.9729 - val_loss: 1.5110 - val_acc: 0.6938\n",
      "Epoch 1/1\n",
      "17/17 [==============================] - 10s 589ms/step - loss: 0.1554 - acc: 0.9587 - val_loss: 1.5007 - val_acc: 0.6764\n",
      "Epoch 1/1\n",
      "17/17 [==============================] - 10s 585ms/step - loss: 0.2502 - acc: 0.9330 - val_loss: 3.6180 - val_acc: 0.4430\n",
      "Epoch 1/1\n",
      "17/17 [==============================] - 10s 585ms/step - loss: 0.0680 - acc: 0.9853 - val_loss: 0.8336 - val_acc: 0.7823\n",
      "last model loss ------------------------------------------0.833645\n",
      "Epoch 1/1\n",
      "16/16 [==============================] - 10s 610ms/step - loss: 0.0804 - acc: 0.9772 - val_loss: 1.5629 - val_acc: 0.6692\n",
      "Epoch 1/1\n",
      "11/11 [==============================] - 8s 740ms/step - loss: 0.0464 - acc: 0.9900 - val_loss: 0.9714 - val_acc: 0.7868\n",
      "Epoch 1/1\n",
      "9/9 [==============================] - 7s 816ms/step - loss: 0.0598 - acc: 0.9842 - val_loss: 0.7357 - val_acc: 0.8234\n",
      "last model loss ------------------------------------------0.735669\n",
      "Epoch 1/1\n",
      "8/8 [==============================] - 7s 882ms/step - loss: 0.0421 - acc: 0.9884 - val_loss: 0.6478 - val_acc: 0.8297\n",
      "last model loss ------------------------------------------0.647845\n",
      "Epoch 1/1\n",
      "8/8 [==============================] - 7s 872ms/step - loss: 0.0156 - acc: 1.0000 - val_loss: 0.6012 - val_acc: 0.8440\n",
      "last model loss ------------------------------------------0.601189\n",
      "Epoch 1/1\n",
      "10/10 [==============================] - 8s 764ms/step - loss: 0.0838 - acc: 0.9863 - val_loss: 0.6609 - val_acc: 0.8207\n",
      "Epoch 1/1\n",
      "11/11 [==============================] - 8s 738ms/step - loss: 0.1225 - acc: 0.9709 - val_loss: 0.5691 - val_acc: 0.8386\n",
      "last model loss ------------------------------------------0.569099\n",
      "Epoch 1/1\n",
      "14/14 [==============================] - 9s 639ms/step - loss: 0.0186 - acc: 0.9978 - val_loss: 0.7216 - val_acc: 0.7886\n",
      "Epoch 1/1\n",
      "11/11 [==============================] - 8s 722ms/step - loss: 0.5802 - acc: 0.8216 - val_loss: 4.8708 - val_acc: 0.4247\n",
      "Epoch 1/1\n",
      "13/13 [==============================] - 9s 681ms/step - loss: 0.1424 - acc: 0.9663 - val_loss: 3.5689 - val_acc: 0.4850\n",
      "Epoch 1/1\n",
      "10/10 [==============================] - 8s 763ms/step - loss: 0.0659 - acc: 0.9858 - val_loss: 2.1214 - val_acc: 0.5776\n",
      "Epoch 1/1\n",
      "11/11 [==============================] - 8s 724ms/step - loss: 0.2824 - acc: 0.9005 - val_loss: 0.8736 - val_acc: 0.7599\n",
      "Epoch 1/1\n",
      "11/11 [==============================] - 8s 730ms/step - loss: 0.1366 - acc: 0.9626 - val_loss: 0.7160 - val_acc: 0.8064\n",
      "Epoch 1/1\n",
      "11/11 [==============================] - 8s 725ms/step - loss: 0.5047 - acc: 0.8378 - val_loss: 0.8863 - val_acc: 0.7331\n",
      "Epoch 1/1\n",
      "14/14 [==============================] - 9s 644ms/step - loss: 0.1369 - acc: 0.9638 - val_loss: 0.5896 - val_acc: 0.8319\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 6s 1s/step - loss: 0.2469 - acc: 0.9052 - val_loss: 0.8640 - val_acc: 0.7895\n",
      "Epoch 1/1\n",
      "11/11 [==============================] - 8s 732ms/step - loss: 0.1471 - acc: 0.9686 - val_loss: 0.9923 - val_acc: 0.7591\n",
      "Epoch 1/1\n",
      "11/11 [==============================] - 8s 732ms/step - loss: 0.1070 - acc: 0.9716 - val_loss: 0.6990 - val_acc: 0.8122\n",
      "step---------------------- {7}\n",
      "Epoch 1/1\n",
      "10/10 [==============================] - 8s 764ms/step - loss: 0.0753 - acc: 0.9780 - val_loss: 0.6984 - val_acc: 0.8069\n",
      "Epoch 1/1\n",
      "11/11 [==============================] - 8s 736ms/step - loss: 0.1089 - acc: 0.9724 - val_loss: 0.7791 - val_acc: 0.7903\n",
      "Epoch 1/1\n",
      "12/12 [==============================] - 9s 709ms/step - loss: 0.4487 - acc: 0.8776 - val_loss: 6.7804 - val_acc: 0.3000\n",
      "Epoch 1/1\n",
      "12/12 [==============================] - 8s 697ms/step - loss: 0.2062 - acc: 0.9418 - val_loss: 4.9632 - val_acc: 0.3661\n",
      "Epoch 1/1\n",
      "14/14 [==============================] - 9s 654ms/step - loss: 0.0794 - acc: 0.9832 - val_loss: 3.0004 - val_acc: 0.5096\n",
      "Epoch 1/1\n",
      "17/17 [==============================] - 10s 596ms/step - loss: 0.1127 - acc: 0.9642 - val_loss: 6.5135 - val_acc: 0.3165\n",
      "Epoch 1/1\n",
      "17/17 [==============================] - 10s 591ms/step - loss: 0.0305 - acc: 0.9892 - val_loss: 1.8779 - val_acc: 0.6504\n",
      "Epoch 1/1\n",
      "17/17 [==============================] - 10s 586ms/step - loss: 0.0287 - acc: 0.9954 - val_loss: 1.9743 - val_acc: 0.6415\n",
      "Epoch 1/1\n",
      "16/16 [==============================] - 10s 610ms/step - loss: 0.0448 - acc: 0.9902 - val_loss: 0.8867 - val_acc: 0.7819\n",
      "Epoch 1/1\n",
      "11/11 [==============================] - 8s 741ms/step - loss: 0.0499 - acc: 0.9897 - val_loss: 0.4875 - val_acc: 0.8695\n",
      "last model loss ------------------------------------------0.487466\n",
      "Epoch 1/1\n",
      "9/9 [==============================] - 7s 813ms/step - loss: 0.0160 - acc: 0.9982 - val_loss: 0.4564 - val_acc: 0.8753\n",
      "last model loss ------------------------------------------0.456445\n",
      "Epoch 1/1\n",
      "8/8 [==============================] - 7s 887ms/step - loss: 0.0202 - acc: 0.9921 - val_loss: 0.3955 - val_acc: 0.8909\n",
      "last model loss ------------------------------------------0.395518\n",
      "Epoch 1/1\n",
      "8/8 [==============================] - 7s 880ms/step - loss: 0.0749 - acc: 0.9817 - val_loss: 0.3189 - val_acc: 0.9106\n",
      "last model loss ------------------------------------------0.318873\n",
      "Epoch 1/1\n",
      "10/10 [==============================] - 8s 787ms/step - loss: 0.0571 - acc: 0.9859 - val_loss: 0.3872 - val_acc: 0.8981\n",
      "Epoch 1/1\n",
      "11/11 [==============================] - 8s 738ms/step - loss: 0.5076 - acc: 0.8334 - val_loss: 5.9576 - val_acc: 0.3603\n",
      "Epoch 1/1\n",
      "14/14 [==============================] - 9s 641ms/step - loss: 0.0661 - acc: 0.9843 - val_loss: 7.9615 - val_acc: 0.3286\n",
      "Epoch 1/1\n",
      "11/11 [==============================] - 8s 721ms/step - loss: 0.2467 - acc: 0.8908 - val_loss: 2.0743 - val_acc: 0.6290\n",
      "Epoch 1/1\n",
      "13/13 [==============================] - 9s 681ms/step - loss: 0.1117 - acc: 0.9712 - val_loss: 1.6433 - val_acc: 0.6460\n",
      "Epoch 1/1\n",
      "10/10 [==============================] - 8s 757ms/step - loss: 0.0559 - acc: 0.9827 - val_loss: 1.4106 - val_acc: 0.6723\n",
      "Epoch 1/1\n",
      "11/11 [==============================] - 8s 723ms/step - loss: 0.1391 - acc: 0.9634 - val_loss: 2.9144 - val_acc: 0.5646\n",
      "Epoch 1/1\n",
      "11/11 [==============================] - 8s 727ms/step - loss: 0.0703 - acc: 0.9756 - val_loss: 9.5564 - val_acc: 0.2293\n",
      "Epoch 1/1\n",
      "11/11 [==============================] - 8s 732ms/step - loss: 0.0653 - acc: 0.9859 - val_loss: 2.6183 - val_acc: 0.5963\n",
      "Epoch 1/1\n",
      "14/14 [==============================] - 9s 644ms/step - loss: 0.0757 - acc: 0.9720 - val_loss: 0.8074 - val_acc: 0.7868\n",
      "Epoch 1/1\n",
      "4/4 [==============================] - 6s 1s/step - loss: 0.1429 - acc: 0.9531 - val_loss: 0.7760 - val_acc: 0.7819\n",
      "Epoch 1/1\n",
      "11/11 [==============================] - 8s 731ms/step - loss: 0.6425 - acc: 0.8245 - val_loss: 1.6834 - val_acc: 0.6375\n",
      "Epoch 1/1\n",
      "11/11 [==============================] - 8s 755ms/step - loss: 0.5744 - acc: 0.8453 - val_loss: 1.2488 - val_acc: 0.6911\n",
      "step---------------------- {8}\n",
      "Epoch 1/1\n",
      "10/10 [==============================] - 8s 795ms/step - loss: 0.1158 - acc: 0.9686 - val_loss: 1.2044 - val_acc: 0.7068\n"
     ]
    }
   ],
   "source": [
    "model = train_model_2(restNet_model)\n",
    "test_model(model, 'pred.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = train_model(restNet_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_model(model, 'pred.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_model_2(model, 'pred.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = train_model(restNet_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_model(model, 'pred.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
