{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import *\n",
    "from keras.layers import *\n",
    "from keras.applications import *\n",
    "from keras.preprocessing.image import *\n",
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "import numpy as np\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import applications\n",
    "def vgg16Model(image_size = (224, 224), if_draw_model = False):\n",
    "    width = image_size[0]\n",
    "    height = image_size[1]\n",
    "    \n",
    "    base_model = applications.VGG16(input_tensor=Input((height, width, 3)), weights='imagenet', include_top=False)\n",
    "\n",
    "    for layers in base_model.layers:\n",
    "        layers.trainable = True\n",
    "        \n",
    "    for i, layer in enumerate(base_model.layers):\n",
    "        print(i, layer.name)\n",
    "        \n",
    "   # for layer in base_model.layers[25:]:\n",
    "   #     layer.trainable = True\n",
    "\n",
    "    x = GlobalAveragePooling2D()(base_model.output)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = Dense(10, activation='sigmoid')(x)\n",
    "    model = Model(base_model.input, x)\n",
    "    \n",
    "    if if_draw_model:\n",
    "        SVG(model_to_dot(model).create(prog='dot', format='svg'))\n",
    "    \n",
    "    model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications.resnet50 import ResNet50\n",
    "from keras.applications.resnet50 import preprocess_input, decode_predictions\n",
    "import numpy as np\n",
    "\n",
    "def restNet_model(image_size = (224, 224), if_draw_model = False):\n",
    "\n",
    "    width = image_size[0]\n",
    "    height = image_size[1]\n",
    "    \n",
    "    base_model = ResNet50(input_tensor=Input((height, width, 3)), weights='imagenet', include_top=False)\n",
    "\n",
    "    for layers in base_model.layers:\n",
    "        layers.trainable = True\n",
    "        \n",
    "    for i, layer in enumerate(base_model.layers):\n",
    "        print(i, layer.name)\n",
    "        \n",
    "   # for layer in base_model.layers[25:]:\n",
    "   #     layer.trainable = True\n",
    "\n",
    "    x = GlobalAveragePooling2D()(base_model.output)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = Dense(10, activation='sigmoid')(x)\n",
    "    model = Model(base_model.input, x)\n",
    "    \n",
    "    if if_draw_model:\n",
    "        SVG(model_to_dot(model).create(prog='dot', format='svg'))\n",
    "    \n",
    "    model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.applications.inception_v3 import preprocess_input, decode_predictions\n",
    "import numpy as np\n",
    "\n",
    "def inceptionV3_model(image_size = (224, 224), if_draw_model = False):\n",
    "\n",
    "    width = image_size[0]\n",
    "    height = image_size[1]\n",
    "    \n",
    "    base_model = InceptionV3(input_tensor=Input((height, width, 3)), weights='imagenet', include_top=False)\n",
    "\n",
    "    for layers in base_model.layers:\n",
    "        layers.trainable = True\n",
    "        \n",
    "    for i, layer in enumerate(base_model.layers):\n",
    "        print(i, layer.name)\n",
    "        \n",
    "   # for layer in base_model.layers[25:]:\n",
    "   #     layer.trainable = True\n",
    "\n",
    "    x = GlobalAveragePooling2D()(base_model.output)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = Dense(10, activation='sigmoid')(x)\n",
    "    model = Model(base_model.input, x)\n",
    "    \n",
    "    if if_draw_model:\n",
    "        SVG(model_to_dot(model).create(prog='dot', format='svg'))\n",
    "    \n",
    "    model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#简单模型\n",
    "def simple_model(time_len=1):\n",
    "    ch, row, col = 3, 66, 200  # camera format\n",
    "    model = Sequential()\n",
    "    model.add(Lambda(lambda x: x/127.5 - 1.,\n",
    "  #  model.add(Lambda(lambda x: x,\n",
    "            input_shape=( row, col, ch),\n",
    "            output_shape=( row, col,ch)))\n",
    "    model.add(Convolution2D(3, 3, 3, subsample=(2, 2), border_mode=\"same\"))\n",
    "    model.add(ELU())\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    model.add(Dropout(.5))\n",
    "    model.add(ELU())\n",
    "    model.add(Dense(10))\n",
    "#  model.add(Lambda(nor_output_1))\n",
    "    sgd = optimizers.SGD(lr=0.00003, momentum=0.9, nesterov=True)\n",
    "    model.compile(loss='mean_squared_error', optimizer=sgd)\n",
    "\n",
    "      \n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "from sklearn.utils import shuffle\n",
    "np.random.seed(2017)\n",
    "\n",
    "def prepare_val():\n",
    "    dirname = 'imgs/val'\n",
    "    dirname_src = 'imgs/train/'\n",
    "    if os.path.exists(dirname):\n",
    "        return\n",
    "    os.mkdir(dirname)\n",
    "    sub_dirs = ['c0', 'c1', 'c2', 'c3', 'c4', 'c5', 'c6', 'c7', 'c8', 'c9']\n",
    "    for sub_dir in sub_dirs:\n",
    "        address_des = dirname + '/' + sub_dir\n",
    "        os.mkdir(address_des)\n",
    "        \n",
    "        address_src = dirname_src + '/' + sub_dir\n",
    "        train_filenames = os.listdir(address_src)\n",
    "        train_filenames = shuffle(train_filenames)\n",
    "        for file_src in train_filenames[0: int(len(train_filenames) / 10)]:\n",
    "            add_con_list = file_src.split('/')\n",
    "            add_old = dirname_src + sub_dir + '/' + add_con_list[-1]\n",
    "            add_new = dirname + '/' + sub_dir + '/' + add_con_list[-1]\n",
    "         #   print(add_old)\n",
    "         #   print(add_new)\n",
    "            shutil.move(add_old, add_new)  \n",
    "        \n",
    "prepare_val()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import pandas as pd\n",
    "import cv2\n",
    "from sklearn.utils import shuffle\n",
    "np.random.seed(2017)\n",
    "\n",
    "def get_driver_list():\n",
    "    driver_id_list = []\n",
    "    df = pd.read_csv(\"driver_imgs_list.csv\")\n",
    "    for i in range(df.shape[0]):\n",
    "        driver_id = df.loc[i][\"subject\"]\n",
    "        is_saved_id = False\n",
    "        for saved_id in driver_id_list:\n",
    "            if saved_id == driver_id:\n",
    "                is_saved_id = True\n",
    "                break\n",
    "        \n",
    "        if is_saved_id == False:\n",
    "            driver_id_list.append(driver_id)\n",
    "    return driver_id_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def prepare_data():\n",
    "    dirbase = 'imgs/train2/'\n",
    "    if os.path.exists(dirbase):\n",
    "        return\n",
    "    os.mkdir(dirbase)\n",
    "        \n",
    "    driver_id_list = get_driver_list()\n",
    "    \n",
    "    df = pd.read_csv(\"driver_imgs_list.csv\")  \n",
    "    sub_dirs = ['c0', 'c1', 'c2', 'c3', 'c4', 'c5', 'c6', 'c7', 'c8', 'c9']\n",
    "    for driver_id in driver_id_list:\n",
    "        os.mkdir(dirbase + driver_id)\n",
    "        for sub_dir in sub_dirs:\n",
    "            os.mkdir(dirbase + driver_id + '/' + sub_dir)\n",
    "\n",
    "    for i in range(df.shape[0]):\n",
    "        driver_id = df.loc[i][\"subject\"]\n",
    "        class_name = df.loc[i][\"classname\"]\n",
    "        img = df.loc[i][\"img\"]\n",
    "        add_old = 'imgs/train/' + class_name+'/' + img\n",
    "        add_new = dirbase + driver_id + '/' + class_name + '/' + img\n",
    "        if os.path.exists(add_old):\n",
    "            shutil.move(add_old, add_new)\n",
    "        \n",
    "prepare_data()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size=(224, 224)\n",
    "batch_size =64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#训练\n",
    "from keras.callbacks import *\n",
    "from keras.models import *\n",
    "#from keras.applications.vgg19 import preprocess_input\n",
    "from keras.applications.resnet50 import preprocess_input, decode_predictions\n",
    "#from keras.applications.inception_v3 import preprocess_input, decode_predictions\n",
    "\n",
    "import copy\n",
    "def get_file_num(driver_id):\n",
    "    train_base_add = 'imgs/train2/'\n",
    "    add_driver = train_base_add + driver_id\n",
    "    sub_dirs = ['c0', 'c1', 'c2', 'c3', 'c4', 'c5', 'c6', 'c7', 'c8', 'c9']\n",
    "    num = 0\n",
    "    for sub_dir in sub_dirs:\n",
    "        add_driver_class = add_driver + '/' + sub_dir\n",
    "        train_filenames = os.listdir(add_driver_class)\n",
    "        num += len(train_filenames)\n",
    "    return num\n",
    "\n",
    "def train_model(Model):\n",
    "    model = Model()\n",
    "    \n",
    "    train_datagen = ImageDataGenerator(\n",
    " #   shear_range=0.2,\n",
    " #   zoom_range=0.2,\n",
    "    preprocessing_function=preprocess_input,\n",
    " #   horizontal_flip=True\n",
    "    )\n",
    "    driver_id_list = get_driver_list()\n",
    "    train_base_add = 'imgs/train2/'\n",
    "    \n",
    "    \n",
    "    patience = 5\n",
    "    loss_list = []\n",
    "    \n",
    "    best_model = 0\n",
    "    save_loss_callback = LambdaCallback(on_epoch_end=lambda epoch, logs:loss_list.append(logs['val_loss']))\n",
    "                            \n",
    "    for epoch in range(10):\n",
    "        print('step---------------------- {%d}'%(epoch))\n",
    "        for driver_id in driver_id_list:\n",
    "            nb_train_samples = get_file_num(driver_id)\n",
    "            \n",
    "            train_generator = train_datagen.flow_from_directory(\n",
    "                train_base_add + driver_id,\n",
    "                target_size=(image_size[0], image_size[1]),\n",
    "                batch_size=batch_size,\n",
    "                class_mode='categorical')\n",
    "    \n",
    "            val_generator = train_datagen.flow_from_directory(\n",
    "                'imgs/val',\n",
    "                target_size=(image_size[0], image_size[1]),\n",
    "                batch_size=batch_size,\n",
    "                class_mode='categorical')\n",
    "        \n",
    "            model.fit_generator(\n",
    "                train_generator,\n",
    "                steps_per_epoch=nb_train_samples // batch_size,\n",
    "                epochs=1,\n",
    "                workers=6,\n",
    "                callbacks=[save_loss_callback],\n",
    "                validation_data = val_generator)\n",
    "            \n",
    "            last_loss = loss_list[-1]\n",
    "            if_best_loss = True\n",
    "            for loss in loss_list:\n",
    "                if loss < last_loss:\n",
    "                    if_best_loss = False\n",
    "            if if_best_loss == True:\n",
    "            #    best_model =copy.deepcopy(model) \n",
    "                print('last model loss ------------------------------------------%f'%(last_loss))\n",
    "                model.save('model.h5')\n",
    "    \n",
    "    \n",
    "    model = load_model('model.h5')\n",
    "    \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#训练方式2\n",
    "from keras.callbacks import *\n",
    "from keras.models import *\n",
    "#from keras.applications.vgg19 import preprocess_input\n",
    "from keras.applications.resnet50 import preprocess_input, decode_predictions\n",
    "#from keras.applications.inception_v3 import preprocess_input, decode_predictions\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from skimage.io import imread, imsave\n",
    "from scipy.misc import imresize\n",
    "\n",
    "def load_image(path):\n",
    "    img = imread(path)\n",
    "    img = imresize(img, (image_size[1], image_size[0]))\n",
    "    return img\n",
    "\n",
    "def load_driver_imgs(driver_id, pre_add = 'imgs/train2/'):\n",
    "    base_add = pre_add + driver_id\n",
    "    sub_dirs = ['c0', 'c1', 'c2', 'c3', 'c4', 'c5', 'c6', 'c7', 'c8', 'c9']\n",
    "    \n",
    "    img_list = []\n",
    "    label_list = []\n",
    "    for i, sub_dir in enumerate(sub_dirs) :\n",
    "        img_class_add = base_add + '/' + sub_dir\n",
    "        img_names = os.listdir(img_class_add)\n",
    "        for img_name in img_names:\n",
    "            \n",
    "            img = load_image(img_class_add + '/' + img_name)\n",
    "       #     img = img.swapaxes(2, 0)\n",
    "            img_list.append(img)\n",
    "            label_val = [0,0,0,0,0,0,0,0,0,0]\n",
    "            label_val[i] = 1\n",
    "            label_list.append(label_val)\n",
    "    \n",
    "    img_list = np.array(img_list)\n",
    "    label_list = np.array(label_list)\n",
    "  #  label_list = OneHotEncoder(n_values=10).fit_transform(label_list.reshape(-1, 1)).toarray()\n",
    "    return img_list, label_list\n",
    "\n",
    "def train_model_2(Model):\n",
    "    model = Model()\n",
    "    \n",
    "    train_datagen = ImageDataGenerator(\n",
    " #   shear_range=0.2,\n",
    " #   zoom_range=0.2,\n",
    "    preprocessing_function=preprocess_input,\n",
    " #   horizontal_flip=True\n",
    "    )\n",
    "    driver_id_list = get_driver_list()\n",
    "    train_base_add = 'imgs/train2/'\n",
    "    \n",
    "    \n",
    "    patience = 5\n",
    "    loss_list = []\n",
    "    \n",
    "    best_model = model\n",
    "    save_loss_callback = LambdaCallback(on_epoch_end=lambda epoch, logs:loss_list.append(logs['val_loss']))\n",
    "    \n",
    "    val_datagen = ImageDataGenerator(\n",
    " #   shear_range=0.2,\n",
    " #   zoom_range=0.2,\n",
    "    preprocessing_function=preprocess_input,\n",
    " #   horizontal_flip=True\n",
    "    )\n",
    "    x_val, y_val = load_driver_imgs('val', 'imgs/')\n",
    "    val_datagen.fit(x_val)\n",
    "    \n",
    "    \n",
    "    for epoch in range(10):\n",
    "        print('step---------------------- {%d}'%(epoch))\n",
    "        for driver_id in driver_id_list:\n",
    "            nb_train_samples = get_file_num(driver_id)\n",
    "            \n",
    "            x_train, y_train = load_driver_imgs(driver_id)\n",
    "        \n",
    "            train_datagen.fit(x_train)\n",
    "            model.fit_generator(\n",
    "                train_datagen.flow(x_train, y_train, batch_size=batch_size),\n",
    "                shuffle=True,\n",
    "                steps_per_epoch=nb_train_samples // batch_size,\n",
    "                epochs=1,\n",
    "                workers=6,\n",
    "                callbacks=[save_loss_callback],\n",
    "                validation_data = val_datagen.flow(x_val, y_val, batch_size=batch_size)\n",
    "               \n",
    "            )\n",
    "            \n",
    "            last_loss = loss_list[-1]\n",
    "            if_best_loss = True\n",
    "            for loss in loss_list:\n",
    "                if loss < last_loss:\n",
    "                    if_best_loss = False\n",
    "            if if_best_loss == True:\n",
    "                best_model = model\n",
    "                print('last model loss ------------------------------------------%f'%(last_loss))\n",
    "                model.save('model.h5')\n",
    "    \n",
    "    \n",
    "    model = load_model('model.h5')\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import cv2\n",
    "def test_model(model, file_name):\n",
    "    df = pd.read_csv(\"sample_submission.csv\")\n",
    "    \n",
    "    test_address = 'imgs/test'\n",
    "    test_filenames = os.listdir(test_address)\n",
    " #   test_filenames = test_filenames[:10]\n",
    "    X = np.zeros((len(test_filenames), image_size[0], image_size[1], 3), dtype=np.uint8)\n",
    "\n",
    "    for i, test_file in enumerate(test_filenames) :\n",
    "        X[i] = cv2.resize(cv2.imread(test_address + '/' + test_file), image_size)\n",
    "    \n",
    "    y_pred = model.predict(X, batch_size=batch_size, verbose=0)\n",
    "  #  print(y_pred)\n",
    "    \n",
    "    for i, fname in enumerate(test_filenames):\n",
    "      #  print(fname)\n",
    "        df.set_value(i, 'img', fname)\n",
    "        sub_dirs = ['c0', 'c1', 'c2', 'c3', 'c4', 'c5', 'c6', 'c7', 'c8', 'c9']\n",
    "        for ii, sb in enumerate(sub_dirs):\n",
    "            df.set_value(i, sb, y_pred[i][ii])\n",
    "\n",
    "\n",
    "    df.to_csv(file_name, index=None)\n",
    "    df.head(10)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import cv2\n",
    "#from keras.applications.vgg19 import preprocess_input\n",
    "#from keras.applications.resnet50 import preprocess_input, decode_predictions\n",
    "from keras.applications.inception_v3 import preprocess_input, decode_predictions\n",
    "\n",
    "def test_model_2(model, file_name):\n",
    "    df = pd.read_csv(\"sample_submission.csv\")\n",
    "    \n",
    "    test_address = 'imgs/test'\n",
    "\n",
    "    \n",
    "    test_datagen = ImageDataGenerator(\n",
    " #   shear_range=0.2,\n",
    " #   zoom_range=0.2,\n",
    "    preprocessing_function=preprocess_input,\n",
    " #   horizontal_flip=True\n",
    "    )\n",
    "    test_generator = test_datagen.flow_from_directory(\n",
    "        test_address,\n",
    "        target_size=(image_size[0], image_size[1]),\n",
    "        shuffle = \"false\",\n",
    "        class_mode='categorical',\n",
    "        batch_size=1)\n",
    "\n",
    "    filenames = test_generator.filenames\n",
    "    nb_samples = len(filenames)\n",
    "   \n",
    "    y_pred = model.predict_generator(test_generator, steps = nb_samples)\n",
    "  #  print(y_pred)\n",
    "    \n",
    "    for i, fname in enumerate(filenames):\n",
    "      #  print(fname)\n",
    "        df.set_value(i, 'img', fname)\n",
    "        sub_dirs = ['c0', 'c1', 'c2', 'c3', 'c4', 'c5', 'c6', 'c7', 'c8', 'c9']\n",
    "        for ii, sb in enumerate(sub_dirs):\n",
    "            df.set_value(i, sb, y_pred[i][ii])\n",
    "\n",
    "\n",
    "    df.to_csv(file_name, index=None)\n",
    "    df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 input_1\n",
      "1 conv1\n",
      "2 bn_conv1\n",
      "3 activation_1\n",
      "4 max_pooling2d_1\n",
      "5 res2a_branch2a\n",
      "6 bn2a_branch2a\n",
      "7 activation_2\n",
      "8 res2a_branch2b\n",
      "9 bn2a_branch2b\n",
      "10 activation_3\n",
      "11 res2a_branch2c\n",
      "12 res2a_branch1\n",
      "13 bn2a_branch2c\n",
      "14 bn2a_branch1\n",
      "15 add_1\n",
      "16 activation_4\n",
      "17 res2b_branch2a\n",
      "18 bn2b_branch2a\n",
      "19 activation_5\n",
      "20 res2b_branch2b\n",
      "21 bn2b_branch2b\n",
      "22 activation_6\n",
      "23 res2b_branch2c\n",
      "24 bn2b_branch2c\n",
      "25 add_2\n",
      "26 activation_7\n",
      "27 res2c_branch2a\n",
      "28 bn2c_branch2a\n",
      "29 activation_8\n",
      "30 res2c_branch2b\n",
      "31 bn2c_branch2b\n",
      "32 activation_9\n",
      "33 res2c_branch2c\n",
      "34 bn2c_branch2c\n",
      "35 add_3\n",
      "36 activation_10\n",
      "37 res3a_branch2a\n",
      "38 bn3a_branch2a\n",
      "39 activation_11\n",
      "40 res3a_branch2b\n",
      "41 bn3a_branch2b\n",
      "42 activation_12\n",
      "43 res3a_branch2c\n",
      "44 res3a_branch1\n",
      "45 bn3a_branch2c\n",
      "46 bn3a_branch1\n",
      "47 add_4\n",
      "48 activation_13\n",
      "49 res3b_branch2a\n",
      "50 bn3b_branch2a\n",
      "51 activation_14\n",
      "52 res3b_branch2b\n",
      "53 bn3b_branch2b\n",
      "54 activation_15\n",
      "55 res3b_branch2c\n",
      "56 bn3b_branch2c\n",
      "57 add_5\n",
      "58 activation_16\n",
      "59 res3c_branch2a\n",
      "60 bn3c_branch2a\n",
      "61 activation_17\n",
      "62 res3c_branch2b\n",
      "63 bn3c_branch2b\n",
      "64 activation_18\n",
      "65 res3c_branch2c\n",
      "66 bn3c_branch2c\n",
      "67 add_6\n",
      "68 activation_19\n",
      "69 res3d_branch2a\n",
      "70 bn3d_branch2a\n",
      "71 activation_20\n",
      "72 res3d_branch2b\n",
      "73 bn3d_branch2b\n",
      "74 activation_21\n",
      "75 res3d_branch2c\n",
      "76 bn3d_branch2c\n",
      "77 add_7\n",
      "78 activation_22\n",
      "79 res4a_branch2a\n",
      "80 bn4a_branch2a\n",
      "81 activation_23\n",
      "82 res4a_branch2b\n",
      "83 bn4a_branch2b\n",
      "84 activation_24\n",
      "85 res4a_branch2c\n",
      "86 res4a_branch1\n",
      "87 bn4a_branch2c\n",
      "88 bn4a_branch1\n",
      "89 add_8\n",
      "90 activation_25\n",
      "91 res4b_branch2a\n",
      "92 bn4b_branch2a\n",
      "93 activation_26\n",
      "94 res4b_branch2b\n",
      "95 bn4b_branch2b\n",
      "96 activation_27\n",
      "97 res4b_branch2c\n",
      "98 bn4b_branch2c\n",
      "99 add_9\n",
      "100 activation_28\n",
      "101 res4c_branch2a\n",
      "102 bn4c_branch2a\n",
      "103 activation_29\n",
      "104 res4c_branch2b\n",
      "105 bn4c_branch2b\n",
      "106 activation_30\n",
      "107 res4c_branch2c\n",
      "108 bn4c_branch2c\n",
      "109 add_10\n",
      "110 activation_31\n",
      "111 res4d_branch2a\n",
      "112 bn4d_branch2a\n",
      "113 activation_32\n",
      "114 res4d_branch2b\n",
      "115 bn4d_branch2b\n",
      "116 activation_33\n",
      "117 res4d_branch2c\n",
      "118 bn4d_branch2c\n",
      "119 add_11\n",
      "120 activation_34\n",
      "121 res4e_branch2a\n",
      "122 bn4e_branch2a\n",
      "123 activation_35\n",
      "124 res4e_branch2b\n",
      "125 bn4e_branch2b\n",
      "126 activation_36\n",
      "127 res4e_branch2c\n",
      "128 bn4e_branch2c\n",
      "129 add_12\n",
      "130 activation_37\n",
      "131 res4f_branch2a\n",
      "132 bn4f_branch2a\n",
      "133 activation_38\n",
      "134 res4f_branch2b\n",
      "135 bn4f_branch2b\n",
      "136 activation_39\n",
      "137 res4f_branch2c\n",
      "138 bn4f_branch2c\n",
      "139 add_13\n",
      "140 activation_40\n",
      "141 res5a_branch2a\n",
      "142 bn5a_branch2a\n",
      "143 activation_41\n",
      "144 res5a_branch2b\n",
      "145 bn5a_branch2b\n",
      "146 activation_42\n",
      "147 res5a_branch2c\n",
      "148 res5a_branch1\n",
      "149 bn5a_branch2c\n",
      "150 bn5a_branch1\n",
      "151 add_14\n",
      "152 activation_43\n",
      "153 res5b_branch2a\n",
      "154 bn5b_branch2a\n",
      "155 activation_44\n",
      "156 res5b_branch2b\n",
      "157 bn5b_branch2b\n",
      "158 activation_45\n",
      "159 res5b_branch2c\n",
      "160 bn5b_branch2c\n",
      "161 add_15\n",
      "162 activation_46\n",
      "163 res5c_branch2a\n",
      "164 bn5c_branch2a\n",
      "165 activation_47\n",
      "166 res5c_branch2b\n",
      "167 bn5c_branch2b\n",
      "168 activation_48\n",
      "169 res5c_branch2c\n",
      "170 bn5c_branch2c\n",
      "171 add_16\n",
      "172 activation_49\n",
      "173 avg_pool\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda/lib/python3.5/site-packages/ipykernel_launcher.py:13: DeprecationWarning: `imresize` is deprecated!\n",
      "`imresize` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``skimage.transform.resize`` instead.\n",
      "  del sys.path[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step---------------------- {0}\n",
      "Epoch 1/1\n",
      "10/10 [==============================] - 213s 21s/step - loss: 1.6884 - acc: 0.4607 - val_loss: 5.3382 - val_acc: 0.2034\n",
      "last model loss ------------------------------------------5.338233\n",
      "Epoch 1/1\n",
      "11/11 [==============================] - 8s 743ms/step - loss: 2.2889 - acc: 0.3526 - val_loss: 7.7284 - val_acc: 0.1216\n",
      "Epoch 1/1\n",
      "12/12 [==============================] - 8s 685ms/step - loss: 2.0086 - acc: 0.5262 - val_loss: 13.1990 - val_acc: 0.1596\n",
      "Epoch 1/1\n",
      "12/12 [==============================] - 8s 695ms/step - loss: 1.1578 - acc: 0.6433 - val_loss: 14.4408 - val_acc: 0.1037\n",
      "Epoch 1/1\n",
      "14/14 [==============================] - 9s 656ms/step - loss: 0.7741 - acc: 0.6912 - val_loss: 14.4529 - val_acc: 0.1033\n",
      "Epoch 1/1\n",
      "17/17 [==============================] - 10s 591ms/step - loss: 0.6168 - acc: 0.7954 - val_loss: 13.2743 - val_acc: 0.1118\n",
      "Epoch 1/1\n",
      "17/17 [==============================] - 10s 591ms/step - loss: 0.2941 - acc: 0.8823 - val_loss: 8.5653 - val_acc: 0.2454\n",
      "Epoch 1/1\n",
      "17/17 [==============================] - 10s 587ms/step - loss: 0.1884 - acc: 0.9622 - val_loss: 14.4418 - val_acc: 0.1033\n",
      "Epoch 1/1\n",
      "16/16 [==============================] - 10s 614ms/step - loss: 0.2934 - acc: 0.9195 - val_loss: 14.4321 - val_acc: 0.1046\n",
      "Epoch 1/1\n",
      "11/11 [==============================] - 8s 748ms/step - loss: 0.3387 - acc: 0.9150 - val_loss: 14.1571 - val_acc: 0.1113\n",
      "Epoch 1/1\n",
      "9/9 [==============================] - 7s 816ms/step - loss: 0.4931 - acc: 0.8688 - val_loss: 10.5228 - val_acc: 0.2427\n",
      "Epoch 1/1\n",
      "8/8 [==============================] - 7s 890ms/step - loss: 0.2689 - acc: 0.9397 - val_loss: 13.9160 - val_acc: 0.1189\n",
      "Epoch 1/1\n",
      "8/8 [==============================] - 7s 891ms/step - loss: 0.2207 - acc: 0.9527 - val_loss: 13.2853 - val_acc: 0.1609\n",
      "Epoch 1/1\n",
      "10/10 [==============================] - 8s 764ms/step - loss: 0.3426 - acc: 0.8907 - val_loss: 13.0456 - val_acc: 0.1082\n",
      "Epoch 1/1\n",
      "11/11 [==============================] - 8s 745ms/step - loss: 1.7003 - acc: 0.5666 - val_loss: 13.5989 - val_acc: 0.1430\n",
      "Epoch 1/1\n",
      "14/14 [==============================] - 9s 636ms/step - loss: 0.6998 - acc: 0.7487 - val_loss: 14.4537 - val_acc: 0.1033\n",
      "Epoch 1/1\n",
      "11/11 [==============================] - 8s 722ms/step - loss: 1.4249 - acc: 0.6031 - val_loss: 14.4537 - val_acc: 0.1033\n",
      "Epoch 1/1\n",
      "13/13 [==============================] - 9s 675ms/step - loss: 1.0045 - acc: 0.6923 - val_loss: 14.4537 - val_acc: 0.1033\n",
      "Epoch 1/1\n",
      "10/10 [==============================] - 8s 763ms/step - loss: 0.6210 - acc: 0.8582 - val_loss: 14.4537 - val_acc: 0.1033\n",
      "Epoch 1/1\n",
      "11/11 [==============================] - 8s 726ms/step - loss: 0.7037 - acc: 0.8343 - val_loss: 0.4828 - val_acc: 0.1109\n",
      "last model loss ------------------------------------------0.482750\n",
      "Epoch 1/1\n",
      "11/11 [==============================] - 8s 734ms/step - loss: 0.8782 - acc: 0.7525 - val_loss: 14.0364 - val_acc: 0.0948\n",
      "Epoch 1/1\n",
      "11/11 [==============================] - 8s 725ms/step - loss: 0.7030 - acc: 0.7693 - val_loss: 11.6330 - val_acc: 0.1672\n",
      "Epoch 1/1\n",
      "14/14 [==============================] - 9s 646ms/step - loss: 0.5606 - acc: 0.8093 - val_loss: 13.6916 - val_acc: 0.1225\n",
      "Epoch 1/1\n",
      "4/4 [==============================] - 6s 1s/step - loss: 1.5338 - acc: 0.5000 - val_loss: 14.3941 - val_acc: 0.1042\n",
      "Epoch 1/1\n",
      "11/11 [==============================] - 8s 737ms/step - loss: 1.0287 - acc: 0.6562 - val_loss: 13.5062 - val_acc: 0.1104\n",
      "Epoch 1/1\n",
      "11/11 [==============================] - 8s 722ms/step - loss: 0.4964 - acc: 0.8460 - val_loss: 14.4489 - val_acc: 0.1033\n",
      "step---------------------- {1}\n",
      "Epoch 1/1\n",
      "10/10 [==============================] - 8s 755ms/step - loss: 0.7944 - acc: 0.7784 - val_loss: 14.5776 - val_acc: 0.0912\n",
      "Epoch 1/1\n",
      "11/11 [==============================] - 8s 731ms/step - loss: 1.8843 - acc: 0.5025 - val_loss: 14.2528 - val_acc: 0.0899\n",
      "Epoch 1/1\n",
      "12/12 [==============================] - 8s 685ms/step - loss: 0.6143 - acc: 0.8691 - val_loss: 2.4834 - val_acc: 0.1042\n",
      "Epoch 1/1\n",
      "12/12 [==============================] - 8s 686ms/step - loss: 0.6399 - acc: 0.8017 - val_loss: 13.5725 - val_acc: 0.0939\n",
      "Epoch 1/1\n",
      "14/14 [==============================] - 9s 650ms/step - loss: 0.4540 - acc: 0.8929 - val_loss: 13.9788 - val_acc: 0.1024\n",
      "Epoch 1/1\n",
      "17/17 [==============================] - 10s 585ms/step - loss: 0.3948 - acc: 0.8697 - val_loss: 13.2584 - val_acc: 0.1211\n",
      "Epoch 1/1\n",
      "17/17 [==============================] - 10s 586ms/step - loss: 0.2886 - acc: 0.9028 - val_loss: 10.2784 - val_acc: 0.2986\n",
      "Epoch 1/1\n",
      "17/17 [==============================] - 10s 581ms/step - loss: 0.1811 - acc: 0.9521 - val_loss: 11.9210 - val_acc: 0.1815\n",
      "Epoch 1/1\n",
      "16/16 [==============================] - 10s 606ms/step - loss: 1.2084 - acc: 0.6819 - val_loss: 13.7305 - val_acc: 0.1010\n",
      "Epoch 1/1\n",
      "11/11 [==============================] - 8s 733ms/step - loss: 0.5663 - acc: 0.8555 - val_loss: 12.0642 - val_acc: 0.1466\n",
      "Epoch 1/1\n",
      "9/9 [==============================] - 7s 807ms/step - loss: 0.5826 - acc: 0.8202 - val_loss: 5.3314 - val_acc: 0.2593\n",
      "Epoch 1/1\n",
      "8/8 [==============================] - 7s 875ms/step - loss: 1.1971 - acc: 0.7098 - val_loss: 10.1900 - val_acc: 0.1815\n",
      "Epoch 1/1\n",
      "8/8 [==============================] - 7s 874ms/step - loss: 0.4194 - acc: 0.8558 - val_loss: 8.1700 - val_acc: 0.1243\n",
      "Epoch 1/1\n",
      "10/10 [==============================] - 8s 757ms/step - loss: 0.2834 - acc: 0.9433 - val_loss: 8.1975 - val_acc: 0.0952\n",
      "Epoch 1/1\n",
      "11/11 [==============================] - 8s 728ms/step - loss: 0.3900 - acc: 0.8841 - val_loss: 13.3776 - val_acc: 0.1229\n",
      "Epoch 1/1\n",
      "14/14 [==============================] - 9s 635ms/step - loss: 0.2109 - acc: 0.9327 - val_loss: 14.3814 - val_acc: 0.1037\n"
     ]
    }
   ],
   "source": [
    "model = train_model_2(restNet_model)\n",
    "test_model(model, 'pred.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 input_14\n",
      "1 conv1\n",
      "2 bn_conv1\n",
      "3 activation_638\n",
      "4 max_pooling2d_14\n",
      "5 res2a_branch2a\n",
      "6 bn2a_branch2a\n",
      "7 activation_639\n",
      "8 res2a_branch2b\n",
      "9 bn2a_branch2b\n",
      "10 activation_640\n",
      "11 res2a_branch2c\n",
      "12 res2a_branch1\n",
      "13 bn2a_branch2c\n",
      "14 bn2a_branch1\n",
      "15 add_209\n",
      "16 activation_641\n",
      "17 res2b_branch2a\n",
      "18 bn2b_branch2a\n",
      "19 activation_642\n",
      "20 res2b_branch2b\n",
      "21 bn2b_branch2b\n",
      "22 activation_643\n",
      "23 res2b_branch2c\n",
      "24 bn2b_branch2c\n",
      "25 add_210\n",
      "26 activation_644\n",
      "27 res2c_branch2a\n",
      "28 bn2c_branch2a\n",
      "29 activation_645\n",
      "30 res2c_branch2b\n",
      "31 bn2c_branch2b\n",
      "32 activation_646\n",
      "33 res2c_branch2c\n",
      "34 bn2c_branch2c\n",
      "35 add_211\n",
      "36 activation_647\n",
      "37 res3a_branch2a\n",
      "38 bn3a_branch2a\n",
      "39 activation_648\n",
      "40 res3a_branch2b\n",
      "41 bn3a_branch2b\n",
      "42 activation_649\n",
      "43 res3a_branch2c\n",
      "44 res3a_branch1\n",
      "45 bn3a_branch2c\n",
      "46 bn3a_branch1\n",
      "47 add_212\n",
      "48 activation_650\n",
      "49 res3b_branch2a\n",
      "50 bn3b_branch2a\n",
      "51 activation_651\n",
      "52 res3b_branch2b\n",
      "53 bn3b_branch2b\n",
      "54 activation_652\n",
      "55 res3b_branch2c\n",
      "56 bn3b_branch2c\n",
      "57 add_213\n",
      "58 activation_653\n",
      "59 res3c_branch2a\n",
      "60 bn3c_branch2a\n",
      "61 activation_654\n",
      "62 res3c_branch2b\n",
      "63 bn3c_branch2b\n",
      "64 activation_655\n",
      "65 res3c_branch2c\n",
      "66 bn3c_branch2c\n",
      "67 add_214\n",
      "68 activation_656\n",
      "69 res3d_branch2a\n",
      "70 bn3d_branch2a\n",
      "71 activation_657\n",
      "72 res3d_branch2b\n",
      "73 bn3d_branch2b\n",
      "74 activation_658\n",
      "75 res3d_branch2c\n",
      "76 bn3d_branch2c\n",
      "77 add_215\n",
      "78 activation_659\n",
      "79 res4a_branch2a\n",
      "80 bn4a_branch2a\n",
      "81 activation_660\n",
      "82 res4a_branch2b\n",
      "83 bn4a_branch2b\n",
      "84 activation_661\n",
      "85 res4a_branch2c\n",
      "86 res4a_branch1\n",
      "87 bn4a_branch2c\n",
      "88 bn4a_branch1\n",
      "89 add_216\n",
      "90 activation_662\n",
      "91 res4b_branch2a\n",
      "92 bn4b_branch2a\n",
      "93 activation_663\n",
      "94 res4b_branch2b\n",
      "95 bn4b_branch2b\n",
      "96 activation_664\n",
      "97 res4b_branch2c\n",
      "98 bn4b_branch2c\n",
      "99 add_217\n",
      "100 activation_665\n",
      "101 res4c_branch2a\n",
      "102 bn4c_branch2a\n",
      "103 activation_666\n",
      "104 res4c_branch2b\n",
      "105 bn4c_branch2b\n",
      "106 activation_667\n",
      "107 res4c_branch2c\n",
      "108 bn4c_branch2c\n",
      "109 add_218\n",
      "110 activation_668\n",
      "111 res4d_branch2a\n",
      "112 bn4d_branch2a\n",
      "113 activation_669\n",
      "114 res4d_branch2b\n",
      "115 bn4d_branch2b\n",
      "116 activation_670\n",
      "117 res4d_branch2c\n",
      "118 bn4d_branch2c\n",
      "119 add_219\n",
      "120 activation_671\n",
      "121 res4e_branch2a\n",
      "122 bn4e_branch2a\n",
      "123 activation_672\n",
      "124 res4e_branch2b\n",
      "125 bn4e_branch2b\n",
      "126 activation_673\n",
      "127 res4e_branch2c\n",
      "128 bn4e_branch2c\n",
      "129 add_220\n",
      "130 activation_674\n",
      "131 res4f_branch2a\n",
      "132 bn4f_branch2a\n",
      "133 activation_675\n",
      "134 res4f_branch2b\n",
      "135 bn4f_branch2b\n",
      "136 activation_676\n",
      "137 res4f_branch2c\n",
      "138 bn4f_branch2c\n",
      "139 add_221\n",
      "140 activation_677\n",
      "141 res5a_branch2a\n",
      "142 bn5a_branch2a\n",
      "143 activation_678\n",
      "144 res5a_branch2b\n",
      "145 bn5a_branch2b\n",
      "146 activation_679\n",
      "147 res5a_branch2c\n",
      "148 res5a_branch1\n",
      "149 bn5a_branch2c\n",
      "150 bn5a_branch1\n",
      "151 add_222\n",
      "152 activation_680\n",
      "153 res5b_branch2a\n",
      "154 bn5b_branch2a\n",
      "155 activation_681\n",
      "156 res5b_branch2b\n",
      "157 bn5b_branch2b\n",
      "158 activation_682\n",
      "159 res5b_branch2c\n",
      "160 bn5b_branch2c\n",
      "161 add_223\n",
      "162 activation_683\n",
      "163 res5c_branch2a\n",
      "164 bn5c_branch2a\n",
      "165 activation_684\n",
      "166 res5c_branch2b\n",
      "167 bn5c_branch2b\n",
      "168 activation_685\n",
      "169 res5c_branch2c\n",
      "170 bn5c_branch2c\n",
      "171 add_224\n",
      "172 activation_686\n",
      "173 avg_pool\n",
      "step---------------------- {0}\n",
      "Found 655 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "10/10 [==============================] - 25s 3s/step - loss: 0.6596 - acc: 0.8646 - val_loss: 2.4596 - val_acc: 0.3397\n",
      "last model loss ------------------------------------------2.459552\n",
      "Found 749 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "11/11 [==============================] - 9s 830ms/step - loss: 0.2500 - acc: 0.9311 - val_loss: 11.7496 - val_acc: 0.1301\n",
      "Found 778 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "12/12 [==============================] - 10s 799ms/step - loss: 0.2253 - acc: 0.9320 - val_loss: 11.8052 - val_acc: 0.1605\n",
      "Found 792 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "12/12 [==============================] - 10s 799ms/step - loss: 0.3183 - acc: 0.9084 - val_loss: 12.3653 - val_acc: 0.1529\n",
      "Found 957 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "14/14 [==============================] - 11s 755ms/step - loss: 0.1616 - acc: 0.9607 - val_loss: 9.5499 - val_acc: 0.2298\n",
      "Found 1121 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "17/17 [==============================] - 12s 678ms/step - loss: 0.4172 - acc: 0.8998 - val_loss: 14.4401 - val_acc: 0.1033\n",
      "Found 1123 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "17/17 [==============================] - 11s 668ms/step - loss: 2.8213 - acc: 0.3735 - val_loss: 14.5834 - val_acc: 0.0952\n",
      "Found 1109 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "17/17 [==============================] - 11s 654ms/step - loss: 1.4380 - acc: 0.4542 - val_loss: 12.8152 - val_acc: 0.1109\n",
      "Found 1071 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "16/16 [==============================] - 11s 680ms/step - loss: 3.2408 - acc: 0.2581 - val_loss: 11.3846 - val_acc: 0.1109\n",
      "Found 754 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "11/11 [==============================] - 9s 860ms/step - loss: 1.6736 - acc: 0.3349 - val_loss: 9.3626 - val_acc: 0.1109\n",
      "Found 596 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "9/9 [==============================] - 9s 957ms/step - loss: 1.8640 - acc: 0.3218 - val_loss: 11.2733 - val_acc: 0.1006\n",
      "Found 544 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "8/8 [==============================] - 8s 1s/step - loss: 1.4616 - acc: 0.4909 - val_loss: 10.4112 - val_acc: 0.1234\n",
      "Found 540 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "8/8 [==============================] - 8s 1s/step - loss: 1.2467 - acc: 0.4731 - val_loss: 11.7271 - val_acc: 0.1033\n",
      "Found 656 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "10/10 [==============================] - 9s 898ms/step - loss: 1.2432 - acc: 0.5632 - val_loss: 12.0725 - val_acc: 0.1363\n",
      "Found 748 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "11/11 [==============================] - 9s 853ms/step - loss: 1.1632 - acc: 0.5517 - val_loss: 11.3615 - val_acc: 0.0939\n",
      "Found 911 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "14/14 [==============================] - 10s 728ms/step - loss: 1.0771 - acc: 0.6333 - val_loss: 13.3034 - val_acc: 0.1305\n",
      "Found 708 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "11/11 [==============================] - 9s 843ms/step - loss: 1.1296 - acc: 0.6292 - val_loss: 8.3976 - val_acc: 0.1645\n",
      "Found 832 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "13/13 [==============================] - 10s 774ms/step - loss: 1.0297 - acc: 0.6887 - val_loss: 9.8665 - val_acc: 0.1131\n",
      "Found 651 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "10/10 [==============================] - 9s 894ms/step - loss: 2.1260 - acc: 0.3787 - val_loss: 11.6483 - val_acc: 0.1077\n",
      "Found 717 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "11/11 [==============================] - 9s 835ms/step - loss: 1.3027 - acc: 0.6673 - val_loss: 10.3716 - val_acc: 0.1511\n",
      "Found 733 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "11/11 [==============================] - 9s 861ms/step - loss: 0.9556 - acc: 0.6903 - val_loss: 11.2905 - val_acc: 0.1162\n",
      "Found 736 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "11/11 [==============================] - 9s 836ms/step - loss: 0.7709 - acc: 0.7906 - val_loss: 12.4561 - val_acc: 0.1086\n",
      "Found 922 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "14/14 [==============================] - 10s 733ms/step - loss: 0.6117 - acc: 0.8249 - val_loss: 11.6268 - val_acc: 0.1354\n",
      "Found 314 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 7s 2s/step - loss: 1.9095 - acc: 0.3867 - val_loss: 9.8907 - val_acc: 0.1833\n",
      "Found 734 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "11/11 [==============================] - 9s 847ms/step - loss: 0.7188 - acc: 0.7754 - val_loss: 11.6367 - val_acc: 0.1422\n",
      "Found 736 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "11/11 [==============================] - 9s 839ms/step - loss: 0.5455 - acc: 0.8433 - val_loss: 10.6182 - val_acc: 0.1042\n",
      "step---------------------- {1}\n",
      "Found 655 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "10/10 [==============================] - 9s 913ms/step - loss: 0.7516 - acc: 0.7531 - val_loss: 4.6243 - val_acc: 0.1667\n",
      "Found 749 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "11/11 [==============================] - 10s 865ms/step - loss: 0.7958 - acc: 0.7620 - val_loss: 2.9529 - val_acc: 0.2427\n",
      "Found 778 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "12/12 [==============================] - 10s 795ms/step - loss: 0.6379 - acc: 0.8076 - val_loss: 10.2338 - val_acc: 0.1439\n",
      "Found 792 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "12/12 [==============================] - 10s 795ms/step - loss: 0.6954 - acc: 0.7892 - val_loss: 12.2464 - val_acc: 0.1185\n",
      "Found 957 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "14/14 [==============================] - 10s 744ms/step - loss: 0.3932 - acc: 0.8915 - val_loss: 14.2171 - val_acc: 0.1010\n",
      "Found 1121 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "17/17 [==============================] - 11s 664ms/step - loss: 0.3794 - acc: 0.8925 - val_loss: 3.2925 - val_acc: 0.3362\n",
      "Found 1123 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "17/17 [==============================] - 11s 662ms/step - loss: 0.3149 - acc: 0.9086 - val_loss: 11.5399 - val_acc: 0.1430\n",
      "Found 1109 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "17/17 [==============================] - 11s 653ms/step - loss: 0.2765 - acc: 0.9117 - val_loss: 11.6923 - val_acc: 0.2043\n",
      "Found 1071 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "16/16 [==============================] - 11s 691ms/step - loss: 0.3203 - acc: 0.8965 - val_loss: 5.5659 - val_acc: 0.3312\n",
      "Found 754 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "11/11 [==============================] - 9s 852ms/step - loss: 0.2260 - acc: 0.9562 - val_loss: 7.8111 - val_acc: 0.2436\n",
      "Found 596 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "9/9 [==============================] - 9s 958ms/step - loss: 0.3516 - acc: 0.8932 - val_loss: 10.2650 - val_acc: 0.1846\n",
      "Found 544 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.2346 - acc: 0.9160 - val_loss: 5.7935 - val_acc: 0.3125\n",
      "Found 540 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "8/8 [==============================] - 8s 1s/step - loss: 1.2209 - acc: 0.6329 - val_loss: 7.2527 - val_acc: 0.2499\n",
      "Found 656 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "10/10 [==============================] - 9s 879ms/step - loss: 0.4005 - acc: 0.8851 - val_loss: 11.2607 - val_acc: 0.2021\n",
      "Found 748 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "11/11 [==============================] - 10s 867ms/step - loss: 0.3453 - acc: 0.8736 - val_loss: 13.8652 - val_acc: 0.1171\n",
      "Found 911 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "14/14 [==============================] - 10s 731ms/step - loss: 0.2583 - acc: 0.9327 - val_loss: 8.6605 - val_acc: 0.2669\n",
      "Found 708 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "11/11 [==============================] - 9s 835ms/step - loss: 0.6339 - acc: 0.8058 - val_loss: 9.6812 - val_acc: 0.2494\n",
      "Found 832 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "13/13 [==============================] - 10s 781ms/step - loss: 0.5018 - acc: 0.8954 - val_loss: 8.7308 - val_acc: 0.2329\n",
      "Found 651 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "10/10 [==============================] - 9s 894ms/step - loss: 0.4122 - acc: 0.8792 - val_loss: 8.5658 - val_acc: 0.2342\n",
      "Found 717 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "11/11 [==============================] - 9s 851ms/step - loss: 1.5158 - acc: 0.6080 - val_loss: 7.1286 - val_acc: 0.2329\n",
      "Found 733 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "11/11 [==============================] - 9s 846ms/step - loss: 0.5760 - acc: 0.8108 - val_loss: 9.7494 - val_acc: 0.1985\n",
      "Found 736 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "11/11 [==============================] - 9s 862ms/step - loss: 0.4658 - acc: 0.8693 - val_loss: 12.1517 - val_acc: 0.1524\n",
      "Found 922 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "14/14 [==============================] - 10s 738ms/step - loss: 0.4365 - acc: 0.8674 - val_loss: 12.0312 - val_acc: 0.1292\n",
      "Found 314 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "4/4 [==============================] - 7s 2s/step - loss: 0.7592 - acc: 0.7937 - val_loss: 11.1959 - val_acc: 0.1681\n",
      "Found 734 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "11/11 [==============================] - 9s 857ms/step - loss: 0.4297 - acc: 0.8835 - val_loss: 12.6597 - val_acc: 0.1743\n",
      "Found 736 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "11/11 [==============================] - 9s 847ms/step - loss: 0.3906 - acc: 0.9005 - val_loss: 12.0634 - val_acc: 0.1752\n",
      "step---------------------- {2}\n",
      "Found 655 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "10/10 [==============================] - 9s 888ms/step - loss: 0.7512 - acc: 0.8238 - val_loss: 12.7888 - val_acc: 0.1453\n",
      "Found 749 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "11/11 [==============================] - 9s 843ms/step - loss: 0.7601 - acc: 0.7896 - val_loss: 13.4997 - val_acc: 0.0934\n",
      "Found 778 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "12/12 [==============================] - 10s 822ms/step - loss: 0.4396 - acc: 0.8698 - val_loss: 13.2499 - val_acc: 0.1033\n",
      "Found 792 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "12/12 [==============================] - 10s 797ms/step - loss: 0.4591 - acc: 0.8580 - val_loss: 13.9509 - val_acc: 0.1037\n",
      "Found 957 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "14/14 [==============================] - 11s 760ms/step - loss: 0.2657 - acc: 0.9140 - val_loss: 14.3022 - val_acc: 0.1059\n",
      "Found 1121 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "17/17 [==============================] - 11s 657ms/step - loss: 0.3836 - acc: 0.8932 - val_loss: 10.9041 - val_acc: 0.1359\n",
      "Found 1123 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "17/17 [==============================] - 11s 665ms/step - loss: 0.2220 - acc: 0.9321 - val_loss: 9.9553 - val_acc: 0.1882\n",
      "Found 1109 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "17/17 [==============================] - 11s 655ms/step - loss: 0.1634 - acc: 0.9613 - val_loss: 4.4958 - val_acc: 0.3934\n",
      "Found 1071 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "16/16 [==============================] - 11s 691ms/step - loss: 0.2796 - acc: 0.9185 - val_loss: 2.5325 - val_acc: 0.5092\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 754 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "11/11 [==============================] - 9s 843ms/step - loss: 0.8262 - acc: 0.7745 - val_loss: 2.1472 - val_acc: 0.4765\n",
      "last model loss ------------------------------------------2.147226\n",
      "Found 596 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "9/9 [==============================] - 8s 938ms/step - loss: 0.3070 - acc: 0.8972 - val_loss: 8.9202 - val_acc: 0.1149\n",
      "Found 544 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.1822 - acc: 0.9456 - val_loss: 11.1202 - val_acc: 0.0975\n",
      "Found 540 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.2344 - acc: 0.9311 - val_loss: 8.2619 - val_acc: 0.1703\n",
      "Found 656 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "10/10 [==============================] - 9s 894ms/step - loss: 0.1521 - acc: 0.9685 - val_loss: 5.9438 - val_acc: 0.2521\n",
      "Found 748 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "11/11 [==============================] - 9s 856ms/step - loss: 0.2262 - acc: 0.9390 - val_loss: 3.9463 - val_acc: 0.3791\n",
      "Found 911 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "14/14 [==============================] - 10s 734ms/step - loss: 0.0933 - acc: 0.9731 - val_loss: 8.6891 - val_acc: 0.1913\n",
      "Found 708 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "11/11 [==============================] - 9s 824ms/step - loss: 0.4589 - acc: 0.8140 - val_loss: 5.4946 - val_acc: 0.1989\n",
      "Found 832 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "13/13 [==============================] - 10s 780ms/step - loss: 0.2950 - acc: 0.9243 - val_loss: 2.3173 - val_acc: 0.5136\n",
      "Found 651 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "10/10 [==============================] - 9s 887ms/step - loss: 0.1633 - acc: 0.9559 - val_loss: 3.0305 - val_acc: 0.4613\n",
      "Found 717 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "11/11 [==============================] - 9s 835ms/step - loss: 0.2205 - acc: 0.9177 - val_loss: 5.3736 - val_acc: 0.3031\n",
      "Found 733 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "11/11 [==============================] - 9s 853ms/step - loss: 0.5699 - acc: 0.8488 - val_loss: 4.5269 - val_acc: 0.4394\n",
      "Found 736 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "11/11 [==============================] - 9s 857ms/step - loss: 0.4056 - acc: 0.8705 - val_loss: 6.7701 - val_acc: 0.3388\n",
      "Found 922 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "14/14 [==============================] - 10s 739ms/step - loss: 0.2228 - acc: 0.9399 - val_loss: 7.6912 - val_acc: 0.2973\n",
      "Found 314 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "4/4 [==============================] - 7s 2s/step - loss: 0.6406 - acc: 0.7897 - val_loss: 8.6571 - val_acc: 0.2521\n",
      "Found 734 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "11/11 [==============================] - 9s 850ms/step - loss: 0.2171 - acc: 0.9242 - val_loss: 2.8225 - val_acc: 0.4958\n",
      "Found 736 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "11/11 [==============================] - 9s 841ms/step - loss: 0.2422 - acc: 0.9276 - val_loss: 11.1999 - val_acc: 0.1712\n",
      "step---------------------- {3}\n",
      "Found 655 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "10/10 [==============================] - 9s 875ms/step - loss: 0.2849 - acc: 0.9009 - val_loss: 12.9913 - val_acc: 0.1042\n",
      "Found 749 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "11/11 [==============================] - 9s 850ms/step - loss: 1.8193 - acc: 0.5355 - val_loss: 11.2799 - val_acc: 0.0957\n",
      "Found 778 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "12/12 [==============================] - 10s 794ms/step - loss: 0.3799 - acc: 0.8889 - val_loss: 14.0856 - val_acc: 0.0916\n",
      "Found 792 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "12/12 [==============================] - 10s 804ms/step - loss: 0.4140 - acc: 0.8652 - val_loss: 13.4991 - val_acc: 0.1059\n",
      "Found 957 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "14/14 [==============================] - 10s 744ms/step - loss: 0.2473 - acc: 0.9285 - val_loss: 10.3784 - val_acc: 0.1851\n",
      "Found 1121 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "17/17 [==============================] - 11s 667ms/step - loss: 0.2143 - acc: 0.9402 - val_loss: 6.8056 - val_acc: 0.2763\n",
      "Found 1123 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "17/17 [==============================] - 11s 663ms/step - loss: 0.1962 - acc: 0.9459 - val_loss: 2.3046 - val_acc: 0.5785\n",
      "Found 1109 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "17/17 [==============================] - 11s 653ms/step - loss: 0.1236 - acc: 0.9650 - val_loss: 8.1791 - val_acc: 0.2611\n",
      "Found 1071 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "16/16 [==============================] - 11s 683ms/step - loss: 0.8646 - acc: 0.7960 - val_loss: 5.2639 - val_acc: 0.3755\n",
      "Found 754 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "11/11 [==============================] - 10s 866ms/step - loss: 0.1722 - acc: 0.9503 - val_loss: 2.9202 - val_acc: 0.5016\n",
      "Found 596 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "9/9 [==============================] - 9s 962ms/step - loss: 0.1578 - acc: 0.9492 - val_loss: 1.9496 - val_acc: 0.5820\n",
      "last model loss ------------------------------------------1.949576\n",
      "Found 544 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.1198 - acc: 0.9668 - val_loss: 1.7953 - val_acc: 0.5709\n",
      "last model loss ------------------------------------------1.795331\n",
      "Found 540 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.4689 - acc: 0.7983 - val_loss: 4.6720 - val_acc: 0.3478\n",
      "Found 656 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "10/10 [==============================] - 9s 889ms/step - loss: 0.2420 - acc: 0.9422 - val_loss: 8.1852 - val_acc: 0.2383\n",
      "Found 748 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "11/11 [==============================] - 9s 833ms/step - loss: 0.2243 - acc: 0.9283 - val_loss: 10.6371 - val_acc: 0.1846\n",
      "Found 911 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "14/14 [==============================] - 10s 736ms/step - loss: 0.1304 - acc: 0.9573 - val_loss: 7.3118 - val_acc: 0.3147\n",
      "Found 708 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "11/11 [==============================] - 9s 823ms/step - loss: 0.4061 - acc: 0.8960 - val_loss: 5.0123 - val_acc: 0.3996\n",
      "Found 832 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "13/13 [==============================] - 10s 785ms/step - loss: 1.0857 - acc: 0.7404 - val_loss: 14.0268 - val_acc: 0.0536\n",
      "Found 651 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "10/10 [==============================] - 9s 913ms/step - loss: 0.1573 - acc: 0.9672 - val_loss: 14.1153 - val_acc: 0.0648\n",
      "Found 717 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "11/11 [==============================] - 9s 841ms/step - loss: 0.3136 - acc: 0.9071 - val_loss: 8.6836 - val_acc: 0.2088\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 733 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "11/11 [==============================] - 9s 834ms/step - loss: 0.2579 - acc: 0.9141 - val_loss: 2.7018 - val_acc: 0.5262\n",
      "Found 736 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "11/11 [==============================] - 9s 850ms/step - loss: 0.3276 - acc: 0.8777 - val_loss: 2.7294 - val_acc: 0.5181\n",
      "Found 922 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "14/14 [==============================] - 10s 738ms/step - loss: 0.2862 - acc: 0.9067 - val_loss: 2.7137 - val_acc: 0.5369\n",
      "Found 314 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "4/4 [==============================] - 7s 2s/step - loss: 0.2817 - acc: 0.9228 - val_loss: 2.5684 - val_acc: 0.5601\n",
      "Found 734 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "11/11 [==============================] - 9s 839ms/step - loss: 0.2144 - acc: 0.9443 - val_loss: 1.8509 - val_acc: 0.6781\n",
      "Found 736 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "11/11 [==============================] - 9s 844ms/step - loss: 0.1752 - acc: 0.9515 - val_loss: 1.8310 - val_acc: 0.6781\n",
      "step---------------------- {4}\n",
      "Found 655 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "10/10 [==============================] - 9s 882ms/step - loss: 0.2378 - acc: 0.9198 - val_loss: 3.0969 - val_acc: 0.5633\n",
      "Found 749 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "11/11 [==============================] - 9s 853ms/step - loss: 0.2964 - acc: 0.9125 - val_loss: 1.3668 - val_acc: 0.6750\n",
      "last model loss ------------------------------------------1.366795\n",
      "Found 778 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "12/12 [==============================] - 9s 778ms/step - loss: 0.1987 - acc: 0.9437 - val_loss: 1.9185 - val_acc: 0.6151\n",
      "Found 792 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "12/12 [==============================] - 9s 781ms/step - loss: 0.2374 - acc: 0.9320 - val_loss: 1.7879 - val_acc: 0.5440\n",
      "Found 957 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "14/14 [==============================] - 10s 742ms/step - loss: 0.1156 - acc: 0.9621 - val_loss: 2.8086 - val_acc: 0.4859\n",
      "Found 1121 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "17/17 [==============================] - 11s 650ms/step - loss: 0.1436 - acc: 0.9588 - val_loss: 1.4533 - val_acc: 0.6527\n",
      "Found 1123 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "17/17 [==============================] - 11s 672ms/step - loss: 0.0456 - acc: 0.9908 - val_loss: 0.9440 - val_acc: 0.7407\n",
      "last model loss ------------------------------------------0.944025\n",
      "Found 1109 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "17/17 [==============================] - 11s 653ms/step - loss: 0.0569 - acc: 0.9843 - val_loss: 0.9113 - val_acc: 0.7452\n",
      "last model loss ------------------------------------------0.911281\n",
      "Found 1071 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "16/16 [==============================] - 11s 683ms/step - loss: 0.0817 - acc: 0.9785 - val_loss: 0.8119 - val_acc: 0.7787\n",
      "last model loss ------------------------------------------0.811860\n",
      "Found 754 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "11/11 [==============================] - 9s 843ms/step - loss: 0.0636 - acc: 0.9844 - val_loss: 0.9121 - val_acc: 0.7751\n",
      "Found 596 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "9/9 [==============================] - 9s 956ms/step - loss: 0.0610 - acc: 0.9790 - val_loss: 1.1180 - val_acc: 0.7376\n",
      "Found 544 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0375 - acc: 0.9924 - val_loss: 1.5201 - val_acc: 0.6844\n",
      "Found 540 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0380 - acc: 0.9921 - val_loss: 2.0717 - val_acc: 0.6080\n",
      "Found 656 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "10/10 [==============================] - 9s 897ms/step - loss: 0.1453 - acc: 0.9620 - val_loss: 1.7975 - val_acc: 0.6750\n",
      "Found 748 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "11/11 [==============================] - 9s 847ms/step - loss: 0.1383 - acc: 0.9553 - val_loss: 1.4596 - val_acc: 0.7233\n",
      "Found 911 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "14/14 [==============================] - 10s 722ms/step - loss: 0.0232 - acc: 0.9944 - val_loss: 0.9280 - val_acc: 0.8149\n",
      "Found 708 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "11/11 [==============================] - 9s 827ms/step - loss: 0.7927 - acc: 0.7471 - val_loss: 2.1951 - val_acc: 0.5141\n",
      "Found 832 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "13/13 [==============================] - 10s 783ms/step - loss: 0.1678 - acc: 0.9579 - val_loss: 4.7198 - val_acc: 0.3183\n",
      "Found 651 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "10/10 [==============================] - 9s 893ms/step - loss: 0.1669 - acc: 0.9522 - val_loss: 1.6644 - val_acc: 0.5995\n",
      "Found 717 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "11/11 [==============================] - 9s 849ms/step - loss: 0.4524 - acc: 0.8652 - val_loss: 6.4339 - val_acc: 0.2816\n",
      "Found 733 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "11/11 [==============================] - 9s 857ms/step - loss: 0.2507 - acc: 0.9282 - val_loss: 8.0181 - val_acc: 0.2758\n",
      "Found 736 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "11/11 [==============================] - 9s 835ms/step - loss: 0.3738 - acc: 0.8847 - val_loss: 9.9267 - val_acc: 0.2047\n",
      "Found 922 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "14/14 [==============================] - 10s 734ms/step - loss: 0.1689 - acc: 0.9443 - val_loss: 2.4519 - val_acc: 0.5834\n",
      "Found 314 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "4/4 [==============================] - 7s 2s/step - loss: 0.2373 - acc: 0.9330 - val_loss: 2.5352 - val_acc: 0.5811\n",
      "Found 734 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "11/11 [==============================] - 9s 843ms/step - loss: 0.8552 - acc: 0.7854 - val_loss: 7.2426 - val_acc: 0.2481\n",
      "Found 736 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "11/11 [==============================] - 9s 834ms/step - loss: 0.2123 - acc: 0.9323 - val_loss: 13.1760 - val_acc: 0.0769\n",
      "step---------------------- {5}\n",
      "Found 655 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "10/10 [==============================] - 9s 884ms/step - loss: 0.1182 - acc: 0.9669 - val_loss: 2.8907 - val_acc: 0.5127\n",
      "Found 749 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "11/11 [==============================] - 9s 852ms/step - loss: 0.2309 - acc: 0.9257 - val_loss: 3.5063 - val_acc: 0.4551\n",
      "Found 778 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "12/12 [==============================] - 9s 781ms/step - loss: 0.0997 - acc: 0.9738 - val_loss: 8.2756 - val_acc: 0.2870\n",
      "Found 792 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "12/12 [==============================] - 10s 806ms/step - loss: 0.1657 - acc: 0.9425 - val_loss: 5.3665 - val_acc: 0.3733\n",
      "Found 957 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 10s 743ms/step - loss: 0.0509 - acc: 0.9866 - val_loss: 3.2440 - val_acc: 0.4524\n",
      "Found 1121 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "17/17 [==============================] - 11s 657ms/step - loss: 0.1237 - acc: 0.9641 - val_loss: 5.1913 - val_acc: 0.3527\n",
      "Found 1123 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "17/17 [==============================] - 11s 665ms/step - loss: 0.0535 - acc: 0.9822 - val_loss: 1.3321 - val_acc: 0.7108\n",
      "Found 1109 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "17/17 [==============================] - 11s 654ms/step - loss: 0.0392 - acc: 0.9917 - val_loss: 0.8600 - val_acc: 0.7774\n",
      "Found 1071 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "16/16 [==============================] - 11s 686ms/step - loss: 0.0459 - acc: 0.9873 - val_loss: 0.7482 - val_acc: 0.8006\n",
      "last model loss ------------------------------------------0.748237\n",
      "Found 754 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "11/11 [==============================] - 9s 819ms/step - loss: 0.0598 - acc: 0.9847 - val_loss: 0.6323 - val_acc: 0.8386\n",
      "last model loss ------------------------------------------0.632252\n",
      "Found 596 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "9/9 [==============================] - 8s 933ms/step - loss: 0.0613 - acc: 0.9790 - val_loss: 0.5886 - val_acc: 0.8458\n",
      "last model loss ------------------------------------------0.588627\n",
      "Found 544 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "8/8 [==============================] - 8s 992ms/step - loss: 0.0311 - acc: 0.9902 - val_loss: 0.7312 - val_acc: 0.8230\n",
      "Found 540 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0217 - acc: 0.9941 - val_loss: 0.9228 - val_acc: 0.8033\n",
      "Found 656 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "10/10 [==============================] - 9s 886ms/step - loss: 0.0803 - acc: 0.9795 - val_loss: 1.4432 - val_acc: 0.7322\n",
      "Found 748 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "11/11 [==============================] - 9s 850ms/step - loss: 0.0471 - acc: 0.9909 - val_loss: 1.0023 - val_acc: 0.7792\n",
      "Found 911 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "14/14 [==============================] - 10s 723ms/step - loss: 0.0285 - acc: 0.9933 - val_loss: 0.8383 - val_acc: 0.8069\n",
      "Found 708 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "11/11 [==============================] - 9s 828ms/step - loss: 0.1174 - acc: 0.9613 - val_loss: 0.7827 - val_acc: 0.8315\n",
      "Found 832 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "13/13 [==============================] - 10s 781ms/step - loss: 0.0629 - acc: 0.9796 - val_loss: 0.8597 - val_acc: 0.8078\n",
      "Found 651 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "10/10 [==============================] - 9s 888ms/step - loss: 0.0443 - acc: 0.9937 - val_loss: 1.0302 - val_acc: 0.7644\n",
      "Found 717 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "11/11 [==============================] - 9s 837ms/step - loss: 0.0879 - acc: 0.9749 - val_loss: 0.9959 - val_acc: 0.7863\n",
      "Found 733 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "11/11 [==============================] - 9s 850ms/step - loss: 0.7124 - acc: 0.7773 - val_loss: 4.3416 - val_acc: 0.4207\n",
      "Found 736 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "11/11 [==============================] - 9s 838ms/step - loss: 0.2180 - acc: 0.9253 - val_loss: 8.8542 - val_acc: 0.1448\n",
      "Found 922 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "14/14 [==============================] - 10s 726ms/step - loss: 0.1696 - acc: 0.9462 - val_loss: 5.3810 - val_acc: 0.2763\n",
      "Found 314 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "4/4 [==============================] - 7s 2s/step - loss: 0.5355 - acc: 0.8241 - val_loss: 2.6995 - val_acc: 0.5472\n",
      "Found 734 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "11/11 [==============================] - 9s 855ms/step - loss: 0.1156 - acc: 0.9670 - val_loss: 2.2776 - val_acc: 0.6661\n",
      "Found 736 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "11/11 [==============================] - 9s 846ms/step - loss: 0.0984 - acc: 0.9688 - val_loss: 2.1355 - val_acc: 0.6813\n",
      "step---------------------- {6}\n",
      "Found 655 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "10/10 [==============================] - 9s 894ms/step - loss: 0.0827 - acc: 0.9717 - val_loss: 2.8981 - val_acc: 0.6133\n",
      "Found 749 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "11/11 [==============================] - 9s 847ms/step - loss: 0.0954 - acc: 0.9653 - val_loss: 2.6392 - val_acc: 0.5937\n",
      "Found 778 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "12/12 [==============================] - 10s 795ms/step - loss: 0.0556 - acc: 0.9856 - val_loss: 1.9448 - val_acc: 0.6339\n",
      "Found 792 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "12/12 [==============================] - 10s 800ms/step - loss: 0.0733 - acc: 0.9712 - val_loss: 1.6585 - val_acc: 0.6308\n",
      "Found 957 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "14/14 [==============================] - 10s 744ms/step - loss: 0.0323 - acc: 0.9944 - val_loss: 1.3194 - val_acc: 0.6916\n",
      "Found 1121 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "17/17 [==============================] - 11s 655ms/step - loss: 0.0630 - acc: 0.9834 - val_loss: 2.0942 - val_acc: 0.5793\n",
      "Found 1123 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "17/17 [==============================] - 11s 654ms/step - loss: 0.0384 - acc: 0.9899 - val_loss: 3.3861 - val_acc: 0.4242\n",
      "Found 1109 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "17/17 [==============================] - 11s 651ms/step - loss: 0.0270 - acc: 0.9917 - val_loss: 1.2404 - val_acc: 0.7264\n",
      "Found 1071 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "16/16 [==============================] - 11s 696ms/step - loss: 0.0361 - acc: 0.9902 - val_loss: 0.5641 - val_acc: 0.8350\n",
      "last model loss ------------------------------------------0.564075\n",
      "Found 754 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "11/11 [==============================] - 9s 845ms/step - loss: 0.0229 - acc: 0.9972 - val_loss: 0.5976 - val_acc: 0.8319\n",
      "Found 596 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "9/9 [==============================] - 9s 967ms/step - loss: 0.0453 - acc: 0.9825 - val_loss: 0.3963 - val_acc: 0.8833\n",
      "last model loss ------------------------------------------0.396276\n",
      "Found 544 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0106 - acc: 0.9961 - val_loss: 0.4806 - val_acc: 0.8713\n",
      "Found 540 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0325 - acc: 0.9877 - val_loss: 0.8677 - val_acc: 0.8100\n",
      "Found 656 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "10/10 [==============================] - 9s 887ms/step - loss: 0.0392 - acc: 0.9858 - val_loss: 0.9703 - val_acc: 0.7984\n",
      "Found 748 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 9s 857ms/step - loss: 0.0296 - acc: 0.9929 - val_loss: 1.2364 - val_acc: 0.7720\n",
      "Found 911 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "14/14 [==============================] - 11s 753ms/step - loss: 0.5957 - acc: 0.8460 - val_loss: 6.6107 - val_acc: 0.3657\n",
      "Found 708 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "11/11 [==============================] - 9s 858ms/step - loss: 0.2233 - acc: 0.9418 - val_loss: 7.8577 - val_acc: 0.2494\n",
      "Found 832 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "13/13 [==============================] - 10s 780ms/step - loss: 0.1761 - acc: 0.9531 - val_loss: 4.2768 - val_acc: 0.3907\n",
      "Found 651 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "10/10 [==============================] - 9s 916ms/step - loss: 0.0828 - acc: 0.9766 - val_loss: 2.5646 - val_acc: 0.5449\n",
      "Found 717 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "11/11 [==============================] - 9s 833ms/step - loss: 0.1337 - acc: 0.9620 - val_loss: 2.8833 - val_acc: 0.5333\n",
      "Found 733 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "11/11 [==============================] - 9s 828ms/step - loss: 0.1020 - acc: 0.9658 - val_loss: 2.6125 - val_acc: 0.5829\n",
      "Found 736 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "11/11 [==============================] - 9s 844ms/step - loss: 0.0867 - acc: 0.9643 - val_loss: 2.0775 - val_acc: 0.6156\n",
      "Found 922 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "14/14 [==============================] - 10s 725ms/step - loss: 0.1443 - acc: 0.9567 - val_loss: 1.5491 - val_acc: 0.6813\n",
      "Found 314 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "4/4 [==============================] - 7s 2s/step - loss: 0.1187 - acc: 0.9644 - val_loss: 1.6147 - val_acc: 0.6638\n",
      "Found 734 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "11/11 [==============================] - 9s 847ms/step - loss: 0.0626 - acc: 0.9829 - val_loss: 1.6930 - val_acc: 0.6755\n",
      "Found 736 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "11/11 [==============================] - 9s 847ms/step - loss: 0.0699 - acc: 0.9773 - val_loss: 1.2625 - val_acc: 0.7483\n",
      "step---------------------- {7}\n",
      "Found 655 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "10/10 [==============================] - 9s 886ms/step - loss: 0.0972 - acc: 0.9717 - val_loss: 1.0691 - val_acc: 0.7519\n",
      "Found 749 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "11/11 [==============================] - 9s 842ms/step - loss: 0.0636 - acc: 0.9838 - val_loss: 1.7796 - val_acc: 0.6120\n",
      "Found 778 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "12/12 [==============================] - 9s 791ms/step - loss: 0.0644 - acc: 0.9791 - val_loss: 3.2840 - val_acc: 0.4403\n",
      "Found 792 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "12/12 [==============================] - 10s 801ms/step - loss: 0.0563 - acc: 0.9843 - val_loss: 5.1062 - val_acc: 0.3523\n",
      "Found 957 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "14/14 [==============================] - 10s 743ms/step - loss: 0.0335 - acc: 0.9922 - val_loss: 2.6274 - val_acc: 0.5212\n",
      "Found 1121 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "17/17 [==============================] - 11s 669ms/step - loss: 0.0368 - acc: 0.9901 - val_loss: 1.5656 - val_acc: 0.6392\n",
      "Found 1123 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "17/17 [==============================] - 11s 653ms/step - loss: 0.0204 - acc: 0.9954 - val_loss: 0.4976 - val_acc: 0.8350\n",
      "Found 1109 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "17/17 [==============================] - 11s 655ms/step - loss: 0.0108 - acc: 0.9972 - val_loss: 0.3106 - val_acc: 0.8994\n",
      "last model loss ------------------------------------------0.310618\n",
      "Found 1071 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "16/16 [==============================] - 11s 679ms/step - loss: 0.4416 - acc: 0.8638 - val_loss: 7.9378 - val_acc: 0.2722\n",
      "Found 754 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "11/11 [==============================] - 9s 861ms/step - loss: 0.0778 - acc: 0.9769 - val_loss: 2.2124 - val_acc: 0.6518\n",
      "Found 596 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "9/9 [==============================] - 8s 939ms/step - loss: 0.0684 - acc: 0.9878 - val_loss: 3.0822 - val_acc: 0.6013\n",
      "Found 544 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0452 - acc: 0.9902 - val_loss: 3.3937 - val_acc: 0.5950\n",
      "Found 540 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0151 - acc: 1.0000 - val_loss: 3.6431 - val_acc: 0.5937\n",
      "Found 656 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "10/10 [==============================] - 9s 880ms/step - loss: 0.0506 - acc: 0.9847 - val_loss: 4.8897 - val_acc: 0.5203\n",
      "Found 748 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "11/11 [==============================] - 9s 845ms/step - loss: 0.0574 - acc: 0.9888 - val_loss: 3.9302 - val_acc: 0.5740\n",
      "Found 911 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "14/14 [==============================] - 10s 728ms/step - loss: 0.0125 - acc: 0.9989 - val_loss: 2.3014 - val_acc: 0.6893\n",
      "Found 708 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "11/11 [==============================] - 9s 860ms/step - loss: 0.0694 - acc: 0.9773 - val_loss: 1.5490 - val_acc: 0.7523\n",
      "Found 832 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "13/13 [==============================] - 10s 782ms/step - loss: 0.0595 - acc: 0.9796 - val_loss: 1.8134 - val_acc: 0.7193\n",
      "Found 651 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "10/10 [==============================] - 9s 896ms/step - loss: 0.1313 - acc: 0.9821 - val_loss: 1.0896 - val_acc: 0.8131\n",
      "Found 717 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "11/11 [==============================] - 9s 826ms/step - loss: 0.0924 - acc: 0.9685 - val_loss: 0.7576 - val_acc: 0.8507\n",
      "Found 733 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "11/11 [==============================] - 9s 842ms/step - loss: 0.0292 - acc: 0.9886 - val_loss: 0.7829 - val_acc: 0.8449\n",
      "Found 736 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "11/11 [==============================] - 9s 847ms/step - loss: 0.0356 - acc: 0.9914 - val_loss: 0.7231 - val_acc: 0.8453\n",
      "Found 922 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "14/14 [==============================] - 10s 742ms/step - loss: 0.0876 - acc: 0.9743 - val_loss: 0.9256 - val_acc: 0.8006\n",
      "Found 314 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "4/4 [==============================] - 7s 2s/step - loss: 0.0423 - acc: 0.9882 - val_loss: 0.7977 - val_acc: 0.8105\n",
      "Found 734 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "11/11 [==============================] - 9s 849ms/step - loss: 0.0261 - acc: 0.9900 - val_loss: 0.6876 - val_acc: 0.8297\n",
      "Found 736 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "11/11 [==============================] - 9s 835ms/step - loss: 0.0516 - acc: 0.9873 - val_loss: 0.5090 - val_acc: 0.8578\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step---------------------- {8}\n",
      "Found 655 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "10/10 [==============================] - 9s 883ms/step - loss: 0.0376 - acc: 0.9843 - val_loss: 0.4802 - val_acc: 0.8717\n",
      "Found 749 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "11/11 [==============================] - 9s 856ms/step - loss: 0.8037 - acc: 0.7629 - val_loss: 6.8792 - val_acc: 0.1301\n",
      "Found 778 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "12/12 [==============================] - 9s 789ms/step - loss: 0.1357 - acc: 0.9581 - val_loss: 4.9116 - val_acc: 0.3849\n",
      "Found 792 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "12/12 [==============================] - 10s 797ms/step - loss: 0.1102 - acc: 0.9686 - val_loss: 2.6081 - val_acc: 0.5561\n",
      "Found 957 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "14/14 [==============================] - 10s 745ms/step - loss: 0.0466 - acc: 0.9866 - val_loss: 3.1267 - val_acc: 0.4586\n",
      "Found 1121 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "17/17 [==============================] - 11s 664ms/step - loss: 0.0609 - acc: 0.9761 - val_loss: 3.3653 - val_acc: 0.4850\n",
      "Found 1123 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "17/17 [==============================] - 11s 660ms/step - loss: 0.0437 - acc: 0.9908 - val_loss: 0.8751 - val_acc: 0.7461\n",
      "Found 1109 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "17/17 [==============================] - 11s 668ms/step - loss: 0.0209 - acc: 0.9936 - val_loss: 0.5674 - val_acc: 0.8270\n",
      "Found 1071 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "16/16 [==============================] - 11s 693ms/step - loss: 0.0297 - acc: 0.9941 - val_loss: 0.5762 - val_acc: 0.8310\n",
      "Found 754 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "11/11 [==============================] - 9s 863ms/step - loss: 0.0262 - acc: 0.9939 - val_loss: 0.4756 - val_acc: 0.8610\n",
      "Found 596 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "9/9 [==============================] - 9s 952ms/step - loss: 0.1741 - acc: 0.9580 - val_loss: 2.3083 - val_acc: 0.5919\n",
      "Found 544 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0268 - acc: 0.9921 - val_loss: 4.8823 - val_acc: 0.4359\n",
      "Found 540 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0399 - acc: 0.9902 - val_loss: 6.2041 - val_acc: 0.3835\n",
      "Found 656 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "10/10 [==============================] - 9s 903ms/step - loss: 0.0568 - acc: 0.9844 - val_loss: 7.3144 - val_acc: 0.3304\n",
      "Found 748 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "11/11 [==============================] - 9s 852ms/step - loss: 0.0619 - acc: 0.9809 - val_loss: 7.3359 - val_acc: 0.2673\n",
      "Found 911 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "14/14 [==============================] - 10s 730ms/step - loss: 0.0115 - acc: 0.9978 - val_loss: 4.6421 - val_acc: 0.4533\n",
      "Found 708 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "11/11 [==============================] - 9s 825ms/step - loss: 0.0745 - acc: 0.9714 - val_loss: 5.4501 - val_acc: 0.3970\n",
      "Found 832 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "13/13 [==============================] - 10s 776ms/step - loss: 0.2401 - acc: 0.9303 - val_loss: 6.3387 - val_acc: 0.2861\n",
      "Found 651 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "10/10 [==============================] - 9s 889ms/step - loss: 0.4874 - acc: 0.8917 - val_loss: 4.4126 - val_acc: 0.4131\n",
      "Found 717 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "11/11 [==============================] - 9s 832ms/step - loss: 0.1717 - acc: 0.9612 - val_loss: 13.2730 - val_acc: 0.1162\n",
      "Found 733 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "11/11 [==============================] - 9s 845ms/step - loss: 0.1477 - acc: 0.9513 - val_loss: 10.7145 - val_acc: 0.1851\n",
      "Found 736 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "11/11 [==============================] - 9s 841ms/step - loss: 0.0991 - acc: 0.9673 - val_loss: 3.0166 - val_acc: 0.5753\n",
      "Found 922 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "14/14 [==============================] - 10s 739ms/step - loss: 0.1090 - acc: 0.9638 - val_loss: 4.2715 - val_acc: 0.4350\n",
      "Found 314 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "4/4 [==============================] - 7s 2s/step - loss: 0.1481 - acc: 0.9531 - val_loss: 5.0224 - val_acc: 0.4001\n",
      "Found 734 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "11/11 [==============================] - 9s 836ms/step - loss: 0.0657 - acc: 0.9800 - val_loss: 5.2042 - val_acc: 0.3438\n",
      "Found 736 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "11/11 [==============================] - 9s 835ms/step - loss: 0.0673 - acc: 0.9815 - val_loss: 1.8746 - val_acc: 0.6495\n",
      "step---------------------- {9}\n",
      "Found 655 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "10/10 [==============================] - 9s 914ms/step - loss: 0.0582 - acc: 0.9828 - val_loss: 1.1912 - val_acc: 0.7506\n",
      "Found 749 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "11/11 [==============================] - 9s 827ms/step - loss: 0.7260 - acc: 0.8371 - val_loss: 2.5293 - val_acc: 0.5539\n",
      "Found 778 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "12/12 [==============================] - 9s 790ms/step - loss: 0.1563 - acc: 0.9489 - val_loss: 2.1865 - val_acc: 0.6312\n",
      "Found 792 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "12/12 [==============================] - 10s 796ms/step - loss: 0.1201 - acc: 0.9660 - val_loss: 2.5498 - val_acc: 0.5780\n",
      "Found 957 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "14/14 [==============================] - 10s 743ms/step - loss: 0.0564 - acc: 0.9866 - val_loss: 3.2482 - val_acc: 0.5543\n",
      "Found 1121 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "17/17 [==============================] - 11s 655ms/step - loss: 0.6699 - acc: 0.8436 - val_loss: 13.8796 - val_acc: 0.0916\n",
      "Found 1123 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "17/17 [==============================] - 11s 672ms/step - loss: 0.1472 - acc: 0.9549 - val_loss: 12.9898 - val_acc: 0.0966\n",
      "Found 1109 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "17/17 [==============================] - 11s 655ms/step - loss: 0.0928 - acc: 0.9733 - val_loss: 9.6632 - val_acc: 0.2257\n",
      "Found 1071 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "16/16 [==============================] - 11s 680ms/step - loss: 0.0846 - acc: 0.9775 - val_loss: 5.9884 - val_acc: 0.4466\n",
      "Found 754 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "11/11 [==============================] - 9s 850ms/step - loss: 0.0546 - acc: 0.9797 - val_loss: 4.1661 - val_acc: 0.5078\n",
      "Found 596 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "9/9 [==============================] - 8s 944ms/step - loss: 0.0633 - acc: 0.9772 - val_loss: 2.3068 - val_acc: 0.5995\n",
      "Found 544 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 8s 1s/step - loss: 0.0451 - acc: 0.9882 - val_loss: 2.1553 - val_acc: 0.6165\n",
      "Found 540 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0266 - acc: 0.9941 - val_loss: 1.6265 - val_acc: 0.7059\n",
      "Found 656 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "10/10 [==============================] - 9s 884ms/step - loss: 0.1012 - acc: 0.9769 - val_loss: 2.2448 - val_acc: 0.6477\n",
      "Found 748 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "11/11 [==============================] - 9s 852ms/step - loss: 0.1048 - acc: 0.9692 - val_loss: 2.3029 - val_acc: 0.6634\n",
      "Found 911 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "14/14 [==============================] - 10s 726ms/step - loss: 0.1578 - acc: 0.9619 - val_loss: 5.5484 - val_acc: 0.4131\n",
      "Found 708 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "11/11 [==============================] - 9s 840ms/step - loss: 0.3805 - acc: 0.8569 - val_loss: 11.2029 - val_acc: 0.1480\n",
      "Found 832 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "13/13 [==============================] - 10s 783ms/step - loss: 0.1330 - acc: 0.9591 - val_loss: 10.8760 - val_acc: 0.1609\n",
      "Found 651 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "10/10 [==============================] - 9s 885ms/step - loss: 0.9420 - acc: 0.7653 - val_loss: 10.3670 - val_acc: 0.2620\n",
      "Found 717 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "11/11 [==============================] - 9s 848ms/step - loss: 0.2803 - acc: 0.9132 - val_loss: 9.1311 - val_acc: 0.2955\n",
      "Found 733 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "11/11 [==============================] - 9s 839ms/step - loss: 0.5947 - acc: 0.8645 - val_loss: 12.1995 - val_acc: 0.1596\n",
      "Found 736 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "11/11 [==============================] - 9s 848ms/step - loss: 0.3939 - acc: 0.8862 - val_loss: 12.7544 - val_acc: 0.1068\n",
      "Found 922 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "14/14 [==============================] - 10s 725ms/step - loss: 0.6415 - acc: 0.8278 - val_loss: 6.8477 - val_acc: 0.2553\n",
      "Found 314 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "4/4 [==============================] - 7s 2s/step - loss: 0.7043 - acc: 0.7737 - val_loss: 1.7163 - val_acc: 0.5798\n",
      "Found 734 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "11/11 [==============================] - 9s 838ms/step - loss: 0.1661 - acc: 0.9529 - val_loss: 3.2607 - val_acc: 0.4989\n",
      "Found 736 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "11/11 [==============================] - 9s 837ms/step - loss: 0.4038 - acc: 0.8842 - val_loss: 7.0420 - val_acc: 0.2915\n"
     ]
    }
   ],
   "source": [
    "model = train_model(restNet_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda/lib/python3.5/site-packages/ipykernel_launcher.py:19: FutureWarning: set_value is deprecated and will be removed in a future release. Please use .at[] or .iat[] accessors instead\n",
      "/home/ubuntu/anaconda/lib/python3.5/site-packages/ipykernel_launcher.py:22: FutureWarning: set_value is deprecated and will be removed in a future release. Please use .at[] or .iat[] accessors instead\n"
     ]
    }
   ],
   "source": [
    "test_model(model, 'pred.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 0 images belonging to 0 classes.\n"
     ]
    }
   ],
   "source": [
    "test_model_2(model, 'pred.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 input_6\n",
      "1 conv1\n",
      "2 bn_conv1\n",
      "3 activation_246\n",
      "4 max_pooling2d_6\n",
      "5 res2a_branch2a\n",
      "6 bn2a_branch2a\n",
      "7 activation_247\n",
      "8 res2a_branch2b\n",
      "9 bn2a_branch2b\n",
      "10 activation_248\n",
      "11 res2a_branch2c\n",
      "12 res2a_branch1\n",
      "13 bn2a_branch2c\n",
      "14 bn2a_branch1\n",
      "15 add_81\n",
      "16 activation_249\n",
      "17 res2b_branch2a\n",
      "18 bn2b_branch2a\n",
      "19 activation_250\n",
      "20 res2b_branch2b\n",
      "21 bn2b_branch2b\n",
      "22 activation_251\n",
      "23 res2b_branch2c\n",
      "24 bn2b_branch2c\n",
      "25 add_82\n",
      "26 activation_252\n",
      "27 res2c_branch2a\n",
      "28 bn2c_branch2a\n",
      "29 activation_253\n",
      "30 res2c_branch2b\n",
      "31 bn2c_branch2b\n",
      "32 activation_254\n",
      "33 res2c_branch2c\n",
      "34 bn2c_branch2c\n",
      "35 add_83\n",
      "36 activation_255\n",
      "37 res3a_branch2a\n",
      "38 bn3a_branch2a\n",
      "39 activation_256\n",
      "40 res3a_branch2b\n",
      "41 bn3a_branch2b\n",
      "42 activation_257\n",
      "43 res3a_branch2c\n",
      "44 res3a_branch1\n",
      "45 bn3a_branch2c\n",
      "46 bn3a_branch1\n",
      "47 add_84\n",
      "48 activation_258\n",
      "49 res3b_branch2a\n",
      "50 bn3b_branch2a\n",
      "51 activation_259\n",
      "52 res3b_branch2b\n",
      "53 bn3b_branch2b\n",
      "54 activation_260\n",
      "55 res3b_branch2c\n",
      "56 bn3b_branch2c\n",
      "57 add_85\n",
      "58 activation_261\n",
      "59 res3c_branch2a\n",
      "60 bn3c_branch2a\n",
      "61 activation_262\n",
      "62 res3c_branch2b\n",
      "63 bn3c_branch2b\n",
      "64 activation_263\n",
      "65 res3c_branch2c\n",
      "66 bn3c_branch2c\n",
      "67 add_86\n",
      "68 activation_264\n",
      "69 res3d_branch2a\n",
      "70 bn3d_branch2a\n",
      "71 activation_265\n",
      "72 res3d_branch2b\n",
      "73 bn3d_branch2b\n",
      "74 activation_266\n",
      "75 res3d_branch2c\n",
      "76 bn3d_branch2c\n",
      "77 add_87\n",
      "78 activation_267\n",
      "79 res4a_branch2a\n",
      "80 bn4a_branch2a\n",
      "81 activation_268\n",
      "82 res4a_branch2b\n",
      "83 bn4a_branch2b\n",
      "84 activation_269\n",
      "85 res4a_branch2c\n",
      "86 res4a_branch1\n",
      "87 bn4a_branch2c\n",
      "88 bn4a_branch1\n",
      "89 add_88\n",
      "90 activation_270\n",
      "91 res4b_branch2a\n",
      "92 bn4b_branch2a\n",
      "93 activation_271\n",
      "94 res4b_branch2b\n",
      "95 bn4b_branch2b\n",
      "96 activation_272\n",
      "97 res4b_branch2c\n",
      "98 bn4b_branch2c\n",
      "99 add_89\n",
      "100 activation_273\n",
      "101 res4c_branch2a\n",
      "102 bn4c_branch2a\n",
      "103 activation_274\n",
      "104 res4c_branch2b\n",
      "105 bn4c_branch2b\n",
      "106 activation_275\n",
      "107 res4c_branch2c\n",
      "108 bn4c_branch2c\n",
      "109 add_90\n",
      "110 activation_276\n",
      "111 res4d_branch2a\n",
      "112 bn4d_branch2a\n",
      "113 activation_277\n",
      "114 res4d_branch2b\n",
      "115 bn4d_branch2b\n",
      "116 activation_278\n",
      "117 res4d_branch2c\n",
      "118 bn4d_branch2c\n",
      "119 add_91\n",
      "120 activation_279\n",
      "121 res4e_branch2a\n",
      "122 bn4e_branch2a\n",
      "123 activation_280\n",
      "124 res4e_branch2b\n",
      "125 bn4e_branch2b\n",
      "126 activation_281\n",
      "127 res4e_branch2c\n",
      "128 bn4e_branch2c\n",
      "129 add_92\n",
      "130 activation_282\n",
      "131 res4f_branch2a\n",
      "132 bn4f_branch2a\n",
      "133 activation_283\n",
      "134 res4f_branch2b\n",
      "135 bn4f_branch2b\n",
      "136 activation_284\n",
      "137 res4f_branch2c\n",
      "138 bn4f_branch2c\n",
      "139 add_93\n",
      "140 activation_285\n",
      "141 res5a_branch2a\n",
      "142 bn5a_branch2a\n",
      "143 activation_286\n",
      "144 res5a_branch2b\n",
      "145 bn5a_branch2b\n",
      "146 activation_287\n",
      "147 res5a_branch2c\n",
      "148 res5a_branch1\n",
      "149 bn5a_branch2c\n",
      "150 bn5a_branch1\n",
      "151 add_94\n",
      "152 activation_288\n",
      "153 res5b_branch2a\n",
      "154 bn5b_branch2a\n",
      "155 activation_289\n",
      "156 res5b_branch2b\n",
      "157 bn5b_branch2b\n",
      "158 activation_290\n",
      "159 res5b_branch2c\n",
      "160 bn5b_branch2c\n",
      "161 add_95\n",
      "162 activation_291\n",
      "163 res5c_branch2a\n",
      "164 bn5c_branch2a\n",
      "165 activation_292\n",
      "166 res5c_branch2b\n",
      "167 bn5c_branch2b\n",
      "168 activation_293\n",
      "169 res5c_branch2c\n",
      "170 bn5c_branch2c\n",
      "171 add_96\n",
      "172 activation_294\n",
      "173 avg_pool\n",
      "step {0}\n",
      "Found 655 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "10/10 [==============================] - 16s 2s/step - loss: 2.3710 - acc: 0.2437 - val_loss: 9.2597 - val_acc: 0.1109\n",
      "Found 749 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "11/11 [==============================] - 9s 818ms/step - loss: 1.3438 - acc: 0.3999 - val_loss: 12.5160 - val_acc: 0.1135\n",
      "Found 778 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "12/12 [==============================] - 9s 769ms/step - loss: 1.1599 - acc: 0.4858 - val_loss: 13.2333 - val_acc: 0.1135\n",
      "Found 792 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "12/12 [==============================] - 9s 767ms/step - loss: 1.0766 - acc: 0.6373 - val_loss: 14.0820 - val_acc: 0.1118\n",
      "Found 957 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "14/14 [==============================] - 10s 724ms/step - loss: 0.7047 - acc: 0.7763 - val_loss: 12.8358 - val_acc: 0.1390\n",
      "Found 1121 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "17/17 [==============================] - 11s 637ms/step - loss: 0.6839 - acc: 0.7873 - val_loss: 13.8196 - val_acc: 0.1426\n",
      "Found 1123 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "17/17 [==============================] - 11s 643ms/step - loss: 0.4343 - acc: 0.8353 - val_loss: 11.1423 - val_acc: 0.1940\n",
      "Found 1109 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "17/17 [==============================] - 11s 638ms/step - loss: 0.3876 - acc: 0.8392 - val_loss: 10.2165 - val_acc: 0.0966\n",
      "Found 1071 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "16/16 [==============================] - 11s 668ms/step - loss: 0.4555 - acc: 0.8553 - val_loss: 13.7353 - val_acc: 0.1274\n",
      "Found 754 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "11/11 [==============================] - 9s 819ms/step - loss: 1.3943 - acc: 0.6435 - val_loss: 4.3333 - val_acc: 0.1386\n",
      "Found 596 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "9/9 [==============================] - 8s 930ms/step - loss: 1.1945 - acc: 0.6608 - val_loss: 4.7219 - val_acc: 0.1149\n",
      "Found 544 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "8/8 [==============================] - 8s 1s/step - loss: 2.1780 - acc: 0.4309 - val_loss: 14.3168 - val_acc: 0.1118\n",
      "Found 540 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.9119 - acc: 0.6958 - val_loss: 13.4945 - val_acc: 0.1417\n",
      "Found 656 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "10/10 [==============================] - 9s 863ms/step - loss: 0.6552 - acc: 0.8179 - val_loss: 14.2159 - val_acc: 0.0930\n",
      "Found 748 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "11/11 [==============================] - 9s 837ms/step - loss: 0.4434 - acc: 0.8707 - val_loss: 7.9690 - val_acc: 0.0899\n",
      "Found 911 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "14/14 [==============================] - 10s 716ms/step - loss: 0.4008 - acc: 0.8924 - val_loss: 11.7023 - val_acc: 0.1672\n",
      "Found 708 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "11/11 [==============================] - 9s 824ms/step - loss: 1.2802 - acc: 0.6245 - val_loss: 1.1921e-07 - val_acc: 0.1109\n",
      "Found 832 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "13/13 [==============================] - 10s 759ms/step - loss: 0.8424 - acc: 0.7512 - val_loss: 14.2367 - val_acc: 0.1104\n",
      "Found 651 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "10/10 [==============================] - 9s 859ms/step - loss: 0.6920 - acc: 0.8088 - val_loss: 14.2523 - val_acc: 0.1051\n",
      "Found 717 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "11/11 [==============================] - 9s 807ms/step - loss: 0.5923 - acc: 0.8227 - val_loss: 12.2182 - val_acc: 0.1842\n",
      "Found 733 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "11/11 [==============================] - 9s 821ms/step - loss: 0.7614 - acc: 0.7486 - val_loss: 14.3896 - val_acc: 0.1037\n",
      "Found 736 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "11/11 [==============================] - 9s 820ms/step - loss: 0.5714 - acc: 0.8120 - val_loss: 12.1176 - val_acc: 0.1328\n",
      "Found 922 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "14/14 [==============================] - 10s 712ms/step - loss: 0.5642 - acc: 0.8278 - val_loss: 12.7148 - val_acc: 0.1395\n",
      "Found 314 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "4/4 [==============================] - 7s 2s/step - loss: 1.3026 - acc: 0.6380 - val_loss: 9.3227 - val_acc: 0.1980\n",
      "Found 734 images belonging to 10 classes.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "11/11 [==============================] - 9s 832ms/step - loss: 0.7194 - acc: 0.7728 - val_loss: 13.7494 - val_acc: 0.1167\n",
      "Found 736 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "11/11 [==============================] - 9s 809ms/step - loss: 0.7150 - acc: 0.7938 - val_loss: 12.5258 - val_acc: 0.1685\n",
      "step {1}\n",
      "Found 655 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "10/10 [==============================] - 9s 859ms/step - loss: 0.5128 - acc: 0.8477 - val_loss: 13.6141 - val_acc: 0.1381\n",
      "Found 749 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "11/11 [==============================] - 9s 825ms/step - loss: 1.0530 - acc: 0.7049 - val_loss: 12.3854 - val_acc: 0.1225\n",
      "Found 778 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "12/12 [==============================] - 9s 765ms/step - loss: 0.5946 - acc: 0.8312 - val_loss: 14.2116 - val_acc: 0.1113\n",
      "Found 792 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "12/12 [==============================] - 9s 775ms/step - loss: 1.6945 - acc: 0.5217 - val_loss: 12.1451 - val_acc: 0.1296\n",
      "Found 957 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "14/14 [==============================] - 10s 734ms/step - loss: 0.9801 - acc: 0.7095 - val_loss: 11.5208 - val_acc: 0.1690\n",
      "Found 1121 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "17/17 [==============================] - 11s 647ms/step - loss: 0.4774 - acc: 0.8522 - val_loss: 9.8536 - val_acc: 0.2217\n",
      "Found 1123 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "17/17 [==============================] - 11s 635ms/step - loss: 0.4132 - acc: 0.8605 - val_loss: 5.0910 - val_acc: 0.3885\n",
      "Found 1109 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "17/17 [==============================] - 11s 642ms/step - loss: 0.2507 - acc: 0.9208 - val_loss: 9.8855 - val_acc: 0.2043\n",
      "Found 1071 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "16/16 [==============================] - 11s 666ms/step - loss: 0.2898 - acc: 0.9045 - val_loss: 8.0694 - val_acc: 0.2298\n",
      "Found 754 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "11/11 [==============================] - 9s 832ms/step - loss: 0.2207 - acc: 0.9332 - val_loss: 11.4056 - val_acc: 0.2021\n",
      "Found 596 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "9/9 [==============================] - 8s 928ms/step - loss: 0.4557 - acc: 0.8637 - val_loss: 5.8662 - val_acc: 0.2982\n",
      "Found 544 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.3271 - acc: 0.9392 - val_loss: 3.7086 - val_acc: 0.4117\n",
      "Found 540 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.2148 - acc: 0.9082 - val_loss: 4.9182 - val_acc: 0.4131\n",
      "Found 656 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "10/10 [==============================] - 9s 873ms/step - loss: 0.2180 - acc: 0.9353 - val_loss: 4.3543 - val_acc: 0.3983\n",
      "Found 748 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "11/11 [==============================] - 9s 831ms/step - loss: 1.3891 - acc: 0.5764 - val_loss: 6.8845 - val_acc: 0.2888\n",
      "Found 911 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "14/14 [==============================] - 10s 720ms/step - loss: 1.4083 - acc: 0.5976 - val_loss: 6.1488 - val_acc: 0.3268\n",
      "Found 708 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "11/11 [==============================] - 9s 798ms/step - loss: 0.8042 - acc: 0.7129 - val_loss: 5.4424 - val_acc: 0.3594\n",
      "Found 832 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "13/13 [==============================] - 10s 768ms/step - loss: 0.5244 - acc: 0.8714 - val_loss: 4.5250 - val_acc: 0.3737\n",
      "Found 651 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "10/10 [==============================] - 9s 869ms/step - loss: 0.3354 - acc: 0.9112 - val_loss: 10.5096 - val_acc: 0.1457\n",
      "Found 717 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "11/11 [==============================] - 9s 808ms/step - loss: 0.3378 - acc: 0.9097 - val_loss: 12.8389 - val_acc: 0.0899\n",
      "Found 733 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "11/11 [==============================] - 9s 822ms/step - loss: 0.6680 - acc: 0.7984 - val_loss: 8.0239 - val_acc: 0.2749\n",
      "Found 736 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "11/11 [==============================] - 9s 821ms/step - loss: 0.5408 - acc: 0.8234 - val_loss: 7.5473 - val_acc: 0.2843\n",
      "Found 922 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "14/14 [==============================] - 10s 712ms/step - loss: 0.9351 - acc: 0.7535 - val_loss: 9.0958 - val_acc: 0.1444\n",
      "Found 314 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "4/4 [==============================] - 7s 2s/step - loss: 1.5625 - acc: 0.5391 - val_loss: 7.6203 - val_acc: 0.2754\n",
      "Found 734 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "11/11 [==============================] - 9s 806ms/step - loss: 0.3911 - acc: 0.8828 - val_loss: 10.4153 - val_acc: 0.1658\n",
      "Found 736 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "11/11 [==============================] - 9s 829ms/step - loss: 0.5131 - acc: 0.8503 - val_loss: 4.6990 - val_acc: 0.3943\n",
      "step {2}\n",
      "Found 655 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "10/10 [==============================] - 9s 859ms/step - loss: 0.4230 - acc: 0.8616 - val_loss: 8.4720 - val_acc: 0.2530\n",
      "Found 749 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "11/11 [==============================] - 9s 814ms/step - loss: 0.5579 - acc: 0.8455 - val_loss: 8.8748 - val_acc: 0.2253\n",
      "Found 778 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "12/12 [==============================] - 9s 763ms/step - loss: 0.2824 - acc: 0.9176 - val_loss: 12.2571 - val_acc: 0.1073\n",
      "Found 792 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "12/12 [==============================] - 9s 779ms/step - loss: 0.3762 - acc: 0.8854 - val_loss: 13.1456 - val_acc: 0.0930\n",
      "Found 957 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "14/14 [==============================] - 10s 715ms/step - loss: 0.2767 - acc: 0.9205 - val_loss: 10.2628 - val_acc: 0.1810\n",
      "Found 1121 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "17/17 [==============================] - 11s 638ms/step - loss: 0.3940 - acc: 0.8872 - val_loss: 14.4435 - val_acc: 0.0894\n",
      "Found 1123 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "17/17 [==============================] - 11s 642ms/step - loss: 0.3204 - acc: 0.9045 - val_loss: 2.5389 - val_acc: 0.5092\n",
      "Found 1109 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "17/17 [==============================] - 11s 644ms/step - loss: 0.6317 - acc: 0.8388 - val_loss: 3.2927 - val_acc: 0.3612\n",
      "Found 1071 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "16/16 [==============================] - 11s 666ms/step - loss: 0.2669 - acc: 0.9208 - val_loss: 2.2457 - val_acc: 0.5203\n",
      "Found 754 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "11/11 [==============================] - 9s 839ms/step - loss: 0.1890 - acc: 0.9541 - val_loss: 1.9852 - val_acc: 0.5709\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 596 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "9/9 [==============================] - 9s 945ms/step - loss: 0.2362 - acc: 0.9149 - val_loss: 1.5921 - val_acc: 0.6187\n",
      "Found 544 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.1771 - acc: 0.9451 - val_loss: 1.5005 - val_acc: 0.6388\n",
      "Found 540 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.1275 - acc: 0.9657 - val_loss: 1.3337 - val_acc: 0.6710\n",
      "Found 656 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "10/10 [==============================] - 9s 892ms/step - loss: 0.1453 - acc: 0.9719 - val_loss: 1.5156 - val_acc: 0.6361\n",
      "Found 748 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "11/11 [==============================] - 9s 815ms/step - loss: 0.2645 - acc: 0.9188 - val_loss: 1.6099 - val_acc: 0.6218\n",
      "Found 911 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "14/14 [==============================] - 10s 708ms/step - loss: 0.0719 - acc: 0.9764 - val_loss: 1.8280 - val_acc: 0.6491\n",
      "Found 708 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "11/11 [==============================] - 9s 799ms/step - loss: 0.5702 - acc: 0.8554 - val_loss: 8.3013 - val_acc: 0.2012\n",
      "Found 832 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "13/13 [==============================] - 10s 760ms/step - loss: 0.1455 - acc: 0.9615 - val_loss: 5.5298 - val_acc: 0.3424\n",
      "Found 651 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "10/10 [==============================] - 9s 878ms/step - loss: 0.1588 - acc: 0.9417 - val_loss: 2.0634 - val_acc: 0.5592\n",
      "Found 717 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "11/11 [==============================] - 9s 806ms/step - loss: 0.3314 - acc: 0.9105 - val_loss: 2.9566 - val_acc: 0.4658\n",
      "Found 733 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "11/11 [==============================] - 9s 827ms/step - loss: 0.3102 - acc: 0.9014 - val_loss: 6.0104 - val_acc: 0.3442\n",
      "Found 736 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "11/11 [==============================] - 9s 818ms/step - loss: 0.3591 - acc: 0.8947 - val_loss: 2.1151 - val_acc: 0.5869\n",
      "Found 922 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "14/14 [==============================] - 10s 718ms/step - loss: 0.2821 - acc: 0.9197 - val_loss: 0.8687 - val_acc: 0.7689\n",
      "Found 314 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "4/4 [==============================] - 7s 2s/step - loss: 0.4076 - acc: 0.8611 - val_loss: 0.9407 - val_acc: 0.7215\n",
      "Found 734 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "11/11 [==============================] - 9s 844ms/step - loss: 0.2698 - acc: 0.9276 - val_loss: 1.8902 - val_acc: 0.4761\n",
      "Found 736 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "11/11 [==============================] - 9s 821ms/step - loss: 0.1898 - acc: 0.9388 - val_loss: 3.4803 - val_acc: 0.3648\n",
      "step {3}\n",
      "Found 655 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "10/10 [==============================] - 9s 870ms/step - loss: 0.2483 - acc: 0.9214 - val_loss: 2.2935 - val_acc: 0.5212\n",
      "Found 749 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "11/11 [==============================] - 9s 818ms/step - loss: 0.2575 - acc: 0.9320 - val_loss: 2.1359 - val_acc: 0.5668\n",
      "Found 778 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "12/12 [==============================] - 9s 774ms/step - loss: 0.1747 - acc: 0.9502 - val_loss: 1.8570 - val_acc: 0.5735\n",
      "Found 792 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "12/12 [==============================] - 9s 776ms/step - loss: 0.2207 - acc: 0.9267 - val_loss: 2.6581 - val_acc: 0.4283\n",
      "Found 957 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "14/14 [==============================] - 10s 717ms/step - loss: 0.8172 - acc: 0.8145 - val_loss: 3.6646 - val_acc: 0.3205\n",
      "Found 1121 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "17/17 [==============================] - 11s 637ms/step - loss: 0.2344 - acc: 0.9312 - val_loss: 1.6188 - val_acc: 0.5887\n",
      "Found 1123 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "17/17 [==============================] - 11s 644ms/step - loss: 0.1167 - acc: 0.9581 - val_loss: 1.4145 - val_acc: 0.6728\n",
      "Found 1109 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "17/17 [==============================] - 11s 636ms/step - loss: 0.0576 - acc: 0.9899 - val_loss: 1.4461 - val_acc: 0.6638\n",
      "Found 1071 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "16/16 [==============================] - 11s 663ms/step - loss: 0.0817 - acc: 0.9804 - val_loss: 1.1011 - val_acc: 0.6853\n",
      "Found 754 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "11/11 [==============================] - 9s 833ms/step - loss: 0.0750 - acc: 0.9872 - val_loss: 0.7594 - val_acc: 0.7671\n",
      "Found 596 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "9/9 [==============================] - 8s 917ms/step - loss: 0.1379 - acc: 0.9563 - val_loss: 0.8444 - val_acc: 0.7465\n",
      "Found 544 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0632 - acc: 0.9764 - val_loss: 0.6845 - val_acc: 0.7979\n",
      "Found 540 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0567 - acc: 0.9862 - val_loss: 0.6682 - val_acc: 0.8131\n",
      "Found 656 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "10/10 [==============================] - 9s 874ms/step - loss: 0.1049 - acc: 0.9811 - val_loss: 0.8287 - val_acc: 0.7841\n",
      "Found 748 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "11/11 [==============================] - 9s 833ms/step - loss: 0.1327 - acc: 0.9695 - val_loss: 0.9198 - val_acc: 0.7711\n",
      "Found 911 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "14/14 [==============================] - 10s 721ms/step - loss: 0.0780 - acc: 0.9832 - val_loss: 2.3948 - val_acc: 0.5735\n",
      "Found 708 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "11/11 [==============================] - 9s 815ms/step - loss: 1.2122 - acc: 0.6594 - val_loss: 2.8537 - val_acc: 0.3657\n",
      "Found 832 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "13/13 [==============================] - 10s 759ms/step - loss: 0.1654 - acc: 0.9615 - val_loss: 3.6833 - val_acc: 0.3339\n",
      "Found 651 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "10/10 [==============================] - 9s 879ms/step - loss: 0.1766 - acc: 0.9422 - val_loss: 5.5327 - val_acc: 0.2910\n",
      "Found 717 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "11/11 [==============================] - 9s 794ms/step - loss: 0.3178 - acc: 0.9187 - val_loss: 7.2841 - val_acc: 0.2602\n",
      "Found 733 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "11/11 [==============================] - 9s 810ms/step - loss: 0.4085 - acc: 0.8794 - val_loss: 1.9493 - val_acc: 0.5677\n",
      "Found 736 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "11/11 [==============================] - 9s 811ms/step - loss: 0.2313 - acc: 0.9177 - val_loss: 3.4548 - val_acc: 0.4345\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 922 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "14/14 [==============================] - 10s 718ms/step - loss: 0.2283 - acc: 0.9376 - val_loss: 2.6392 - val_acc: 0.5516\n",
      "Found 314 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "4/4 [==============================] - 7s 2s/step - loss: 0.4075 - acc: 0.8525 - val_loss: 2.3578 - val_acc: 0.6232\n",
      "Found 734 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "11/11 [==============================] - 9s 825ms/step - loss: 0.2140 - acc: 0.9444 - val_loss: 2.9189 - val_acc: 0.5494\n",
      "Found 736 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "11/11 [==============================] - 9s 810ms/step - loss: 0.1779 - acc: 0.9619 - val_loss: 1.8849 - val_acc: 0.5695\n",
      "step {4}\n",
      "Found 655 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "10/10 [==============================] - 9s 855ms/step - loss: 0.1212 - acc: 0.9654 - val_loss: 1.7679 - val_acc: 0.6357\n",
      "Found 749 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "11/11 [==============================] - 9s 819ms/step - loss: 0.2623 - acc: 0.9272 - val_loss: 1.3546 - val_acc: 0.6764\n",
      "Found 778 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "12/12 [==============================] - 9s 780ms/step - loss: 0.1123 - acc: 0.9699 - val_loss: 1.8947 - val_acc: 0.6173\n",
      "Found 792 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "12/12 [==============================] - 9s 779ms/step - loss: 0.1746 - acc: 0.9470 - val_loss: 2.5718 - val_acc: 0.5087\n",
      "Found 957 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "14/14 [==============================] - 10s 726ms/step - loss: 0.0558 - acc: 0.9887 - val_loss: 1.4666 - val_acc: 0.6759\n",
      "Found 1121 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "17/17 [==============================] - 11s 643ms/step - loss: 0.1183 - acc: 0.9681 - val_loss: 2.1924 - val_acc: 0.5641\n",
      "Found 1123 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "17/17 [==============================] - 11s 645ms/step - loss: 0.0539 - acc: 0.9855 - val_loss: 1.0446 - val_acc: 0.7564\n",
      "Found 1109 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "17/17 [==============================] - 11s 642ms/step - loss: 0.0426 - acc: 0.9908 - val_loss: 1.8173 - val_acc: 0.6196\n",
      "Found 1071 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "16/16 [==============================] - 10s 654ms/step - loss: 0.1010 - acc: 0.9687 - val_loss: 0.9936 - val_acc: 0.7354\n",
      "Found 754 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "11/11 [==============================] - 9s 838ms/step - loss: 0.0602 - acc: 0.9872 - val_loss: 0.4644 - val_acc: 0.8574\n",
      "Found 596 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "9/9 [==============================] - 8s 919ms/step - loss: 0.0507 - acc: 0.9808 - val_loss: 0.5599 - val_acc: 0.8342\n",
      "Found 544 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0368 - acc: 0.9863 - val_loss: 0.6822 - val_acc: 0.8154\n",
      "Found 540 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0255 - acc: 0.9961 - val_loss: 0.8057 - val_acc: 0.7868\n",
      "Found 656 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "10/10 [==============================] - 9s 866ms/step - loss: 0.0734 - acc: 0.9843 - val_loss: 0.7011 - val_acc: 0.8422\n",
      "Found 748 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "11/11 [==============================] - 9s 814ms/step - loss: 0.0667 - acc: 0.9866 - val_loss: 0.6288 - val_acc: 0.8520\n",
      "Found 911 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "14/14 [==============================] - 10s 716ms/step - loss: 0.0213 - acc: 0.9933 - val_loss: 0.7325 - val_acc: 0.8342\n",
      "Found 708 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "11/11 [==============================] - 9s 814ms/step - loss: 0.3437 - acc: 0.8840 - val_loss: 1.2354 - val_acc: 0.6920\n",
      "Found 832 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "13/13 [==============================] - 10s 761ms/step - loss: 0.6157 - acc: 0.8245 - val_loss: 3.7225 - val_acc: 0.2745\n",
      "Found 651 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "10/10 [==============================] - 9s 863ms/step - loss: 0.1939 - acc: 0.9307 - val_loss: 3.2882 - val_acc: 0.3791\n",
      "Found 717 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "11/11 [==============================] - 9s 805ms/step - loss: 0.7166 - acc: 0.8313 - val_loss: 3.6326 - val_acc: 0.4636\n",
      "Found 733 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "11/11 [==============================] - 9s 831ms/step - loss: 0.2258 - acc: 0.9210 - val_loss: 10.0483 - val_acc: 0.2186\n",
      "Found 736 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "11/11 [==============================] - 9s 816ms/step - loss: 0.3204 - acc: 0.8945 - val_loss: 8.7249 - val_acc: 0.2982\n",
      "Found 922 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "14/14 [==============================] - 10s 703ms/step - loss: 0.2148 - acc: 0.9263 - val_loss: 4.2898 - val_acc: 0.5069\n",
      "Found 314 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "4/4 [==============================] - 7s 2s/step - loss: 0.3435 - acc: 0.8777 - val_loss: 4.4160 - val_acc: 0.5047\n",
      "Found 734 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "11/11 [==============================] - 9s 804ms/step - loss: 0.1914 - acc: 0.9428 - val_loss: 3.5823 - val_acc: 0.4595\n",
      "Found 736 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "11/11 [==============================] - 9s 808ms/step - loss: 0.1481 - acc: 0.9629 - val_loss: 6.4561 - val_acc: 0.3371\n",
      "step {5}\n",
      "Found 655 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "10/10 [==============================] - 9s 864ms/step - loss: 0.1235 - acc: 0.9717 - val_loss: 4.1429 - val_acc: 0.5011\n",
      "Found 749 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "11/11 [==============================] - 9s 813ms/step - loss: 0.2844 - acc: 0.9186 - val_loss: 4.9341 - val_acc: 0.4354\n",
      "Found 778 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "12/12 [==============================] - 9s 773ms/step - loss: 0.1443 - acc: 0.9581 - val_loss: 2.3012 - val_acc: 0.6334\n",
      "Found 792 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "12/12 [==============================] - 9s 772ms/step - loss: 0.1178 - acc: 0.9627 - val_loss: 1.9518 - val_acc: 0.6442\n",
      "Found 957 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "14/14 [==============================] - 10s 730ms/step - loss: 0.0721 - acc: 0.9788 - val_loss: 1.8674 - val_acc: 0.7081\n",
      "Found 1121 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "17/17 [==============================] - 11s 643ms/step - loss: 0.1692 - acc: 0.9475 - val_loss: 1.2907 - val_acc: 0.7076\n",
      "Found 1123 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "17/17 [==============================] - 11s 648ms/step - loss: 0.0681 - acc: 0.9742 - val_loss: 0.7510 - val_acc: 0.7899\n",
      "Found 1109 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "17/17 [==============================] - 11s 640ms/step - loss: 0.6305 - acc: 0.7886 - val_loss: 7.7655 - val_acc: 0.2584\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1071 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "16/16 [==============================] - 11s 677ms/step - loss: 0.2562 - acc: 0.9111 - val_loss: 5.0764 - val_acc: 0.4283\n",
      "Found 754 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "11/11 [==============================] - 9s 833ms/step - loss: 0.0926 - acc: 0.9815 - val_loss: 2.9109 - val_acc: 0.5507\n",
      "Found 596 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "9/9 [==============================] - 8s 922ms/step - loss: 0.1245 - acc: 0.9702 - val_loss: 1.3999 - val_acc: 0.7135\n",
      "Found 544 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.1317 - acc: 0.9650 - val_loss: 1.4261 - val_acc: 0.7135\n",
      "Found 540 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0563 - acc: 0.9883 - val_loss: 2.2719 - val_acc: 0.6571\n",
      "Found 656 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "10/10 [==============================] - 9s 854ms/step - loss: 0.7667 - acc: 0.8158 - val_loss: 6.8214 - val_acc: 0.2731\n",
      "Found 748 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "11/11 [==============================] - 9s 834ms/step - loss: 0.2531 - acc: 0.9261 - val_loss: 5.2232 - val_acc: 0.3447\n",
      "Found 911 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "14/14 [==============================] - 10s 711ms/step - loss: 0.0866 - acc: 0.9831 - val_loss: 4.4218 - val_acc: 0.4770\n",
      "Found 708 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "11/11 [==============================] - 9s 814ms/step - loss: 0.2972 - acc: 0.9184 - val_loss: 4.8481 - val_acc: 0.4318\n",
      "Found 832 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "13/13 [==============================] - 10s 757ms/step - loss: 0.1013 - acc: 0.9736 - val_loss: 2.5344 - val_acc: 0.6214\n",
      "Found 651 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "10/10 [==============================] - 9s 861ms/step - loss: 0.1478 - acc: 0.9595 - val_loss: 2.2961 - val_acc: 0.6544\n",
      "Found 717 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "11/11 [==============================] - 9s 808ms/step - loss: 0.1824 - acc: 0.9442 - val_loss: 4.0599 - val_acc: 0.4135\n",
      "Found 733 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "11/11 [==============================] - 9s 819ms/step - loss: 0.2339 - acc: 0.9298 - val_loss: 2.5685 - val_acc: 0.6008\n",
      "Found 736 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "11/11 [==============================] - 9s 818ms/step - loss: 1.2875 - acc: 0.6415 - val_loss: 9.2463 - val_acc: 0.2016\n",
      "Found 922 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "14/14 [==============================] - 10s 714ms/step - loss: 0.2936 - acc: 0.9250 - val_loss: 10.8037 - val_acc: 0.1498\n",
      "Found 314 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "4/4 [==============================] - 7s 2s/step - loss: 0.7280 - acc: 0.7910 - val_loss: 4.8095 - val_acc: 0.3393\n",
      "Found 734 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "11/11 [==============================] - 9s 812ms/step - loss: 0.2144 - acc: 0.9300 - val_loss: 8.3950 - val_acc: 0.2105\n",
      "Found 736 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "11/11 [==============================] - 9s 818ms/step - loss: 0.1202 - acc: 0.9688 - val_loss: 3.7316 - val_acc: 0.4761\n",
      "step {6}\n",
      "Found 655 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "10/10 [==============================] - 8s 846ms/step - loss: 0.0968 - acc: 0.9750 - val_loss: 2.1493 - val_acc: 0.6044\n",
      "Found 749 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "11/11 [==============================] - 9s 818ms/step - loss: 0.1898 - acc: 0.9468 - val_loss: 1.1000 - val_acc: 0.6911\n",
      "Found 778 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "12/12 [==============================] - 9s 770ms/step - loss: 0.1155 - acc: 0.9673 - val_loss: 1.0984 - val_acc: 0.7219\n",
      "Found 792 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "12/12 [==============================] - 9s 783ms/step - loss: 0.1466 - acc: 0.9562 - val_loss: 1.4795 - val_acc: 0.6826\n",
      "Found 957 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "14/14 [==============================] - 10s 735ms/step - loss: 0.0500 - acc: 0.9877 - val_loss: 2.0298 - val_acc: 0.6272\n",
      "Found 1121 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "17/17 [==============================] - 11s 648ms/step - loss: 0.1456 - acc: 0.9578 - val_loss: 1.0061 - val_acc: 0.7287\n",
      "Found 1123 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "17/17 [==============================] - 11s 640ms/step - loss: 0.0482 - acc: 0.9829 - val_loss: 1.0618 - val_acc: 0.7425\n",
      "Found 1109 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "17/17 [==============================] - 11s 638ms/step - loss: 0.0353 - acc: 0.9908 - val_loss: 1.1324 - val_acc: 0.7591\n",
      "Found 1071 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "16/16 [==============================] - 11s 673ms/step - loss: 0.0510 - acc: 0.9824 - val_loss: 0.7754 - val_acc: 0.8105\n",
      "Found 754 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "11/11 [==============================] - 9s 835ms/step - loss: 0.0705 - acc: 0.9815 - val_loss: 0.5802 - val_acc: 0.8306\n",
      "Found 596 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "9/9 [==============================] - 8s 923ms/step - loss: 0.0703 - acc: 0.9808 - val_loss: 0.7926 - val_acc: 0.7921\n",
      "Found 544 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "8/8 [==============================] - 8s 978ms/step - loss: 0.0381 - acc: 0.9921 - val_loss: 0.6544 - val_acc: 0.8060\n",
      "Found 540 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0307 - acc: 0.9902 - val_loss: 0.6210 - val_acc: 0.8190\n",
      "Found 656 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "10/10 [==============================] - 9s 872ms/step - loss: 0.0977 - acc: 0.9863 - val_loss: 1.0242 - val_acc: 0.7702\n",
      "Found 748 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "11/11 [==============================] - 9s 831ms/step - loss: 0.0924 - acc: 0.9801 - val_loss: 0.6434 - val_acc: 0.8373\n",
      "Found 911 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "14/14 [==============================] - 10s 713ms/step - loss: 0.0508 - acc: 0.9832 - val_loss: 0.7286 - val_acc: 0.8024\n",
      "Found 708 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "11/11 [==============================] - 9s 804ms/step - loss: 0.4038 - acc: 0.8922 - val_loss: 1.4220 - val_acc: 0.6066\n",
      "Found 832 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "13/13 [==============================] - 10s 757ms/step - loss: 0.0887 - acc: 0.9820 - val_loss: 3.2018 - val_acc: 0.3487\n",
      "Found 651 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "10/10 [==============================] - 9s 887ms/step - loss: 0.0635 - acc: 0.9812 - val_loss: 2.5877 - val_acc: 0.4578\n",
      "Found 717 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "11/11 [==============================] - 9s 811ms/step - loss: 0.1971 - acc: 0.9355 - val_loss: 5.7298 - val_acc: 0.3178\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 733 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "11/11 [==============================] - 9s 815ms/step - loss: 0.1414 - acc: 0.9613 - val_loss: 6.3784 - val_acc: 0.2937\n",
      "Found 736 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "11/11 [==============================] - 9s 831ms/step - loss: 0.0990 - acc: 0.9688 - val_loss: 2.2471 - val_acc: 0.6267\n",
      "Found 922 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "14/14 [==============================] - 10s 717ms/step - loss: 0.0995 - acc: 0.9709 - val_loss: 1.2654 - val_acc: 0.7479\n",
      "Found 314 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "4/4 [==============================] - 7s 2s/step - loss: 0.1338 - acc: 0.9607 - val_loss: 0.8640 - val_acc: 0.8002\n",
      "Found 734 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "11/11 [==============================] - 9s 810ms/step - loss: 0.0984 - acc: 0.9714 - val_loss: 1.2656 - val_acc: 0.7738\n",
      "Found 736 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "11/11 [==============================] - 9s 847ms/step - loss: 0.0493 - acc: 0.9858 - val_loss: 1.3738 - val_acc: 0.7407\n",
      "step {7}\n",
      "Found 655 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "10/10 [==============================] - 9s 866ms/step - loss: 0.6437 - acc: 0.7896 - val_loss: 1.2467 - val_acc: 0.7215\n",
      "Found 749 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "11/11 [==============================] - 9s 827ms/step - loss: 0.1711 - acc: 0.9574 - val_loss: 1.7403 - val_acc: 0.5923\n",
      "Found 778 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "12/12 [==============================] - 9s 789ms/step - loss: 0.1024 - acc: 0.9753 - val_loss: 1.5687 - val_acc: 0.6312\n",
      "Found 792 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "12/12 [==============================] - 9s 775ms/step - loss: 0.1557 - acc: 0.9494 - val_loss: 5.4246 - val_acc: 0.2906\n",
      "Found 957 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "14/14 [==============================] - 10s 732ms/step - loss: 0.0428 - acc: 0.9900 - val_loss: 3.1355 - val_acc: 0.5074\n",
      "Found 1121 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "17/17 [==============================] - 11s 643ms/step - loss: 0.3645 - acc: 0.8973 - val_loss: 2.9979 - val_acc: 0.4600\n",
      "Found 1123 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "17/17 [==============================] - 11s 645ms/step - loss: 0.0412 - acc: 0.9917 - val_loss: 1.2444 - val_acc: 0.6777\n",
      "Found 1109 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "17/17 [==============================] - 11s 637ms/step - loss: 0.0352 - acc: 0.9926 - val_loss: 0.9834 - val_acc: 0.7823\n",
      "Found 1071 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "16/16 [==============================] - 11s 679ms/step - loss: 0.0613 - acc: 0.9795 - val_loss: 0.5623 - val_acc: 0.8502\n",
      "Found 754 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "11/11 [==============================] - 9s 834ms/step - loss: 0.0307 - acc: 0.9900 - val_loss: 0.4015 - val_acc: 0.8762\n",
      "Found 596 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "9/9 [==============================] - 8s 914ms/step - loss: 0.0326 - acc: 0.9895 - val_loss: 0.6057 - val_acc: 0.8373\n",
      "Found 544 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "8/8 [==============================] - 8s 976ms/step - loss: 0.0479 - acc: 0.9867 - val_loss: 0.4281 - val_acc: 0.8744\n",
      "Found 540 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0211 - acc: 0.9980 - val_loss: 0.4950 - val_acc: 0.8547\n",
      "Found 656 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "10/10 [==============================] - 9s 871ms/step - loss: 0.0799 - acc: 0.9800 - val_loss: 0.4381 - val_acc: 0.8619\n",
      "Found 748 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "11/11 [==============================] - 9s 840ms/step - loss: 0.0595 - acc: 0.9858 - val_loss: 0.5430 - val_acc: 0.8534\n",
      "Found 911 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "14/14 [==============================] - 10s 715ms/step - loss: 0.0257 - acc: 0.9933 - val_loss: 0.6017 - val_acc: 0.8592\n",
      "Found 708 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "11/11 [==============================] - 9s 833ms/step - loss: 0.0768 - acc: 0.9801 - val_loss: 0.5844 - val_acc: 0.8601\n",
      "Found 832 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "13/13 [==============================] - 10s 765ms/step - loss: 0.0530 - acc: 0.9844 - val_loss: 0.4775 - val_acc: 0.8869\n",
      "Found 651 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "10/10 [==============================] - 9s 860ms/step - loss: 0.0368 - acc: 0.9853 - val_loss: 0.4575 - val_acc: 0.8909\n",
      "Found 717 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "11/11 [==============================] - 9s 822ms/step - loss: 0.1324 - acc: 0.9663 - val_loss: 0.4765 - val_acc: 0.8708\n",
      "Found 733 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "11/11 [==============================] - 9s 800ms/step - loss: 0.0878 - acc: 0.9755 - val_loss: 0.6062 - val_acc: 0.8266\n",
      "Found 736 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "11/11 [==============================] - 9s 830ms/step - loss: 0.5335 - acc: 0.8800 - val_loss: 5.0599 - val_acc: 0.4341\n",
      "Found 922 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "14/14 [==============================] - 10s 716ms/step - loss: 0.1380 - acc: 0.9597 - val_loss: 5.9572 - val_acc: 0.3862\n",
      "Found 314 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "4/4 [==============================] - 7s 2s/step - loss: 0.4997 - acc: 0.8698 - val_loss: 4.6886 - val_acc: 0.4582\n",
      "Found 734 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "11/11 [==============================] - 9s 828ms/step - loss: 0.2135 - acc: 0.9385 - val_loss: 4.5159 - val_acc: 0.4189\n",
      "Found 736 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "11/11 [==============================] - 9s 827ms/step - loss: 0.1305 - acc: 0.9572 - val_loss: 2.4956 - val_acc: 0.6433\n",
      "step {8}\n",
      "Found 655 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "10/10 [==============================] - 8s 849ms/step - loss: 0.0652 - acc: 0.9827 - val_loss: 1.9312 - val_acc: 0.7072\n",
      "Found 749 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "11/11 [==============================] - 9s 821ms/step - loss: 0.0856 - acc: 0.9761 - val_loss: 1.1561 - val_acc: 0.7993\n",
      "Found 778 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "12/12 [==============================] - 9s 770ms/step - loss: 0.0464 - acc: 0.9935 - val_loss: 0.9148 - val_acc: 0.8207\n",
      "Found 792 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "12/12 [==============================] - 9s 771ms/step - loss: 0.0441 - acc: 0.9869 - val_loss: 0.9361 - val_acc: 0.7796\n",
      "Found 957 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "14/14 [==============================] - 10s 714ms/step - loss: 0.0265 - acc: 0.9955 - val_loss: 1.2071 - val_acc: 0.7394\n",
      "Found 1121 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "17/17 [==============================] - 11s 640ms/step - loss: 0.0922 - acc: 0.9790 - val_loss: 1.0841 - val_acc: 0.7939\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1123 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "17/17 [==============================] - 11s 640ms/step - loss: 0.0218 - acc: 0.9926 - val_loss: 0.6390 - val_acc: 0.8333\n",
      "Found 1109 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "17/17 [==============================] - 11s 643ms/step - loss: 0.0302 - acc: 0.9917 - val_loss: 0.5779 - val_acc: 0.8578\n",
      "Found 1071 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "16/16 [==============================] - 11s 677ms/step - loss: 0.0260 - acc: 0.9941 - val_loss: 0.5156 - val_acc: 0.8637\n",
      "Found 754 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "11/11 [==============================] - 9s 832ms/step - loss: 0.0297 - acc: 0.9943 - val_loss: 0.4156 - val_acc: 0.8824\n",
      "Found 596 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "9/9 [==============================] - 8s 928ms/step - loss: 0.0845 - acc: 0.9702 - val_loss: 0.9967 - val_acc: 0.7591\n",
      "Found 544 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "8/8 [==============================] - 8s 980ms/step - loss: 0.0155 - acc: 1.0000 - val_loss: 0.8978 - val_acc: 0.7868\n",
      "Found 540 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0131 - acc: 0.9980 - val_loss: 0.7491 - val_acc: 0.8252\n",
      "Found 656 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "10/10 [==============================] - 9s 859ms/step - loss: 0.0408 - acc: 0.9874 - val_loss: 0.6468 - val_acc: 0.8516\n",
      "Found 748 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "11/11 [==============================] - 9s 834ms/step - loss: 0.0311 - acc: 0.9943 - val_loss: 0.5708 - val_acc: 0.8713\n",
      "Found 911 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "14/14 [==============================] - 10s 716ms/step - loss: 0.0079 - acc: 1.0000 - val_loss: 0.5698 - val_acc: 0.8650\n",
      "Found 708 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "11/11 [==============================] - 9s 814ms/step - loss: 0.5085 - acc: 0.8244 - val_loss: 2.3696 - val_acc: 0.5020\n",
      "Found 832 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "13/13 [==============================] - 10s 765ms/step - loss: 0.0782 - acc: 0.9820 - val_loss: 1.5919 - val_acc: 0.6330\n",
      "Found 651 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "10/10 [==============================] - 9s 882ms/step - loss: 1.0646 - acc: 0.7189 - val_loss: 14.4522 - val_acc: 0.1033\n",
      "Found 717 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "11/11 [==============================] - 9s 833ms/step - loss: 0.3582 - acc: 0.9205 - val_loss: 14.0600 - val_acc: 0.1033\n",
      "Found 733 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "11/11 [==============================] - 9s 817ms/step - loss: 0.1253 - acc: 0.9672 - val_loss: 8.1126 - val_acc: 0.3572\n",
      "Found 736 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "11/11 [==============================] - 9s 812ms/step - loss: 0.1043 - acc: 0.9701 - val_loss: 10.3834 - val_acc: 0.2865\n",
      "Found 922 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "14/14 [==============================] - 10s 702ms/step - loss: 0.1257 - acc: 0.9604 - val_loss: 6.5356 - val_acc: 0.3728\n",
      "Found 314 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "4/4 [==============================] - 7s 2s/step - loss: 0.2900 - acc: 0.9006 - val_loss: 1.6743 - val_acc: 0.6419\n",
      "Found 734 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "11/11 [==============================] - 9s 817ms/step - loss: 0.0849 - acc: 0.9758 - val_loss: 0.9404 - val_acc: 0.7501\n",
      "Found 736 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "11/11 [==============================] - 9s 815ms/step - loss: 0.0544 - acc: 0.9829 - val_loss: 1.3070 - val_acc: 0.6692\n",
      "step {9}\n",
      "Found 655 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "10/10 [==============================] - 9s 856ms/step - loss: 0.0965 - acc: 0.9750 - val_loss: 1.5499 - val_acc: 0.6674\n",
      "Found 749 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "11/11 [==============================] - 9s 825ms/step - loss: 0.1154 - acc: 0.9687 - val_loss: 1.7908 - val_acc: 0.6616\n",
      "Found 778 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "12/12 [==============================] - 9s 769ms/step - loss: 0.0557 - acc: 0.9882 - val_loss: 1.4542 - val_acc: 0.7219\n",
      "Found 792 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "12/12 [==============================] - 9s 780ms/step - loss: 0.0309 - acc: 0.9895 - val_loss: 0.8358 - val_acc: 0.8069\n",
      "Found 957 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "14/14 [==============================] - 10s 730ms/step - loss: 0.0349 - acc: 0.9911 - val_loss: 0.4840 - val_acc: 0.8753\n",
      "Found 1121 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "17/17 [==============================] - 11s 657ms/step - loss: 0.0638 - acc: 0.9834 - val_loss: 0.5824 - val_acc: 0.8306\n",
      "Found 1123 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "17/17 [==============================] - 11s 644ms/step - loss: 0.0219 - acc: 0.9963 - val_loss: 0.5243 - val_acc: 0.8440\n",
      "Found 1109 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "17/17 [==============================] - 11s 647ms/step - loss: 0.0275 - acc: 0.9945 - val_loss: 0.6364 - val_acc: 0.8288\n",
      "Found 1071 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "16/16 [==============================] - 11s 666ms/step - loss: 0.0403 - acc: 0.9863 - val_loss: 0.4963 - val_acc: 0.8681\n",
      "Found 754 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "11/11 [==============================] - 9s 823ms/step - loss: 0.0320 - acc: 0.9943 - val_loss: 0.3356 - val_acc: 0.9021\n",
      "Found 596 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "9/9 [==============================] - 8s 925ms/step - loss: 0.0331 - acc: 0.9930 - val_loss: 0.2817 - val_acc: 0.9142\n",
      "Found 544 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0205 - acc: 0.9921 - val_loss: 0.3400 - val_acc: 0.8905\n",
      "Found 540 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "8/8 [==============================] - 8s 1s/step - loss: 0.0151 - acc: 0.9980 - val_loss: 0.3759 - val_acc: 0.8905\n",
      "Found 656 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "10/10 [==============================] - 9s 863ms/step - loss: 0.0321 - acc: 0.9921 - val_loss: 0.3579 - val_acc: 0.8954\n",
      "Found 748 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "11/11 [==============================] - 9s 801ms/step - loss: 0.0395 - acc: 0.9894 - val_loss: 0.3835 - val_acc: 0.8923\n",
      "Found 911 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "14/14 [==============================] - 10s 705ms/step - loss: 0.0122 - acc: 0.9989 - val_loss: 0.5337 - val_acc: 0.8628\n",
      "Found 708 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "11/11 [==============================] - 9s 798ms/step - loss: 0.0878 - acc: 0.9785 - val_loss: 0.7859 - val_acc: 0.8288\n",
      "Found 832 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "13/13 [==============================] - 10s 751ms/step - loss: 0.0436 - acc: 0.9892 - val_loss: 2.3567 - val_acc: 0.6594\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 651 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "10/10 [==============================] - 9s 891ms/step - loss: 0.0490 - acc: 0.9875 - val_loss: 1.9806 - val_acc: 0.6679\n",
      "Found 717 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "11/11 [==============================] - 9s 795ms/step - loss: 0.0459 - acc: 0.9820 - val_loss: 0.9513 - val_acc: 0.7725\n",
      "Found 733 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "11/11 [==============================] - 9s 821ms/step - loss: 0.0334 - acc: 0.9856 - val_loss: 0.8348 - val_acc: 0.8015\n",
      "Found 736 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "11/11 [==============================] - 9s 800ms/step - loss: 0.0457 - acc: 0.9873 - val_loss: 0.7710 - val_acc: 0.8002\n",
      "Found 922 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "14/14 [==============================] - 10s 704ms/step - loss: 0.0537 - acc: 0.9832 - val_loss: 0.6384 - val_acc: 0.8319\n",
      "Found 314 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "4/4 [==============================] - 7s 2s/step - loss: 0.0424 - acc: 0.9921 - val_loss: 0.6679 - val_acc: 0.8283\n",
      "Found 734 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "11/11 [==============================] - 9s 819ms/step - loss: 0.0282 - acc: 0.9929 - val_loss: 0.5192 - val_acc: 0.8722\n",
      "Found 736 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      "11/11 [==============================] - 9s 814ms/step - loss: 0.0219 - acc: 0.9929 - val_loss: 0.4944 - val_acc: 0.8891\n"
     ]
    }
   ],
   "source": [
    "model = train_model(restNet_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda/lib/python3.5/site-packages/ipykernel_launcher.py:19: FutureWarning: set_value is deprecated and will be removed in a future release. Please use .at[] or .iat[] accessors instead\n",
      "/home/ubuntu/anaconda/lib/python3.5/site-packages/ipykernel_launcher.py:22: FutureWarning: set_value is deprecated and will be removed in a future release. Please use .at[] or .iat[] accessors instead\n"
     ]
    }
   ],
   "source": [
    "test_model(model, 'pred.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
