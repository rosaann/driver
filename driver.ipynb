{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import *\n",
    "from keras.layers import *\n",
    "from keras.applications import *\n",
    "from keras.preprocessing.image import *\n",
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def vgg19Model(image_size = (224, 224), if_draw_model = False):\n",
    "    width = image_size[0]\n",
    "    height = image_size[1]\n",
    "    \n",
    "    base_model = ResNet50(input_tensor=Input((height, width, 3)), weights='imagenet', include_top=False)\n",
    "\n",
    "    for layers in base_model.layers:\n",
    "        layers.trainable = True\n",
    "        \n",
    "    for i, layer in enumerate(base_model.layers):\n",
    "        print(i, layer.name)\n",
    "        \n",
    " #   for layer in model.layers[140:]:\n",
    " #       layer.trainable = True\n",
    "\n",
    "    x = GlobalAveragePooling2D()(base_model.output)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = Dense(10, activation='sigmoid')(x)\n",
    "    model = Model(base_model.input, x)\n",
    "    \n",
    "    if if_draw_model:\n",
    "        SVG(model_to_dot(model).create(prog='dot', format='svg'))\n",
    "    \n",
    "    model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "    return model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "from sklearn.utils import shuffle\n",
    "np.random.seed(2017)\n",
    "\n",
    "def prepare_val():\n",
    "    dirname = 'imgs/val'\n",
    "    dirname_src = 'imgs/train/'\n",
    "    if os.path.exists(dirname):\n",
    "        return\n",
    "    os.mkdir(dirname)\n",
    "    sub_dirs = ['c0', 'c1', 'c2', 'c3', 'c4', 'c5', 'c6', 'c7', 'c8', 'c9']\n",
    "    for sub_dir in sub_dirs:\n",
    "        address_des = dirname + '/' + sub_dir\n",
    "        os.mkdir(address_des)\n",
    "        \n",
    "        address_src = dirname_src + '/' + sub_dir\n",
    "        train_filenames = os.listdir(address_src)\n",
    "        train_filenames = shuffle(train_filenames)\n",
    "        for file_src in train_filenames[0: int(len(train_filenames) / 10)]:\n",
    "            add_con_list = file_src.split('/')\n",
    "            add_old = dirname_src + sub_dir + '/' + add_con_list[-1]\n",
    "            add_new = dirname + '/' + sub_dir + '/' + add_con_list[-1]\n",
    "         #   print(add_old)\n",
    "         #   print(add_new)\n",
    "            shutil.move(add_old, add_new)  \n",
    "        \n",
    "prepare_val()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "image_size=(224, 224)\n",
    "batch_size =64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#шонч╗Г\n",
    "nb_train_samples = 20197\n",
    "def train_model(Model):\n",
    "    model = Model()\n",
    "    \n",
    "    train_datagen = ImageDataGenerator(\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True)\n",
    "    \n",
    "    train_generator = train_datagen.flow_from_directory(\n",
    "    'imgs/train',\n",
    "    target_size=(image_size[0], image_size[1]),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical')\n",
    "    \n",
    "    val_generator = train_datagen.flow_from_directory(\n",
    "    'imgs/val',\n",
    "    target_size=(image_size[0], image_size[1]),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical')\n",
    "        \n",
    "    model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch=nb_train_samples // batch_size,\n",
    "    epochs=15,\n",
    "    validation_data = val_generator)\n",
    "    \n",
    "    model.save_weights('model.h5')\n",
    "    \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import cv2\n",
    "def test_model(model):\n",
    "    df = pd.read_csv(\"sample_submission.csv\")\n",
    "    \n",
    "    test_address = 'imgs/test'\n",
    "    test_filenames = os.listdir(test_address)\n",
    " #   test_filenames = test_filenames[:10]\n",
    "    X = np.zeros((len(test_filenames), image_size[0], image_size[1], 3), dtype=np.uint8)\n",
    "\n",
    "    for i, test_file in enumerate(test_filenames) :\n",
    "        X[i] = cv2.resize(cv2.imread(test_address + '/' + test_file), image_size)\n",
    "    \n",
    "    y_pred = model.predict(X, batch_size=batch_size, verbose=0)\n",
    "  #  print(y_pred)\n",
    "    \n",
    "    for i, fname in enumerate(test_filenames):\n",
    "        print(fname)\n",
    "        df.set_value(i, 'img', fname)\n",
    "        sub_dirs = ['c0', 'c1', 'c2', 'c3', 'c4', 'c5', 'c6', 'c7', 'c8', 'c9']\n",
    "        for ii, sb in enumerate(sub_dirs):\n",
    "            df.set_value(i, sb, y_pred[i][ii])\n",
    "\n",
    "\n",
    "    df.to_csv('pred.csv', index=None)\n",
    "    df.head(10)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 20187 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/15\n",
      "315/315 [==============================] - 608s 2s/step - loss: 0.0458 - acc: 0.9862 - val_loss: 0.1460 - val_acc: 0.9598\n",
      "Epoch 10/15\n",
      "315/315 [==============================] - 608s 2s/step - loss: 0.0452 - acc: 0.9872 - val_loss: 0.1049 - val_acc: 0.9727\n",
      "Epoch 11/15\n",
      "315/315 [==============================] - 609s 2s/step - loss: 0.0432 - acc: 0.9873 - val_loss: 0.4226 - val_acc: 0.8882\n",
      "Epoch 12/15\n",
      "315/315 [==============================] - 609s 2s/step - loss: 0.0399 - acc: 0.9871 - val_loss: 0.9707 - val_acc: 0.8118\n",
      "Epoch 13/15\n",
      "315/315 [==============================] - 608s 2s/step - loss: 0.0436 - acc: 0.9871 - val_loss: 0.0959 - val_acc: 0.9678\n",
      "Epoch 14/15\n",
      "315/315 [==============================] - 606s 2s/step - loss: 0.0338 - acc: 0.9904 - val_loss: 0.0905 - val_acc: 0.9741\n",
      "Epoch 15/15\n",
      "315/315 [==============================] - 606s 2s/step - loss: 0.0294 - acc: 0.9911 - val_loss: 0.1742 - val_acc: 0.9477\n"
     ]
    }
   ],
   "source": [
    "# all trainable true\n",
    "model = train_model(vgg19Model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.2/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "94658560/94653016 [==============================] - 2s 0us/step\n",
      "Found 20187 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/10\n",
      "315/315 [==============================] - 343s 1s/step - loss: 1.5346 - acc: 0.4580 - val_loss: 2.5485 - val_acc: 0.3049\n",
      "Epoch 2/10\n",
      "315/315 [==============================] - 294s 933ms/step - loss: 0.9704 - acc: 0.6755 - val_loss: 2.1638 - val_acc: 0.3871\n",
      "Epoch 3/10\n",
      "315/315 [==============================] - 290s 922ms/step - loss: 0.8430 - acc: 0.7175 - val_loss: 2.5488 - val_acc: 0.3599\n",
      "Epoch 4/10\n",
      "315/315 [==============================] - 295s 935ms/step - loss: 0.8048 - acc: 0.7299 - val_loss: 3.2590 - val_acc: 0.2986\n",
      "Epoch 5/10\n",
      "315/315 [==============================] - 293s 930ms/step - loss: 0.7828 - acc: 0.7346 - val_loss: 2.5929 - val_acc: 0.3979\n",
      "Epoch 6/10\n",
      "315/315 [==============================] - 291s 925ms/step - loss: 0.7613 - acc: 0.7376 - val_loss: 3.0367 - val_acc: 0.3250\n",
      "Epoch 7/10\n",
      "315/315 [==============================] - 294s 932ms/step - loss: 0.7537 - acc: 0.7455 - val_loss: 2.8400 - val_acc: 0.3800\n",
      "Epoch 8/10\n",
      "315/315 [==============================] - 293s 931ms/step - loss: 0.7572 - acc: 0.7447 - val_loss: 3.4700 - val_acc: 0.3232\n",
      "Epoch 9/10\n",
      "315/315 [==============================] - 292s 927ms/step - loss: 0.7383 - acc: 0.7486 - val_loss: 3.1494 - val_acc: 0.3643\n",
      "Epoch 10/10\n",
      "315/315 [==============================] - 292s 926ms/step - loss: 0.7598 - acc: 0.7413 - val_loss: 3.7833 - val_acc: 0.2924\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.engine.training.Model at 0x7f5eb78d66d8>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# all trainable false\n",
    "train_model(vgg19Model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
