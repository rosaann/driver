{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import *\n",
    "from keras.layers import *\n",
    "from keras.applications import *\n",
    "from keras.preprocessing.image import *\n",
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "import numpy as np\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import applications\n",
    "def vgg16Model(image_size = (224, 224), if_draw_model = False):\n",
    "    width = image_size[0]\n",
    "    height = image_size[1]\n",
    "    \n",
    "    base_model = applications.VGG16(input_tensor=Input((height, width, 3)), weights='imagenet', include_top=False)\n",
    "\n",
    "    for layers in base_model.layers:\n",
    "        layers.trainable = True\n",
    "        \n",
    "    for i, layer in enumerate(base_model.layers):\n",
    "        print(i, layer.name)\n",
    "        \n",
    "   # for layer in base_model.layers[25:]:\n",
    "   #     layer.trainable = True\n",
    "\n",
    "    x = GlobalAveragePooling2D()(base_model.output)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = Dense(10, activation='sigmoid')(x)\n",
    "    model = Model(base_model.input, x)\n",
    "    \n",
    "    if if_draw_model:\n",
    "        SVG(model_to_dot(model).create(prog='dot', format='svg'))\n",
    "    \n",
    "    model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications.resnet50 import ResNet50\n",
    "from keras.applications.resnet50 import preprocess_input, decode_predictions\n",
    "import numpy as np\n",
    "\n",
    "def restNet_model(image_size = (224, 224), if_draw_model = False):\n",
    "\n",
    "    width = image_size[0]\n",
    "    height = image_size[1]\n",
    "    \n",
    "    base_model = ResNet50(input_tensor=Input((height, width, 3)), weights='imagenet', include_top=False)\n",
    "\n",
    "    for layers in base_model.layers:\n",
    "        layers.trainable = True\n",
    "        \n",
    "    for i, layer in enumerate(base_model.layers):\n",
    "        print(i, layer.name)\n",
    "        \n",
    "   # for layer in base_model.layers[25:]:\n",
    "   #     layer.trainable = True\n",
    "\n",
    "    x = GlobalAveragePooling2D()(base_model.output)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = Dense(10, activation='sigmoid')(x)\n",
    "    model = Model(base_model.input, x)\n",
    "    \n",
    "    if if_draw_model:\n",
    "        SVG(model_to_dot(model).create(prog='dot', format='svg'))\n",
    "    \n",
    "    model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.applications.inception_v3 import preprocess_input, decode_predictions\n",
    "import numpy as np\n",
    "\n",
    "def inceptionV3_model(image_size = (224, 224), if_draw_model = False):\n",
    "\n",
    "    width = image_size[0]\n",
    "    height = image_size[1]\n",
    "    \n",
    "    base_model = InceptionV3(input_tensor=Input((height, width, 3)), weights='imagenet', include_top=False)\n",
    "\n",
    "    for layers in base_model.layers:\n",
    "        layers.trainable = True\n",
    "        \n",
    "    for i, layer in enumerate(base_model.layers):\n",
    "        print(i, layer.name)\n",
    "        \n",
    "   # for layer in base_model.layers[25:]:\n",
    "   #     layer.trainable = True\n",
    "\n",
    "    x = GlobalAveragePooling2D()(base_model.output)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = Dense(10, activation='sigmoid')(x)\n",
    "    model = Model(base_model.input, x)\n",
    "    \n",
    "    if if_draw_model:\n",
    "        SVG(model_to_dot(model).create(prog='dot', format='svg'))\n",
    "    \n",
    "    model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#简单模型\n",
    "def simple_model(time_len=1):\n",
    "    ch, row, col = 3, 66, 200  # camera format\n",
    "    model = Sequential()\n",
    "    model.add(Lambda(lambda x: x/127.5 - 1.,\n",
    "  #  model.add(Lambda(lambda x: x,\n",
    "            input_shape=( row, col, ch),\n",
    "            output_shape=( row, col,ch)))\n",
    "    model.add(Convolution2D(3, 3, 3, subsample=(2, 2), border_mode=\"same\"))\n",
    "    model.add(ELU())\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    model.add(Dropout(.5))\n",
    "    model.add(ELU())\n",
    "    model.add(Dense(10))\n",
    "#  model.add(Lambda(nor_output_1))\n",
    "    sgd = optimizers.SGD(lr=0.00003, momentum=0.9, nesterov=True)\n",
    "    model.compile(loss='mean_squared_error', optimizer=sgd)\n",
    "\n",
    "      \n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "from sklearn.utils import shuffle\n",
    "np.random.seed(2017)\n",
    "\n",
    "def prepare_val():\n",
    "    dirname = 'imgs/val'\n",
    "    dirname_src = 'imgs/train/'\n",
    "    if os.path.exists(dirname):\n",
    "        return\n",
    "    os.mkdir(dirname)\n",
    "    sub_dirs = ['c0', 'c1', 'c2', 'c3', 'c4', 'c5', 'c6', 'c7', 'c8', 'c9']\n",
    "    for sub_dir in sub_dirs:\n",
    "        address_des = dirname + '/' + sub_dir\n",
    "        os.mkdir(address_des)\n",
    "        \n",
    "        address_src = dirname_src + '/' + sub_dir\n",
    "        train_filenames = os.listdir(address_src)\n",
    "        train_filenames = shuffle(train_filenames)\n",
    "        for file_src in train_filenames[0: int(len(train_filenames) / 10)]:\n",
    "            add_con_list = file_src.split('/')\n",
    "            add_old = dirname_src + sub_dir + '/' + add_con_list[-1]\n",
    "            add_new = dirname + '/' + sub_dir + '/' + add_con_list[-1]\n",
    "         #   print(add_old)\n",
    "         #   print(add_new)\n",
    "            shutil.move(add_old, add_new)  \n",
    "        \n",
    "prepare_val()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import pandas as pd\n",
    "import cv2\n",
    "from sklearn.utils import shuffle\n",
    "np.random.seed(2017)\n",
    "\n",
    "def get_driver_list():\n",
    "    driver_id_list = []\n",
    "    df = pd.read_csv(\"driver_imgs_list.csv\")\n",
    "    for i in range(df.shape[0]):\n",
    "        driver_id = df.loc[i][\"subject\"]\n",
    "        is_saved_id = False\n",
    "        for saved_id in driver_id_list:\n",
    "            if saved_id == driver_id:\n",
    "                is_saved_id = True\n",
    "                break\n",
    "        \n",
    "        if is_saved_id == False:\n",
    "            driver_id_list.append(driver_id)\n",
    "    return driver_id_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def prepare_data():\n",
    "    dirbase = 'imgs/train2/'\n",
    "    if os.path.exists(dirbase):\n",
    "        return\n",
    "    os.mkdir(dirbase)\n",
    "        \n",
    "    driver_id_list = get_driver_list()\n",
    "    \n",
    "    df = pd.read_csv(\"driver_imgs_list.csv\")  \n",
    "    sub_dirs = ['c0', 'c1', 'c2', 'c3', 'c4', 'c5', 'c6', 'c7', 'c8', 'c9']\n",
    "    for driver_id in driver_id_list:\n",
    "        os.mkdir(dirbase + driver_id)\n",
    "        for sub_dir in sub_dirs:\n",
    "            os.mkdir(dirbase + driver_id + '/' + sub_dir)\n",
    "\n",
    "    for i in range(df.shape[0]):\n",
    "        driver_id = df.loc[i][\"subject\"]\n",
    "        class_name = df.loc[i][\"classname\"]\n",
    "        img = df.loc[i][\"img\"]\n",
    "        add_old = 'imgs/train/' + class_name+'/' + img\n",
    "        add_new = dirbase + driver_id + '/' + class_name + '/' + img\n",
    "        if os.path.exists(add_old):\n",
    "            shutil.move(add_old, add_new)\n",
    "        \n",
    "prepare_data()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size=(224, 224)\n",
    "batch_size =64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#训练\n",
    "from keras.callbacks import EarlyStopping\n",
    "#from keras.applications.vgg19 import preprocess_input\n",
    "#from keras.applications.resnet50 import preprocess_input, decode_predictions\n",
    "from keras.applications.inception_v3 import preprocess_input, decode_predictions\n",
    "\n",
    "\n",
    "def get_file_num(driver_id):\n",
    "    train_base_add = 'imgs/train2/'\n",
    "    add_driver = train_base_add + driver_id\n",
    "    sub_dirs = ['c0', 'c1', 'c2', 'c3', 'c4', 'c5', 'c6', 'c7', 'c8', 'c9']\n",
    "    num = 0\n",
    "    for sub_dir in sub_dirs:\n",
    "        add_driver_class = add_driver + '/' + sub_dir\n",
    "        train_filenames = os.listdir(add_driver_class)\n",
    "        num += len(train_filenames)\n",
    "    return num\n",
    "\n",
    "def train_model(Model):\n",
    "    model = Model()\n",
    "    \n",
    "    train_datagen = ImageDataGenerator(\n",
    " #   shear_range=0.2,\n",
    " #   zoom_range=0.2,\n",
    "    preprocessing_function=preprocess_input,\n",
    " #   horizontal_flip=True\n",
    "    )\n",
    "    driver_id_list = get_driver_list()\n",
    "    train_base_add = 'imgs/train2/'\n",
    "    \n",
    "    for epoch in range(10):\n",
    "        for driver_id in driver_id_list:\n",
    "            nb_train_samples = get_file_num(driver_id)\n",
    "            \n",
    "            train_generator = train_datagen.flow_from_directory(\n",
    "            train_base_add + driver_id,\n",
    "            target_size=(image_size[0], image_size[1]),\n",
    "            batch_size=batch_size,\n",
    "            class_mode='categorical')\n",
    "    \n",
    "            val_generator = train_datagen.flow_from_directory(\n",
    "            'imgs/val',\n",
    "            target_size=(image_size[0], image_size[1]),\n",
    "            batch_size=batch_size,\n",
    "            class_mode='categorical')\n",
    "        \n",
    "            model.fit_generator(\n",
    "            train_generator,\n",
    "            steps_per_epoch=nb_train_samples // batch_size,\n",
    "            epochs=1,\n",
    "            workers=6,\n",
    "            callbacks=[EarlyStopping(monitor='val_loss', patience=5)],\n",
    "            validation_data = val_generator)\n",
    "    \n",
    "          #  model.save_weights('model.h5')\n",
    "    \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import cv2\n",
    "def test_model(model, file_name):\n",
    "    df = pd.read_csv(\"sample_submission.csv\")\n",
    "    \n",
    "    test_address = 'imgs/test'\n",
    "    test_filenames = os.listdir(test_address)\n",
    " #   test_filenames = test_filenames[:10]\n",
    "    X = np.zeros((len(test_filenames), image_size[0], image_size[1], 3), dtype=np.uint8)\n",
    "\n",
    "    for i, test_file in enumerate(test_filenames) :\n",
    "        X[i] = cv2.resize(cv2.imread(test_address + '/' + test_file), image_size)\n",
    "    \n",
    "    y_pred = model.predict(X, batch_size=batch_size, verbose=0)\n",
    "  #  print(y_pred)\n",
    "    \n",
    "    for i, fname in enumerate(test_filenames):\n",
    "      #  print(fname)\n",
    "        df.set_value(i, 'img', fname)\n",
    "        sub_dirs = ['c0', 'c1', 'c2', 'c3', 'c4', 'c5', 'c6', 'c7', 'c8', 'c9']\n",
    "        for ii, sb in enumerate(sub_dirs):\n",
    "            df.set_value(i, sb, y_pred[i][ii])\n",
    "\n",
    "\n",
    "    df.to_csv(file_name, index=None)\n",
    "    df.head(10)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 input_3\n",
      "1 conv1\n",
      "2 bn_conv1\n",
      "3 activation_99\n",
      "4 max_pooling2d_3\n",
      "5 res2a_branch2a\n",
      "6 bn2a_branch2a\n",
      "7 activation_100\n",
      "8 res2a_branch2b\n",
      "9 bn2a_branch2b\n",
      "10 activation_101\n",
      "11 res2a_branch2c\n",
      "12 res2a_branch1\n",
      "13 bn2a_branch2c\n",
      "14 bn2a_branch1\n",
      "15 add_33\n",
      "16 activation_102\n",
      "17 res2b_branch2a\n",
      "18 bn2b_branch2a\n",
      "19 activation_103\n",
      "20 res2b_branch2b\n",
      "21 bn2b_branch2b\n",
      "22 activation_104\n",
      "23 res2b_branch2c\n",
      "24 bn2b_branch2c\n",
      "25 add_34\n",
      "26 activation_105\n",
      "27 res2c_branch2a\n",
      "28 bn2c_branch2a\n",
      "29 activation_106\n",
      "30 res2c_branch2b\n",
      "31 bn2c_branch2b\n",
      "32 activation_107\n",
      "33 res2c_branch2c\n",
      "34 bn2c_branch2c\n",
      "35 add_35\n",
      "36 activation_108\n",
      "37 res3a_branch2a\n",
      "38 bn3a_branch2a\n",
      "39 activation_109\n",
      "40 res3a_branch2b\n",
      "41 bn3a_branch2b\n",
      "42 activation_110\n",
      "43 res3a_branch2c\n",
      "44 res3a_branch1\n",
      "45 bn3a_branch2c\n",
      "46 bn3a_branch1\n",
      "47 add_36\n",
      "48 activation_111\n",
      "49 res3b_branch2a\n",
      "50 bn3b_branch2a\n",
      "51 activation_112\n",
      "52 res3b_branch2b\n",
      "53 bn3b_branch2b\n",
      "54 activation_113\n",
      "55 res3b_branch2c\n",
      "56 bn3b_branch2c\n",
      "57 add_37\n",
      "58 activation_114\n",
      "59 res3c_branch2a\n",
      "60 bn3c_branch2a\n",
      "61 activation_115\n",
      "62 res3c_branch2b\n",
      "63 bn3c_branch2b\n",
      "64 activation_116\n",
      "65 res3c_branch2c\n",
      "66 bn3c_branch2c\n",
      "67 add_38\n",
      "68 activation_117\n",
      "69 res3d_branch2a\n",
      "70 bn3d_branch2a\n",
      "71 activation_118\n",
      "72 res3d_branch2b\n",
      "73 bn3d_branch2b\n",
      "74 activation_119\n",
      "75 res3d_branch2c\n",
      "76 bn3d_branch2c\n",
      "77 add_39\n",
      "78 activation_120\n",
      "79 res4a_branch2a\n",
      "80 bn4a_branch2a\n",
      "81 activation_121\n",
      "82 res4a_branch2b\n",
      "83 bn4a_branch2b\n",
      "84 activation_122\n",
      "85 res4a_branch2c\n",
      "86 res4a_branch1\n",
      "87 bn4a_branch2c\n",
      "88 bn4a_branch1\n",
      "89 add_40\n",
      "90 activation_123\n",
      "91 res4b_branch2a\n",
      "92 bn4b_branch2a\n",
      "93 activation_124\n",
      "94 res4b_branch2b\n",
      "95 bn4b_branch2b\n",
      "96 activation_125\n",
      "97 res4b_branch2c\n",
      "98 bn4b_branch2c\n",
      "99 add_41\n",
      "100 activation_126\n",
      "101 res4c_branch2a\n",
      "102 bn4c_branch2a\n",
      "103 activation_127\n",
      "104 res4c_branch2b\n",
      "105 bn4c_branch2b\n",
      "106 activation_128\n",
      "107 res4c_branch2c\n",
      "108 bn4c_branch2c\n",
      "109 add_42\n",
      "110 activation_129\n",
      "111 res4d_branch2a\n",
      "112 bn4d_branch2a\n",
      "113 activation_130\n",
      "114 res4d_branch2b\n",
      "115 bn4d_branch2b\n",
      "116 activation_131\n",
      "117 res4d_branch2c\n",
      "118 bn4d_branch2c\n",
      "119 add_43\n",
      "120 activation_132\n",
      "121 res4e_branch2a\n",
      "122 bn4e_branch2a\n",
      "123 activation_133\n",
      "124 res4e_branch2b\n",
      "125 bn4e_branch2b\n",
      "126 activation_134\n",
      "127 res4e_branch2c\n",
      "128 bn4e_branch2c\n",
      "129 add_44\n",
      "130 activation_135\n",
      "131 res4f_branch2a\n",
      "132 bn4f_branch2a\n",
      "133 activation_136\n",
      "134 res4f_branch2b\n",
      "135 bn4f_branch2b\n",
      "136 activation_137\n",
      "137 res4f_branch2c\n",
      "138 bn4f_branch2c\n",
      "139 add_45\n",
      "140 activation_138\n",
      "141 res5a_branch2a\n",
      "142 bn5a_branch2a\n",
      "143 activation_139\n",
      "144 res5a_branch2b\n",
      "145 bn5a_branch2b\n",
      "146 activation_140\n",
      "147 res5a_branch2c\n",
      "148 res5a_branch1\n",
      "149 bn5a_branch2c\n",
      "150 bn5a_branch1\n",
      "151 add_46\n",
      "152 activation_141\n",
      "153 res5b_branch2a\n",
      "154 bn5b_branch2a\n",
      "155 activation_142\n",
      "156 res5b_branch2b\n",
      "157 bn5b_branch2b\n",
      "158 activation_143\n",
      "159 res5b_branch2c\n",
      "160 bn5b_branch2c\n",
      "161 add_47\n",
      "162 activation_144\n",
      "163 res5c_branch2a\n",
      "164 bn5c_branch2a\n",
      "165 activation_145\n",
      "166 res5c_branch2b\n",
      "167 bn5c_branch2b\n",
      "168 activation_146\n",
      "169 res5c_branch2c\n",
      "170 bn5c_branch2c\n",
      "171 add_48\n",
      "172 activation_147\n",
      "173 avg_pool\n",
      "Found 655 images belonging to 10 classes.\n",
      "Found 2237 images belonging to 10 classes.\n",
      "Epoch 1/1\n",
      " 2/10 [=====>........................] - ETA: 5:10 - loss: 2.1001 - acc: 0.3594"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = train_model(restNet_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
